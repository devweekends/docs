---
title: "Compute Services"
description: "Master EC2, Lambda, ECS, EKS, and Auto Scaling for any workload"
icon: "microchip"
---

<Frame>
  <img src="/images/aws/ec2-instance-families.svg" alt="EC2 Instance Families" />
</Frame>

## Module Overview

<Info>
**Estimated Time**: 4-5 hours | **Difficulty**: Intermediate | **Prerequisites**: Core Concepts
</Info>

This module covers all AWS compute services in depth. You'll learn when to use each service, how to optimize for cost and performance, and real-world architecture patterns.

**What You'll Learn:**
- EC2 instance types, AMIs, and advanced configurations
- Lambda functions for serverless computing
- Container orchestration with ECS and EKS
- Auto Scaling strategies for elasticity
- Cost optimization techniques for compute

---

## Compute Service Selection Guide

Choose the right compute service for your workload:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AWS Compute Decision Tree                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚   What type of workload?                                              â”‚
â”‚         â”‚                                                             â”‚
â”‚         â”œâ”€â”€â”€ Short-lived, event-driven â”€â”€â”€â”€â”€â”€â–º Lambda (Serverless)   â”‚
â”‚         â”‚    (< 15 min, stateless)                                   â”‚
â”‚         â”‚                                                             â”‚
â”‚         â”œâ”€â”€â”€ Containers needed â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â–º ECS (AWS Native)      â”‚
â”‚         â”‚                           â”‚                                 â”‚
â”‚         â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â–º EKS (Kubernetes)      â”‚
â”‚         â”‚                                                             â”‚
â”‚         â”œâ”€â”€â”€ Full control needed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º EC2 (Virtual Servers) â”‚
â”‚         â”‚    (OS, networking, GPUs)                                  â”‚
â”‚         â”‚                                                             â”‚
â”‚         â””â”€â”€â”€ Simple web app â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Elastic Beanstalk     â”‚
â”‚              (PaaS)                               or App Runner       â”‚
â”‚                                                                       â”‚
â”‚   Control vs Simplicity Spectrum:                                     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚   More Control â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Less Management â”‚
â”‚   EC2  â”‚  ECS/EKS  â”‚  Fargate  â”‚  Lambda  â”‚  App Runner              â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## EC2 (Elastic Compute Cloud)

Virtual servers in the cloud. The most fundamental and flexible AWS compute service.

### Instance Type Deep Dive

AWS offers 500+ instance types optimized for different workloads:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EC2 Instance Families                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚   GENERAL PURPOSE (M, T)                                              â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚   M-series: Balanced compute, memory, networking                      â”‚
â”‚   â€¢ m5.large    2 vCPU,  8 GB  â†’ Web servers, small databases        â”‚
â”‚   â€¢ m5.xlarge   4 vCPU, 16 GB  â†’ Application servers                 â”‚
â”‚   â€¢ m5.4xlarge 16 vCPU, 64 GB  â†’ Medium workloads                    â”‚
â”‚   â€¢ m7g.*      Graviton3 (ARM) â†’ 40% better price/performance        â”‚
â”‚                                                                       â”‚
â”‚   T-series: Burstable performance (for variable workloads)           â”‚
â”‚   â€¢ t3.micro   2 vCPU,  1 GB   â†’ Free tier, dev/test                 â”‚
â”‚   â€¢ t3.medium  2 vCPU,  4 GB   â†’ Light production                    â”‚
â”‚   â€¢ t3.xlarge  4 vCPU, 16 GB   â†’ Moderate workloads                  â”‚
â”‚                                                                       â”‚
â”‚   COMPUTE OPTIMIZED (C)                                               â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚   High CPU-to-memory ratio for compute-intensive tasks               â”‚
â”‚   â€¢ c5.large    2 vCPU,  4 GB  â†’ Batch processing                    â”‚
â”‚   â€¢ c5.4xlarge 16 vCPU, 32 GB  â†’ Scientific computing                â”‚
â”‚   â€¢ c7g.*      Graviton3       â†’ Best compute price/perf             â”‚
â”‚                                                                       â”‚
â”‚   MEMORY OPTIMIZED (R, X)                                             â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚   High memory-to-CPU ratio for in-memory workloads                   â”‚
â”‚   â€¢ r5.large    2 vCPU, 16 GB  â†’ Caching, in-memory DB               â”‚
â”‚   â€¢ r5.4xlarge 16 vCPU,128 GB  â†’ SAP HANA, Redis                     â”‚
â”‚   â€¢ x1e.xlarge  4 vCPU,122 GB  â†’ Extreme memory                      â”‚
â”‚                                                                       â”‚
â”‚   STORAGE OPTIMIZED (I, D)                                            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â”‚
â”‚   High sequential read/write access to large datasets                â”‚
â”‚   â€¢ i3.large    2 vCPU, 15 GB, 475 GB NVMe â†’ Databases              â”‚
â”‚   â€¢ d2.xlarge   4 vCPU, 31 GB, 6 TB HDD   â†’ Data warehousing        â”‚
â”‚                                                                       â”‚
â”‚   ACCELERATED COMPUTING (P, G, Inf)                                   â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚   GPU and custom hardware for ML/graphics                            â”‚
â”‚   â€¢ p4d.24xlarge  8x A100 GPUs â†’ ML training                        â”‚
â”‚   â€¢ g4dn.xlarge   1x T4 GPU    â†’ ML inference, graphics             â”‚
â”‚   â€¢ inf1.xlarge   4x Inferentiaâ†’ Cost-effective inference           â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Instance Naming Convention

```python
# Decoding instance type names
def decode_instance_type(instance_type: str):
    """
    Example: m5dn.2xlarge
    
    m     = Instance family (General Purpose)
    5     = Generation (5th gen, higher = newer)
    d     = Additional capability (NVMe SSD)
    n     = Network optimized
    2xlarge = Size (vCPUs and memory)
    
    Size progression:
    nano â†’ micro â†’ small â†’ medium â†’ large â†’ xlarge â†’ 2xlarge â†’ ... â†’ metal
    """
    
    families = {
        'm': 'General Purpose',
        't': 'Burstable',
        'c': 'Compute Optimized',
        'r': 'Memory Optimized',
        'x': 'Memory Optimized (Extreme)',
        'i': 'Storage Optimized (NVMe)',
        'd': 'Storage Optimized (Dense)',
        'p': 'GPU (Training)',
        'g': 'GPU (Graphics/Inference)',
    }
    
    modifiers = {
        'a': 'AMD processor',
        'g': 'AWS Graviton (ARM)',
        'd': 'NVMe SSD storage',
        'n': 'Network optimized',
        'e': 'Extended memory',
        'z': 'High frequency',
    }
    
    return families.get(instance_type[0], 'Unknown')
```

<Note>
**Pro Tip**: Use Graviton (ARM) instances (m7g, c7g, r7g) for 40% better price/performance on compatible workloads. Most applications work without modification.
</Note>

### T-Series Burstable Instances

T-series instances use CPU credits for burstable performance:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    T3 CPU Credit System                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   Baseline Performance:                                             â”‚
â”‚   â€¢ t3.micro:  10% CPU baseline  (earns 6 credits/hour)            â”‚
â”‚   â€¢ t3.small:  20% CPU baseline  (earns 12 credits/hour)           â”‚
â”‚   â€¢ t3.medium: 20% CPU baseline  (earns 24 credits/hour)           â”‚
â”‚   â€¢ t3.large:  30% CPU baseline  (earns 36 credits/hour)           â”‚
â”‚                                                                     â”‚
â”‚   Credit Usage:                                                     â”‚
â”‚   â€¢ 1 credit = 1 vCPU at 100% for 1 minute                         â”‚
â”‚   â€¢ Below baseline: Earn credits                                    â”‚
â”‚   â€¢ Above baseline: Spend credits                                   â”‚
â”‚   â€¢ Credits expire after 24 hours                                   â”‚
â”‚   â€¢ Max credit balance: varies by instance size                     â”‚
â”‚                                                                     â”‚
â”‚   CPU Usage Graph:                                                  â”‚
â”‚   100% â”¤          â–ˆâ–ˆâ–ˆâ–ˆ                                             â”‚
â”‚    80% â”¤         â–ˆ    â–ˆ          Burst period                      â”‚
â”‚    60% â”¤        â–ˆ      â–ˆ         (spending credits)                â”‚
â”‚    40% â”¤       â–ˆ        â–ˆ                                          â”‚
â”‚    20% â”¤â”€â”€â”€â”€â”€â”€â–ˆâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ˆâ”€â”€â”€â”€â”€â”€  â† Baseline                       â”‚
â”‚     0% â”¤                                                           â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time                            â”‚
â”‚                                                                     â”‚
â”‚   Modes:                                                            â”‚
â”‚   â€¢ Standard: Can burst only with credits                          â”‚
â”‚   â€¢ Unlimited: Can burst beyond credits (pay extra)                â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AMI (Amazon Machine Image)

AMIs are templates containing OS, application server, and applications.

```python
# AMI Selection Best Practices
ami_best_practices = {
    "use_aws_provided": [
        "Amazon Linux 2023",      # AWS optimized, free
        "Ubuntu 22.04 LTS",       # Popular, well-supported
        "Windows Server 2022",    # For .NET workloads
    ],
    
    "create_custom_ami_when": [
        "Need pre-installed software",
        "Custom security hardening",
        "Faster instance boot time",
        "Consistent deployments",
    ],
    
    "golden_ami_pipeline": """
    Base AMI â†’ Install packages â†’ Configure â†’ Test â†’ Create AMI â†’ Share
    
    Automate with:
    - EC2 Image Builder (AWS native)
    - Packer (HashiCorp)
    """,
}

# Launch EC2 with specific AMI
import boto3

ec2 = boto3.client('ec2')

response = ec2.run_instances(
    ImageId='ami-0c55b159cbfafe1f0',  # Amazon Linux 2023
    InstanceType='t3.medium',
    MinCount=1,
    MaxCount=1,
    KeyName='my-key-pair',
    SecurityGroupIds=['sg-0123456789abcdef0'],
    SubnetId='subnet-0123456789abcdef0',
    TagSpecifications=[
        {
            'ResourceType': 'instance',
            'Tags': [
                {'Key': 'Name', 'Value': 'WebServer'},
                {'Key': 'Environment', 'Value': 'Production'},
            ]
        }
    ],
    UserData='''#!/bin/bash
yum update -y
yum install -y httpd
systemctl start httpd
systemctl enable httpd
echo "<h1>Hello from $(hostname)</h1>" > /var/www/html/index.html
'''
)
```

### EC2 Instance Metadata Service (IMDS)

Access instance info from within the instance:

```bash
# IMDSv2 (recommended - more secure)
TOKEN=$(curl -X PUT "http://169.254.169.254/latest/api/token" \
  -H "X-aws-ec2-metadata-token-ttl-seconds: 21600")

# Get instance metadata
curl -H "X-aws-ec2-metadata-token: $TOKEN" \
  http://169.254.169.254/latest/meta-data/instance-id

curl -H "X-aws-ec2-metadata-token: $TOKEN" \
  http://169.254.169.254/latest/meta-data/public-ipv4

curl -H "X-aws-ec2-metadata-token: $TOKEN" \
  http://169.254.169.254/latest/meta-data/iam/security-credentials/MyRole
```

```python
# Python - Using requests with IMDSv2
import requests

def get_instance_metadata(path: str) -> str:
    """Get EC2 instance metadata using IMDSv2."""
    # Get token
    token_response = requests.put(
        "http://169.254.169.254/latest/api/token",
        headers={"X-aws-ec2-metadata-token-ttl-seconds": "21600"}
    )
    token = token_response.text
    
    # Get metadata
    response = requests.get(
        f"http://169.254.169.254/latest/meta-data/{path}",
        headers={"X-aws-ec2-metadata-token": token}
    )
    return response.text

# Usage
instance_id = get_instance_metadata("instance-id")
public_ip = get_instance_metadata("public-ipv4")
az = get_instance_metadata("placement/availability-zone")
```

---

## Lambda (Serverless Functions)

Run code without provisioning servers. Pay only for compute time used.

<Frame>
  <img src="/images/aws/lambda-architecture.svg" alt="Lambda Event-Driven Architecture" />
</Frame>

### Lambda Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Lambda Execution Model                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Request arrives                                                       â”‚
â”‚        â”‚                                                                â”‚
â”‚        â–¼                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                    Lambda Service                                â”‚  â”‚
â”‚   â”‚                                                                  â”‚  â”‚
â”‚   â”‚   Is there a warm container?                                     â”‚  â”‚
â”‚   â”‚        â”‚                                                         â”‚  â”‚
â”‚   â”‚        â”œâ”€â”€ YES â”€â”€â–º Reuse container (warm start: ~1ms)           â”‚  â”‚
â”‚   â”‚        â”‚                                                         â”‚  â”‚
â”‚   â”‚        â””â”€â”€ NO â”€â”€â”€â–º Create container (cold start: 100ms-10s)     â”‚  â”‚
â”‚   â”‚                    â”‚                                             â”‚  â”‚
â”‚   â”‚                    â”œâ”€â”€ Download code from S3                     â”‚  â”‚
â”‚   â”‚                    â”œâ”€â”€ Start runtime (Python, Node, etc.)        â”‚  â”‚
â”‚   â”‚                    â”œâ”€â”€ Run initialization code                   â”‚  â”‚
â”‚   â”‚                    â””â”€â”€ Execute handler                           â”‚  â”‚
â”‚   â”‚                                                                  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚   Cold Start Factors:                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Runtime     â”‚ Cold Start â”‚ Notes                               â”‚  â”‚
â”‚   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚
â”‚   â”‚  Python      â”‚  100-300ms â”‚ Fast, great for most use cases      â”‚  â”‚
â”‚   â”‚  Node.js     â”‚  100-300ms â”‚ Fast, good for APIs                 â”‚  â”‚
â”‚   â”‚  Go          â”‚   50-100ms â”‚ Fastest cold starts                 â”‚  â”‚
â”‚   â”‚  Java        â”‚  3-10s     â”‚ Slow, use SnapStart or GraalVM      â”‚  â”‚
â”‚   â”‚  .NET        â”‚  2-5s      â”‚ Slower, consider ReadyToRun         â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚   Mitigation Strategies:                                                â”‚
â”‚   â€¢ Provisioned Concurrency (pre-warm containers)                       â”‚
â”‚   â€¢ Smaller deployment packages                                         â”‚
â”‚   â€¢ Move initialization outside handler                                 â”‚
â”‚   â€¢ Use SnapStart for Java                                              â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Lambda Function Best Practices

```python
import json
import boto3
import os
from datetime import datetime

# âœ… Initialize outside handler (runs once per container)
dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table(os.environ['TABLE_NAME'])

def lambda_handler(event, context):
    """
    Best Practices:
    1. Keep handlers small and focused
    2. Initialize SDK clients outside handler
    3. Use environment variables for configuration
    4. Handle errors gracefully
    5. Log structured data for observability
    """
    
    # Log incoming event (structured logging)
    print(json.dumps({
        'level': 'INFO',
        'message': 'Processing request',
        'request_id': context.aws_request_id,
        'event_type': event.get('httpMethod', 'unknown'),
        'timestamp': datetime.utcnow().isoformat()
    }))
    
    try:
        # Parse input
        if 'body' in event and event['body']:
            body = json.loads(event['body'])
        else:
            body = event
        
        # Process request
        user_id = body.get('user_id')
        if not user_id:
            return response(400, {'error': 'user_id is required'})
        
        # Database operation
        result = table.get_item(Key={'user_id': user_id})
        
        if 'Item' not in result:
            return response(404, {'error': 'User not found'})
        
        return response(200, result['Item'])
        
    except json.JSONDecodeError:
        return response(400, {'error': 'Invalid JSON'})
    except Exception as e:
        # Log error for debugging
        print(json.dumps({
            'level': 'ERROR',
            'message': str(e),
            'request_id': context.aws_request_id
        }))
        return response(500, {'error': 'Internal server error'})


def response(status_code: int, body: dict) -> dict:
    """Create API Gateway compatible response."""
    return {
        'statusCode': status_code,
        'headers': {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*'
        },
        'body': json.dumps(body)
    }
```

### Lambda Limits and Quotas

| Resource | Limit | Notes |
|----------|-------|-------|
| **Timeout** | 15 minutes | Use Step Functions for longer workflows |
| **Memory** | 128 MB - 10 GB | More memory = more CPU proportionally |
| **Package Size** | 50 MB (zip), 250 MB (unzipped) | Use layers for dependencies |
| **Concurrent Executions** | 1,000 (default) | Can request increase |
| **Payload Size** | 6 MB (sync), 256 KB (async) | Use S3 for larger payloads |
| **Ephemeral Storage** | 512 MB - 10 GB (/tmp) | For temporary files |

### Lambda with Container Images

```dockerfile
# Dockerfile for Lambda container
FROM public.ecr.aws/lambda/python:3.11

# Install dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt --target "${LAMBDA_TASK_ROOT}"

# Copy function code
COPY app.py ${LAMBDA_TASK_ROOT}

# Set the handler
CMD [ "app.lambda_handler" ]
```

```bash
# Build and push to ECR
aws ecr get-login-password | docker login --username AWS --password-stdin $ECR_URI
docker build -t my-lambda .
docker tag my-lambda:latest $ECR_URI/my-lambda:latest
docker push $ECR_URI/my-lambda:latest
```

---

## ECS (Elastic Container Service)

AWS-native container orchestration for Docker containers.

### ECS Architecture Deep Dive

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ECS Architecture                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                         ECS Cluster                              â”‚  â”‚
â”‚   â”‚                                                                  â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚   â”‚   â”‚                      Service                             â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   Desired Count: 3    Running: 3    Pending: 0          â”‚   â”‚  â”‚
â”‚   â”‚   â”‚                                                          â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   Task Definition: my-app:5                              â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   â€¢ Container: nginx (256 CPU, 512 MB)                   â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   â€¢ Container: app   (512 CPU, 1024 MB)                  â”‚   â”‚  â”‚
â”‚   â”‚   â”‚                                                          â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   â”‚              Load Balancer                        â”‚  â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   â”‚        (ALB with Target Group)                    â”‚  â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚  â”‚
â”‚   â”‚   â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚   â”‚  â”‚
â”‚   â”‚   â”‚         â”‚           â”‚           â”‚                       â”‚   â”‚  â”‚
â”‚   â”‚   â”‚         â–¼           â–¼           â–¼                       â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   â”‚  Task 1  â”‚ â”‚  Task 2  â”‚ â”‚  Task 3  â”‚               â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   â”‚  (AZ-1a) â”‚ â”‚  (AZ-1b) â”‚ â”‚  (AZ-1c) â”‚               â”‚   â”‚  â”‚
â”‚   â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚   â”‚  â”‚
â”‚   â”‚   â”‚                                                          â”‚   â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚   â”‚                                                                  â”‚  â”‚
â”‚   â”‚   Launch Types:                                                  â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”‚
â”‚   â”‚   â”‚         EC2            â”‚  â”‚       Fargate          â”‚        â”‚  â”‚
â”‚   â”‚   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚        â”‚  â”‚
â”‚   â”‚   â”‚  â€¢ You manage EC2      â”‚  â”‚  â€¢ Serverless          â”‚        â”‚  â”‚
â”‚   â”‚   â”‚  â€¢ More control        â”‚  â”‚  â€¢ No EC2 management   â”‚        â”‚  â”‚
â”‚   â”‚   â”‚  â€¢ Use Reserved/Spot   â”‚  â”‚  â€¢ Pay per task        â”‚        â”‚  â”‚
â”‚   â”‚   â”‚  â€¢ GPU workloads       â”‚  â”‚  â€¢ Faster scaling      â”‚        â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”‚
â”‚   â”‚                                                                  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Task Definition Example

```json
{
  "family": "my-web-app",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "executionRoleArn": "arn:aws:iam::123456789012:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::123456789012:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "web",
      "image": "123456789012.dkr.ecr.us-east-1.amazonaws.com/my-app:latest",
      "essential": true,
      "portMappings": [
        {
          "containerPort": 8080,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {"name": "NODE_ENV", "value": "production"}
      ],
      "secrets": [
        {
          "name": "DB_PASSWORD",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:123:secret:db-password"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/my-web-app",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3
      }
    }
  ]
}
```

---

## Auto Scaling

Automatically adjust compute capacity to match demand.

### Auto Scaling Strategies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Auto Scaling Strategies                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   1. TARGET TRACKING (Recommended)                                      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚   "Keep CPU at 50%"                                                     â”‚
â”‚                                                                         â”‚
â”‚   CPU Usage                                                             â”‚
â”‚   80% â”¤                    â–ˆâ–ˆâ–ˆâ–ˆ                                        â”‚
â”‚   60% â”¤                   â–ˆ    â–ˆ                                       â”‚
â”‚   50% â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ˆâ”€â”€â”€â”€â”€â”€â–ˆâ”€â”€â”€â”€â”€â”€â”€â”€ Target                        â”‚
â”‚   40% â”¤                â–ˆ        â–ˆ                                      â”‚
â”‚   20% â”¤â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          â–ˆâ–ˆâ–ˆâ–ˆ                                   â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time                          â”‚
â”‚                                                                         â”‚
â”‚   Automatically adds/removes instances to maintain target               â”‚
â”‚                                                                         â”‚
â”‚   2. STEP SCALING                                                       â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚   "If CPU > 80%, add 3. If CPU > 60%, add 1."                          â”‚
â”‚                                                                         â”‚
â”‚   Alarm Threshold â”‚ Scaling Action                                     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚   CPU < 30%       â”‚ Remove 2 instances                                 â”‚
â”‚   CPU 30-50%      â”‚ Do nothing                                         â”‚
â”‚   CPU 50-70%      â”‚ Add 1 instance                                     â”‚
â”‚   CPU 70-90%      â”‚ Add 2 instances                                    â”‚
â”‚   CPU > 90%       â”‚ Add 4 instances                                    â”‚
â”‚                                                                         â”‚
â”‚   3. SCHEDULED SCALING                                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚   "Scale to 10 instances at 9 AM, scale to 3 at 6 PM"                  â”‚
â”‚                                                                         â”‚
â”‚   Instances                                                             â”‚
â”‚   10 â”¤     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                         â”‚
â”‚    8 â”¤    â–ˆ                  â–ˆ                                        â”‚
â”‚    6 â”¤   â–ˆ                    â–ˆ                                       â”‚
â”‚    3 â”¼â–ˆâ–ˆâ–ˆ                      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time                         â”‚
â”‚        6AM  9AM           5PM  8PM                                     â”‚
â”‚                                                                         â”‚
â”‚   4. PREDICTIVE SCALING                                                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚   Uses ML to predict demand and scale proactively                      â”‚
â”‚   Best for cyclical patterns (daily, weekly)                           â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Auto Scaling Configuration (Terraform)

```hcl
# Auto Scaling Group
resource "aws_autoscaling_group" "web" {
  name                = "web-asg"
  vpc_zone_identifier = var.private_subnet_ids
  target_group_arns   = [aws_lb_target_group.web.arn]
  health_check_type   = "ELB"
  
  min_size         = 2
  max_size         = 10
  desired_capacity = 3
  
  launch_template {
    id      = aws_launch_template.web.id
    version = "$Latest"
  }
  
  instance_refresh {
    strategy = "Rolling"
    preferences {
      min_healthy_percentage = 50
    }
  }
  
  tag {
    key                 = "Name"
    value               = "web-server"
    propagate_at_launch = true
  }
}

# Target Tracking Policy
resource "aws_autoscaling_policy" "cpu" {
  name                   = "cpu-target-tracking"
  autoscaling_group_name = aws_autoscaling_group.web.name
  policy_type            = "TargetTrackingScaling"
  
  target_tracking_configuration {
    predefined_metric_specification {
      predefined_metric_type = "ASGAverageCPUUtilization"
    }
    target_value = 50.0
  }
}

# Scale on Request Count
resource "aws_autoscaling_policy" "requests" {
  name                   = "request-target-tracking"
  autoscaling_group_name = aws_autoscaling_group.web.name
  policy_type            = "TargetTrackingScaling"
  
  target_tracking_configuration {
    predefined_metric_specification {
      predefined_metric_type = "ALBRequestCountPerTarget"
      resource_label         = "${aws_lb.main.arn_suffix}/${aws_lb_target_group.web.arn_suffix}"
    }
    target_value = 1000.0  # 1000 requests per target
  }
}
```

---

## Cost Optimization

### Compute Cost Strategies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Compute Cost Optimization                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   1. RIGHT-SIZING (15-30% savings)                                      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚   â€¢ Use AWS Compute Optimizer recommendations                           â”‚
â”‚   â€¢ Monitor CloudWatch metrics (CPU, memory)                            â”‚
â”‚   â€¢ Downsize underutilized instances                                    â”‚
â”‚                                                                         â”‚
â”‚   Example:                                                              â”‚
â”‚   m5.xlarge (15% CPU avg) â†’ m5.large = 50% cost reduction             â”‚
â”‚                                                                         â”‚
â”‚   2. RESERVED + SAVINGS PLANS (30-72% savings)                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚   â€¢ Reserved Instances for steady-state                                 â”‚
â”‚   â€¢ Savings Plans for flexibility                                       â”‚
â”‚   â€¢ Cover 60-80% of baseline with commitments                          â”‚
â”‚                                                                         â”‚
â”‚   3. SPOT INSTANCES (60-90% savings)                                    â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚   Use for:                                                              â”‚
â”‚   âœ… CI/CD workers                                                      â”‚
â”‚   âœ… Batch processing                                                   â”‚
â”‚   âœ… Dev/test environments                                              â”‚
â”‚   âœ… Stateless web servers (behind ASG)                                 â”‚
â”‚                                                                         â”‚
â”‚   4. GRAVITON INSTANCES (40% better price/perf)                         â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚   â€¢ m7g, c7g, r7g instance families                                    â”‚
â”‚   â€¢ Most applications work without changes                              â”‚
â”‚                                                                         â”‚
â”‚   5. LAMBDA OPTIMIZATION                                                â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                â”‚
â”‚   â€¢ Right-size memory (affects CPU)                                     â”‚
â”‚   â€¢ Use Graviton (arm64) for 34% lower cost                            â”‚
â”‚   â€¢ Minimize cold starts                                                â”‚
â”‚                                                                         â”‚
â”‚   COMBINED STRATEGY EXAMPLE:                                            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â”‚
â”‚   Original: 10x m5.xlarge On-Demand = $1,382/month                     â”‚
â”‚                                                                         â”‚
â”‚   Optimized:                                                            â”‚
â”‚   â€¢ 4x m7g.large Reserved (60% base) = $230/month                      â”‚
â”‚   â€¢ 4x m7g.large Spot (30% variable) = $69/month                       â”‚
â”‚   â€¢ 2x m7g.large On-Demand (10% buffer) = $130/month                   â”‚
â”‚   Total: $429/month (69% savings!)                                     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Interview Questions

<AccordionGroup>
  <Accordion title="Q1: When would you choose Lambda over EC2?">
    **Lambda is better when:**
    - Event-driven, short-running tasks (< 15 min)
    - Unpredictable or spiky traffic
    - You want zero server management
    - Cost matters more than consistent latency
    
    **EC2 is better when:**
    - Long-running processes
    - Need specific OS/hardware (GPUs)
    - Consistent, predictable traffic
    - Cost optimization with Reserved Instances
    - Need persistent connections (WebSockets)
  </Accordion>
  
  <Accordion title="Q2: How do you reduce Lambda cold starts?">
    **Strategies:**
    1. **Provisioned Concurrency** - Pre-warm containers
    2. **Smaller packages** - Reduce initialization time
    3. **Initialize outside handler** - SDK clients, DB connections
    4. **Use lighter runtimes** - Go, Python, Node.js
    5. **SnapStart for Java** - Checkpoint/restore
    6. **Keep functions warm** - Scheduled pings (not ideal)
    
    **Code pattern:**
    ```python
    # Initialize OUTSIDE handler
    dynamodb = boto3.resource('dynamodb')
    table = dynamodb.Table(os.environ['TABLE'])
    
    def handler(event, context):
        # Only process logic here
        return table.get_item(...)
    ```
  </Accordion>
  
  <Accordion title="Q3: ECS vs EKS - when to use each?">
    **Choose ECS when:**
    - AWS-native, simpler setup
    - Smaller team without K8s expertise
    - Tighter AWS integration needed
    - Lower operational overhead
    
    **Choose EKS when:**
    - Multi-cloud strategy
    - Team has Kubernetes expertise
    - Need K8s ecosystem (Helm, operators)
    - Complex microservices architectures
    - Portability is important
    
    **Cost Note:** EKS adds $0.10/hour per cluster (~$72/month)
  </Accordion>
  
  <Accordion title="Q4: Design an auto-scaling strategy for an e-commerce site">
    **Multi-layered approach:**
    
    1. **Predictive Scaling**: Scale up before known peaks (Black Friday)
    2. **Target Tracking**: Maintain 50% CPU average
    3. **Step Scaling**: Add extra capacity for sudden spikes
    
    **Configuration:**
    - Minimum: 4 instances (2 per AZ)
    - Desired: 6 instances (normal load)
    - Maximum: 50 instances (peak capacity)
    
    **Policies:**
    - Target tracking: CPU at 50%
    - Step: +4 if CPU > 80% for 2 min
    - Scheduled: Scale to 20 at 8 AM, 10 at 10 PM
    - Predictive: Enable for daily patterns
    
    **Cool-downs:**
    - Scale-out: 60 seconds
    - Scale-in: 300 seconds (avoid thrashing)
  </Accordion>
  
  <Accordion title="Q5: How do you optimize EC2 costs?">
    **Framework (in order of impact):**
    
    1. **Right-size** (15-30% savings)
       - Use Compute Optimizer
       - Monitor actual utilization
    
    2. **Purchase options** (30-72% savings)
       - Reserved for baseline (60-70% of capacity)
       - Spot for stateless/batch
       - Savings Plans for flexibility
    
    3. **Instance selection** (20-40% savings)
       - Graviton (ARM) for compatible workloads
       - Latest generation (m7 vs m5)
    
    4. **Shutdown automation**
       - Stop dev/test outside hours
       - Auto-scaling to zero when possible
    
    5. **Regular review**
       - Monthly cost reviews
       - Tag-based cost allocation
  </Accordion>
</AccordionGroup>

---

## ğŸ§ª Hands-On Lab: Deploy Scalable Web App

**Objective**: Deploy a Node.js application with Auto Scaling and Load Balancing

<Steps>
  <Step title="Create Launch Template">
    Configure EC2 instance with user data for automatic setup
  </Step>
  
  <Step title="Create Auto Scaling Group">
    Set min=2, max=6, desired=3 across 2 AZs
  </Step>
  
  <Step title="Create Application Load Balancer">
    Configure health checks and target group
  </Step>
  
  <Step title="Configure Scaling Policies">
    Add target tracking (CPU 50%) and step scaling
  </Step>
  
  <Step title="Test Scaling">
    Generate load with `ab` or `hey` and watch scaling in action
  </Step>
</Steps>

---

## Next Module

<Card title="Storage & Databases" icon="hard-drive" href="/aws/storage-databases">
  Master S3, EBS, RDS, DynamoDB, and ElastiCache
</Card>
