---
title: "Demystifying Stateful Stream Processing: Flink's State Management Deep Dive"
sidebarTitle: "5. State & Timers"
description: "Master Flink's managed state - from research foundations to production patterns with RocksDB and checkpointing"
icon: "database"
---

# Demystifying Stateful Stream Processing: Flink's State Management

<Info>
**Module Duration**: 5-6 hours
**Focus**: Managed state, state backends, checkpointing, timers
**Prerequisites**: Flink Introduction, Java/Scala proficiency
**Hands-on Labs**: 10+ stateful applications
</Info>

## Introduction: Why State is the Hard Part

### The Fundamental Challenge

Stream processing without state is easy:
```java
stream.map(x -> x * 2)  // Stateless: Each event processed independently
```

But real applications need state:
```java
// "How many times have I seen this user?"
// "What was the user's previous action?"
// "What's the running average over the last hour?"
```

**The Problem**: State in distributed streaming systems is **exponentially harder** than batch:

| Challenge | Batch (MapReduce) | Streaming (Flink) |
|-----------|-------------------|-------------------|
| **Fault Tolerance** | Recompute from start | Continuous processing, can't restart |
| **Scale** | Static dataset | Unbounded data, growing state |
| **Consistency** | All-or-nothing | Exactly-once with continuous updates |
| **Latency** | Hours OK | Milliseconds required |

---

## Part 1: Research Foundation - State Management in Apache Flink

### The Seminal Paper

**Full Citation**:
Paris Carbone, Gyula Fóra, Stephan Ewen, Seif Haridi, and Kostas Tsoumakos. 2017. **"State Management in Apache Flink: Consistent Stateful Distributed Processing"**. Proceedings of the VLDB Endowment, Vol. 10, No. 12.

**Published**: VLDB 2017 (Very Large Data Bases) - Top-tier database conference

### The Authors: Flink's Core Team

- **Paris Carbone**: Research lead at KTH Royal Institute of Technology, core Flink committer
- **Stephan Ewen**: Co-founder of Apache Flink, CTO of Ververica (now Alibaba)
- **Gyula Fóra**: Flink PMC member, state backend expert
- **Seif Haridi**: Professor at KTH, distributed systems pioneer

**Background**: This wasn't speculative research - it documents Flink's **production-proven** state management system used by Alibaba, Uber, Netflix.

### Impact and Reception

**Citations**: 800+ (as of 2024)

**Industry Impact**:
- **Alibaba**: Largest Flink deployment (10,000+ nodes, petabytes of state)
- **Uber**: Real-time fraud detection with terabytes of state
- **Netflix**: Keystone platform with complex stateful pipelines
- **AWS**: Managed Flink (Kinesis Data Analytics) built on this foundation

**Why It Matters**:
Before Flink's approach, you had to choose:
- **Storm**: No state management (build your own)
- **Spark Streaming**: State with high latency (micro-batching)
- **Custom Solutions**: Maintain Cassandra/HBase (operational nightmare)

**Flink**: State is a **first-class citizen** with exactly-once guarantees and low latency.

---

## Part 2: Types of State in Flink

### Keyed State vs Operator State

```
┌─────────────────────────────────────────┐
│              Flink State                │
├──────────────────┬──────────────────────┤
│  Keyed State     │  Operator State      │
│  (partitioned)   │  (global)            │
├──────────────────┼──────────────────────┤
│ • ValueState     │ • ListState          │
│ • ListState      │ • UnionListState     │
│ • MapState       │ • BroadcastState     │
│ • ReducingState  │                      │
│ • AggregatingState                      │
└─────────────────────────────────────────┘
```

#### Keyed State (Most Common)

**Characteristics**:
- Partitioned by key (like a distributed HashMap)
- Each key has independent state
- Automatically distributed across task instances
- Accessed only within keyed streams

```java
DataStream<Event> stream = ...;

stream
    .keyBy(event -> event.userId)  // Partition by userId
    .flatMap(new CountPerUserFunction());  // Each userId has independent counter

// User "alice" → Task Instance 1 → State: {count: 42}
// User "bob"   → Task Instance 2 → State: {count: 18}
// User "carol" → Task Instance 1 → State: {count: 91}
```

**When to Use**: Most stateful operations (counts, aggregations, sessionization, user profiles).

#### Operator State (Advanced)

**Characteristics**:
- Shared across all events processed by an operator instance
- NOT partitioned by key
- Used for source/sink state, broadcast state

```java
// Example: Kafka source maintains offset state
// Each Kafka partition's offset is operator state
FlinkKafkaConsumer<String> consumer = new FlinkKafkaConsumer<>(...);
// Internally maintains: Map<TopicPartition, Long> offsets
```

**When to Use**: Source/sink connectors, broadcast patterns, global configuration.

---

## Part 3: Keyed State Primitives (The Full Arsenal)

### 1. ValueState&lt;T&gt; - Single Value Per Key

**Use Case**: Store one value per key (counter, flag, last seen value).

```java
public class UserSessionTracker extends RichFlatMapFunction<Event, Alert> {
    private transient ValueState<Long> lastSeenTime;

    @Override
    public void open(Configuration config) {
        ValueStateDescriptor<Long> descriptor =
            new ValueStateDescriptor<>("lastSeenTime", Long.class);
        lastSeenTime = getRuntimeContext().getState(descriptor);
    }

    @Override
    public void flatMap(Event event, Collector<Alert> out) throws Exception {
        Long previousTime = lastSeenTime.value();

        if (previousTime != null) {
            long timeSinceLastEvent = event.timestamp - previousTime;
            if (timeSinceLastEvent > 3600000) {  // 1 hour gap
                out.collect(new Alert("User inactive for " + timeSinceLastEvent + "ms"));
            }
        }

        lastSeenTime.update(event.timestamp);
    }
}
```

**Memory**: One value per key (fixed size per key).

### 2. ListState&lt;T&gt; - List of Values Per Key

**Use Case**: Collect multiple values per key (buffering, windowing).

```java
public class BufferEventsFunction extends RichFlatMapFunction<Event, List<Event>> {
    private transient ListState<Event> bufferedEvents;

    @Override
    public void open(Configuration config) {
        ListStateDescriptor<Event> descriptor =
            new ListStateDescriptor<>("bufferedEvents", Event.class);
        bufferedEvents = getRuntimeContext().getListState(descriptor);
    }

    @Override
    public void flatMap(Event event, Collector<List<Event>> out) throws Exception {
        bufferedEvents.add(event);

        // Emit when buffer reaches 100 events
        List<Event> events = new ArrayList<>();
        for (Event e : bufferedEvents.get()) {
            events.add(e);
        }

        if (events.size() >= 100) {
            out.collect(events);
            bufferedEvents.clear();
        }
    }
}
```

**Memory**: Variable size per key (can grow unbounded - use TTL!).

### 3. MapState&lt;UK, UV&gt; - Key-Value Map Per Key

**Use Case**: Store structured data per key (feature maps, aggregations by sub-key).

```java
public class FeatureAggregator extends RichFlatMapFunction<Event, FeatureVector> {
    // MapState: userId -> Map<featureName, featureValue>
    private transient MapState<String, Double> features;

    @Override
    public void open(Configuration config) {
        MapStateDescriptor<String, Double> descriptor =
            new MapStateDescriptor<>("features", String.class, Double.class);
        features = getRuntimeContext().getMapState(descriptor);
    }

    @Override
    public void flatMap(Event event, Collector<FeatureVector> out) throws Exception {
        // Update feature
        features.put(event.featureName, event.featureValue);

        // When ready, emit feature vector
        if (features.contains("all_features_present")) {
            Map<String, Double> featureMap = new HashMap<>();
            for (Map.Entry<String, Double> entry : features.entries()) {
                featureMap.put(entry.getKey(), entry.getValue());
            }
            out.collect(new FeatureVector(featureMap));
            features.clear();
        }
    }
}
```

**Real-World Example**: User profile with multiple attributes.
```java
// For userId "alice":
features.put("total_purchases", 42.0);
features.put("avg_cart_value", 156.78);
features.put("last_login_days_ago", 2.0);
```

### 4. ReducingState&lt;T&gt; - Aggregated Value with Custom Logic

**Use Case**: Maintain running aggregation (sum, min, max, custom).

```java
public class RunningMaxTracker extends RichFlatMapFunction<Tuple2<String, Integer>, Tuple2<String, Integer>> {
    private transient ReducingState<Integer> maxValue;

    @Override
    public void open(Configuration config) {
        ReducingStateDescriptor<Integer> descriptor =
            new ReducingStateDescriptor<>("maxValue",
                (a, b) -> Math.max(a, b),  // Reduce function
                Integer.class);
        maxValue = getRuntimeContext().getReducingState(descriptor);
    }

    @Override
    public void flatMap(Tuple2<String, Integer> value, Collector<Tuple2<String, Integer>> out) throws Exception {
        maxValue.add(value.f1);
        out.collect(Tuple2.of(value.f0, maxValue.get()));
    }
}

// Input:  ("user1", 10), ("user1", 25), ("user1", 15)
// Output: ("user1", 10), ("user1", 25), ("user1", 25)  // Running max
```

### 5. AggregatingState&lt;IN, OUT, ACC&gt; - Complex Aggregations

**Use Case**: Maintain complex aggregations (average, variance, histograms).

```java
public class AverageAggregator extends RichFlatMapFunction<Tuple2<String, Double>, Tuple2<String, Double>> {
    private transient AggregatingState<Double, Double> average;

    @Override
    public void open(Configuration config) {
        AggregatingStateDescriptor<Double, Tuple2<Double, Long>, Double> descriptor =
            new AggregatingStateDescriptor<>(
                "average",
                new AverageAggregateFunction(),
                new TypeHint<Tuple2<Double, Long>>(){}.getTypeInfo()
            );
        average = getRuntimeContext().getAggregatingState(descriptor);
    }

    @Override
    public void flatMap(Tuple2<String, Double> value, Collector<Tuple2<String, Double>> out) throws Exception {
        average.add(value.f1);
        out.collect(Tuple2.of(value.f0, average.get()));
    }

    public static class AverageAggregateFunction implements AggregateFunction<Double, Tuple2<Double, Long>, Double> {
        @Override
        public Tuple2<Double, Long> createAccumulator() {
            return Tuple2.of(0.0, 0L);  // (sum, count)
        }

        @Override
        public Tuple2<Double, Long> add(Double value, Tuple2<Double, Long> accumulator) {
            return Tuple2.of(accumulator.f0 + value, accumulator.f1 + 1);
        }

        @Override
        public Double getResult(Tuple2<Double, Long> accumulator) {
            return accumulator.f0 / accumulator.f1;
        }

        @Override
        public Tuple2<Double, Long> merge(Tuple2<Double, Long> a, Tuple2<Double, Long> b) {
            return Tuple2.of(a.f0 + b.f0, a.f1 + b.f1);
        }
    }
}
```

---

## Part 4: State Time-To-Live (TTL) - Preventing State Explosion

### The Problem

```java
// WITHOUT TTL: State grows forever
MapState<String, UserProfile> userProfiles;
// After 1 year: Billions of users, hundreds of GB of state
// Even for users who haven't been active in months!
```

**Consequence**: Out-of-memory errors, slow checkpoints, expensive storage.

### The Solution: State TTL

```java
public class UserProfileWithTTL extends RichFlatMapFunction<Event, UserProfile> {
    private transient ValueState<UserProfile> profile;

    @Override
    public void open(Configuration config) {
        // Configure TTL: 30 days of inactivity
        StateTtlConfig ttlConfig = StateTtlConfig
            .newBuilder(Time.days(30))
            .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)  // Reset TTL on update
            .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
            .cleanupFullSnapshot()  // Clean on checkpoint
            .build();

        ValueStateDescriptor<UserProfile> descriptor =
            new ValueStateDescriptor<>("profile", UserProfile.class);
        descriptor.enableTimeToLive(ttlConfig);

        profile = getRuntimeContext().getState(descriptor);
    }

    @Override
    public void flatMap(Event event, Collector<UserProfile> out) throws Exception {
        UserProfile currentProfile = profile.value();

        if (currentProfile == null) {
            currentProfile = new UserProfile(event.userId);
        }

        currentProfile.update(event);
        profile.update(currentProfile);
        out.collect(currentProfile);
    }
}
```

### TTL Configuration Options

```java
StateTtlConfig ttlConfig = StateTtlConfig
    .newBuilder(Time.days(7))

    // When to reset TTL
    .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)  // Default
    // or: OnReadAndWrite (reset on access)

    // What to return for expired state
    .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)  // Default
    // or: ReturnExpiredIfNotCleanedUp (if cleanup hasn't run yet)

    // Cleanup strategies
    .cleanupFullSnapshot()  // Cleanup during checkpoints (blocks checkpointing!)
    // or:
    .cleanupIncrementally(1000, true)  // Cleanup 1000 entries per access (recommended)
    // or:
    .cleanupInRocksdbCompactFilter(1000)  // RocksDB-specific cleanup

    .build();
```

**Recommendation for Production**:
```java
StateTtlConfig ttlConfig = StateTtlConfig
    .newBuilder(Time.days(30))
    .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
    .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
    .cleanupIncrementally(10000, true)  // Incremental cleanup, no checkpoint blocking
    .build();
```

---

## Part 5: Timers - Scheduling Future Actions

### Process Functions with Timers

Timers allow you to schedule future callbacks based on **event time** or **processing time**.

#### Example: Session Windows with Timers

```java
public class SessionWindowFunction extends KeyedProcessFunction<String, Event, SessionSummary> {
    private ValueState<List<Event>> sessionEvents;
    private ValueState<Long> sessionEnd;

    @Override
    public void open(Configuration config) {
        sessionEvents = getRuntimeContext().getState(
            new ValueStateDescriptor<>("session", new TypeHint<List<Event>>(){}.getTypeInfo())
        );
        sessionEnd = getRuntimeContext().getState(
            new ValueStateDescriptor<>("sessionEnd", Long.class)
        );
    }

    @Override
    public void processElement(Event event, Context ctx, Collector<SessionSummary> out) throws Exception {
        List<Event> events = sessionEvents.value();
        if (events == null) {
            events = new ArrayList<>();
        }
        events.add(event);
        sessionEvents.update(events);

        // Session timeout: 30 minutes of inactivity
        long newSessionEnd = event.timestamp + 1800000;  // 30 min

        // Delete old timer if exists
        Long oldSessionEnd = sessionEnd.value();
        if (oldSessionEnd != null) {
            ctx.timerService().deleteEventTimeTimer(oldSessionEnd);
        }

        // Register new timer
        ctx.timerService().registerEventTimeTimer(newSessionEnd);
        sessionEnd.update(newSessionEnd);
    }

    @Override
    public void onTimer(long timestamp, OnTimerContext ctx, Collector<SessionSummary> out) throws Exception {
        // Timer fired: Session ended
        List<Event> events = sessionEvents.value();

        SessionSummary summary = new SessionSummary(
            ctx.getCurrentKey(),
            events.size(),
            events.get(0).timestamp,
            events.get(events.size() - 1).timestamp
        );

        out.collect(summary);

        // Clean up state
        sessionEvents.clear();
        sessionEnd.clear();
    }
}
```

**How It Works**:
```
10:00:00 - User action → Set timer for 10:30:00
10:15:00 - User action → Delete 10:30:00 timer, set timer for 10:45:00
10:20:00 - User action → Delete 10:45:00 timer, set timer for 10:50:00
10:50:00 - Timer fires → Emit session summary, clear state
```

#### Processing Time vs Event Time Timers

```java
// Event Time Timer (watermark-based)
ctx.timerService().registerEventTimeTimer(targetTimestamp);
// Fires when: watermark >= targetTimestamp

// Processing Time Timer (wall-clock based)
ctx.timerService().registerProcessingTimeTimer(System.currentTimeMillis() + 60000);
// Fires after: 60 seconds of processing time
```

**Use Cases**:
- **Event Time Timers**: Session timeouts, delayed aggregations, late data handling
- **Processing Time Timers**: Heartbeats, periodic flushes, cache expiration

---

## Part 6: State Backends - Where State Lives

### The Three State Backends

```
┌─────────────────────────────────────────────────┐
│           Flink State Backends                  │
├──────────────┬──────────────┬───────────────────┤
│  MemoryState │  FsState     │  RocksDBState     │
│  Backend     │  Backend     │  Backend          │
├──────────────┼──────────────┼───────────────────┤
│ • Heap       │ • Heap       │ • Off-heap        │
│ • Small      │ • Medium     │ • Large           │
│ • Fast       │ • Fast       │ • Slower but      │
│ • JVM GC     │ • JVM GC     │   GC-free         │
│ • Dev only   │ • Production │ • Production      │
│              │   (< 10 GB)  │   (TBs)           │
└──────────────┴──────────────┴───────────────────┘
```

### 1. MemoryStateBackend (Development)

```java
env.setStateBackend(new MemoryStateBackend());
```

**Characteristics**:
- State stored in Java heap
- Checkpoints stored in JobManager memory
- **Max state size**: Heap size (~GB)
- **Max checkpoint size**: 5 MB (default)

**Use Case**: Local development, testing, demos.

**Do NOT use in production!**

### 2. FsStateBackend (Small-Medium Production)

```java
env.setStateBackend(new FsStateBackend("hdfs://namenode:9000/flink/checkpoints"));
// or S3:
env.setStateBackend(new FsStateBackend("s3://my-bucket/flink/checkpoints"));
```

**Characteristics**:
- State stored in Java heap (working state)
- Checkpoints stored in distributed filesystem (HDFS, S3)
- **Max state size**: Heap size (~10-50 GB per TaskManager)
- **Checkpoint size**: Unlimited (stored in FS)

**Use Case**: Production with moderate state (< 10 GB per TaskManager).

**Pros**:
- Fast access (heap-based)
- Simple setup

**Cons**:
- JVM garbage collection pressure
- Limited by heap size

### 3. RocksDBStateBackend (Large Production)

```java
env.setStateBackend(new RocksDBStateBackend("s3://my-bucket/flink/checkpoints"));
```

**Characteristics**:
- State stored in **RocksDB** (embedded key-value store)
- RocksDB stores data **off-heap** (native memory)
- **Max state size**: Disk size (TBs)
- **Checkpoint size**: Unlimited

**Use Case**: Production with large state (TBs per TaskManager).

**Pros**:
- No JVM GC pressure (off-heap)
- Scales to TBs of state
- Incremental checkpointing (fast)

**Cons**:
- Slower access than heap (serialization overhead)
- Requires native library

#### RocksDB Configuration (Performance Tuning)

```java
RocksDBStateBackend rocksDB = new RocksDBStateBackend("s3://bucket/checkpoints", true);

// Enable incremental checkpointing (CRITICAL for large state)
rocksDB.enableIncrementalCheckpointing(true);

// Tune RocksDB options
rocksDB.setOptions(new OptionsFactory() {
    @Override
    public DBOptions createDBOptions(DBOptions currentOptions) {
        return currentOptions
            .setMaxBackgroundJobs(4)        // Parallel compaction
            .setMaxOpenFiles(-1);           // Unlimited open files
    }

    @Override
    public ColumnFamilyOptions createColumnOptions(ColumnFamilyOptions currentOptions) {
        return currentOptions
            .setCompactionStyle(CompactionStyle.LEVEL)
            .setWriteBufferSize(64 * 1024 * 1024)  // 64 MB write buffer
            .setMaxWriteBufferNumber(3);
    }
});

env.setStateBackend(rocksDB);
```

**Production Recommendation**:
```java
// For state > 1 GB: Use RocksDB with incremental checkpointing
RocksDBStateBackend backend = new RocksDBStateBackend("s3://bucket/checkpoints", true);
backend.enableIncrementalCheckpointing(true);
env.setStateBackend(backend);
```

---

## Part 7: Checkpointing - Fault Tolerance in Action

### What is Checkpointing?

From the paper "Lightweight Asynchronous Snapshots for Distributed Dataflows" (Carbone et al.):

> "A checkpoint is a consistent snapshot of the distributed state of a Flink job, capturing the state of all operators and the position in the input streams."

**In Practice**: Periodically save state to durable storage so on failure, you can resume from the last checkpoint.

### Enabling Checkpointing

```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

// Enable checkpointing every 60 seconds
env.enableCheckpointing(60000);

// Checkpoint configuration
env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
env.getCheckpointConfig().setMinPauseBetweenCheckpoints(30000);  // 30s between checkpoints
env.getCheckpointConfig().setCheckpointTimeout(600000);  // 10 min timeout
env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);  // One at a time
env.getCheckpointConfig().enableExternalizedCheckpoints(
    ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION  // Keep checkpoints on cancel
);

// Optional: Unaligned checkpoints (faster, more storage)
env.getCheckpointConfig().enableUnalignedCheckpoints();
```

### Checkpoint Modes

#### 1. Exactly-Once (Default)

```java
env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
```

**Guarantees**: Each event affects state exactly once, even with failures.

**Mechanism**: Aligns barriers across all input streams before checkpointing.

**Use Case**: Most applications (correctness critical).

#### 2. At-Least-Once (Faster, Less Safe)

```java
env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.AT_LEAST_ONCE);
```

**Guarantees**: Events may be processed multiple times after failure.

**Mechanism**: No barrier alignment, checkpoints faster.

**Use Case**: High-throughput, idempotent operations.

### Incremental Checkpointing (RocksDB Only)

```java
RocksDBStateBackend backend = new RocksDBStateBackend("s3://bucket/checkpoints", true);
backend.enableIncrementalCheckpointing(true);  // Only checkpoint changes
env.setStateBackend(backend);
```

**How It Works**:
```
Checkpoint 1: Full state (10 GB)
Checkpoint 2: Delta since checkpoint 1 (100 MB)
Checkpoint 3: Delta since checkpoint 2 (150 MB)
...
```

**Benefit**: For large state (> 1 GB), incremental checkpoints are **10-100x faster**.

**Trade-off**: Slightly slower recovery (must replay deltas).

---

## Part 8: Real-World Patterns

### Pattern 1: Fraud Detection with State

```java
public class FraudDetector extends KeyedProcessFunction<String, Transaction, Alert> {
    private ValueState<FraudProfile> profile;
    private ListState<Transaction> recentTransactions;

    @Override
    public void open(Configuration config) {
        ValueStateDescriptor<FraudProfile> profileDesc =
            new ValueStateDescriptor<>("profile", FraudProfile.class);
        profileDesc.enableTimeToLive(StateTtlConfig.newBuilder(Time.days(90)).build());
        profile = getRuntimeContext().getState(profileDesc);

        ListStateDescriptor<Transaction> txnDesc =
            new ListStateDescriptor<>("recentTxns", Transaction.class);
        txnDesc.enableTimeToLive(StateTtlConfig.newBuilder(Time.hours(24)).build());
        recentTransactions = getRuntimeContext().getListState(txnDesc);
    }

    @Override
    public void processElement(Transaction txn, Context ctx, Collector<Alert> out) throws Exception {
        FraudProfile prof = profile.value();
        if (prof == null) {
            prof = new FraudProfile(txn.userId);
        }

        // Rule 1: Velocity check (> 5 transactions in 10 minutes)
        List<Transaction> recent = new ArrayList<>();
        for (Transaction t : recentTransactions.get()) {
            if (txn.timestamp - t.timestamp < 600000) {  // 10 min
                recent.add(t);
            }
        }
        if (recent.size() >= 5) {
            out.collect(new Alert("Velocity fraud: " + recent.size() + " txns in 10 min"));
        }

        // Rule 2: Amount spike (> 10x average)
        double avgAmount = prof.getAverageAmount();
        if (txn.amount > avgAmount * 10) {
            out.collect(new Alert("Amount spike: " + txn.amount + " vs avg " + avgAmount));
        }

        // Update state
        prof.addTransaction(txn);
        profile.update(prof);
        recentTransactions.add(txn);
    }
}
```

### Pattern 2: User Session Aggregation

```java
public class SessionAggregator extends KeyedProcessFunction<String, Event, SessionStats> {
    private MapState<String, Integer> eventCounts;  // eventType -> count
    private ValueState<Long> sessionStart;
    private ValueState<Long> sessionTimer;

    @Override
    public void open(Configuration config) {
        eventCounts = getRuntimeContext().getMapState(
            new MapStateDescriptor<>("eventCounts", String.class, Integer.class)
        );
        sessionStart = getRuntimeContext().getState(
            new ValueStateDescriptor<>("sessionStart", Long.class)
        );
        sessionTimer = getRuntimeContext().getState(
            new ValueStateDescriptor<>("timer", Long.class)
        );
    }

    @Override
    public void processElement(Event event, Context ctx, Collector<SessionStats> out) throws Exception {
        // Initialize session
        if (sessionStart.value() == null) {
            sessionStart.update(event.timestamp);
        }

        // Update event counts
        Integer count = eventCounts.get(event.type);
        eventCounts.put(event.type, (count == null ? 0 : count) + 1);

        // Reset session timer (30 min inactivity)
        Long oldTimer = sessionTimer.value();
        if (oldTimer != null) {
            ctx.timerService().deleteEventTimeTimer(oldTimer);
        }
        long newTimer = event.timestamp + 1800000;  // 30 min
        ctx.timerService().registerEventTimeTimer(newTimer);
        sessionTimer.update(newTimer);
    }

    @Override
    public void onTimer(long timestamp, OnTimerContext ctx, Collector<SessionStats> out) throws Exception {
        // Session ended
        Map<String, Integer> counts = new HashMap<>();
        for (Map.Entry<String, Integer> entry : eventCounts.entries()) {
            counts.put(entry.getKey(), entry.getValue());
        }

        SessionStats stats = new SessionStats(
            ctx.getCurrentKey(),
            sessionStart.value(),
            timestamp - 1800000,  // Actual session end
            counts
        );
        out.collect(stats);

        // Clear state
        eventCounts.clear();
        sessionStart.clear();
        sessionTimer.clear();
    }
}
```

### Pattern 3: Deduplication with State

```java
public class Deduplicator extends RichFlatMapFunction<Event, Event> {
    private ValueState<Boolean> seen;

    @Override
    public void open(Configuration config) {
        ValueStateDescriptor<Boolean> descriptor =
            new ValueStateDescriptor<>("seen", Boolean.class);

        // TTL: Keep seen IDs for 24 hours
        descriptor.enableTimeToLive(
            StateTtlConfig.newBuilder(Time.hours(24))
                .cleanupIncrementally(1000, true)
                .build()
        );

        seen = getRuntimeContext().getState(descriptor);
    }

    @Override
    public void flatMap(Event event, Collector<Event> out) throws Exception {
        if (seen.value() == null) {
            seen.update(true);
            out.collect(event);  // First time seeing this ID
        }
        // Else: Duplicate, drop it
    }
}

// Usage
stream
    .keyBy(event -> event.id)  // Partition by event ID
    .flatMap(new Deduplicator())
    .print();
```

---

## Part 9: Performance Optimization

### State Access Patterns (DO's and DON'Ts)

#### ❌ BAD: Multiple State Accesses

```java
// INEFFICIENT: 3 state accesses per event
public void processElement(Event event) throws Exception {
    Long count = counter.value();  // Access 1
    counter.update(count + 1);     // Access 2

    Long sum = total.value();      // Access 3
    total.update(sum + event.value);  // Access 4 (IMPLICIT)
}
```

#### ✅ GOOD: Batch State Access

```java
// EFFICIENT: Minimal state access
public void processElement(Event event) throws Exception {
    // Access all state at once
    Long count = counter.value();
    Long sum = total.value();

    // Update in-memory
    count += 1;
    sum += event.value;

    // Write back
    counter.update(count);
    total.update(sum);
}
```

### State Size Monitoring

```java
public class StateMonitorFunction extends RichFlatMapFunction<Event, Event> {
    private transient Counter stateSizeGauge;

    @Override
    public void open(Configuration config) {
        stateSizeGauge = getRuntimeContext()
            .getMetricGroup()
            .counter("state_size_bytes");
    }

    @Override
    public void flatMap(Event event, Collector<Event> out) throws Exception {
        // Track state growth
        stateSizeGauge.inc(estimateEventSize(event));

        // Process event
        out.collect(event);
    }
}
```

**Monitor via Flink UI** → Metrics → state.backend.*

---

## Part 10: Interview Questions

### Conceptual

**Q1: What's the difference between keyed state and operator state?**

**A**:
- **Keyed state**: Partitioned by key, each key has independent state (e.g., `ValueState<T>`). Used for most stateful operations.
- **Operator state**: Shared across all events in an operator instance, not partitioned (e.g., Kafka offsets). Used for sources/sinks.

**Q2: Explain state TTL. When would you use it?**

**A**:
State TTL automatically expires state after inactivity. Use it to:
- Prevent state from growing unbounded
- Remove stale user sessions
- Comply with data retention policies (GDPR)

**Q3: What's the difference between MemoryStateBackend and RocksDBStateBackend?**

**A**:
- **MemoryStateBackend**: Heap-based, fast, limited to ~GB. For development.
- **RocksDBStateBackend**: Off-heap (RocksDB), slower, scales to TBs. For production with large state.

**Q4: What is incremental checkpointing? Why is it important?**

**A**:
Incremental checkpointing (RocksDB only) saves only state changes since last checkpoint, not full state. Critical for large state (> 1 GB) to avoid long checkpoint times (which block processing).

### Coding

**Q: Implement a function that counts events per key and emits count every 100 events.**

```java
public class CountAndEmit extends RichFlatMapFunction<Event, Tuple2<String, Long>> {
    private ValueState<Long> count;

    @Override
    public void open(Configuration config) {
        count = getRuntimeContext().getState(
            new ValueStateDescriptor<>("count", Long.class, 0L)
        );
    }

    @Override
    public void flatMap(Event event, Collector<Tuple2<String, Long>> out) throws Exception {
        long currentCount = count.value() + 1;
        count.update(currentCount);

        if (currentCount % 100 == 0) {
            out.collect(Tuple2.of(event.key, currentCount));
        }
    }
}
```

---

## Summary

### What You've Mastered

✅ State types (keyed vs operator)
✅ State primitives (ValueState, ListState, MapState, ReducingState, AggregatingState)
✅ State TTL (preventing state explosion)
✅ Timers (event-time and processing-time)
✅ State backends (Memory, Fs, RocksDB)
✅ Checkpointing (exactly-once, incremental)
✅ Real-world patterns (fraud detection, sessions, deduplication)
✅ Performance optimization

### Key Takeaways

1. **State is a First-Class Citizen**: Flink's managed state is its superpower
2. **Choose the Right Backend**: RocksDB for > 1 GB state
3. **Always Use TTL**: Prevent unbounded state growth
4. **Incremental Checkpoints**: Essential for large state
5. **Timers Enable Complex Logic**: Sessions, delayed actions, timeouts

---

## Next Module

<Card
  title="Module 6: Table API & Flink SQL"
  icon="table"
  href="/distributed-systems-tools/flink-sql"
>
  Declarative stream processing with SQL
</Card>

---

## Resources

### Papers
- ["State Management in Apache Flink"](http://www.vldb.org/pvldb/vol10/p1718-carbone.pdf) (Carbone et al., VLDB 2017)
- ["Lightweight Asynchronous Snapshots"](https://arxiv.org/abs/1506.08603) (Carbone et al., 2015)

### Documentation
- [Flink State Backends](https://nightlies.apache.org/flink/flink-docs-stable/docs/ops/state/state_backends/)
- [Checkpointing](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/datastream/fault-tolerance/checkpointing/)

<Info>
**Practice**: Build a stateful fraud detection system with 3+ rules, state TTL, and RocksDB backend. Deploy on a cluster and test failure recovery!
</Info>
