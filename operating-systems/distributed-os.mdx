---
title: "Distributed Operating Systems"
sidebarTitle: "Distributed OS"
description: "Distributed Shared Memory, RPC, DFS, and Logical Clocks"
icon: "network-wired"
---

# Distributed Operating Systems

A **Distributed Operating System (DOS)** manages a collection of independent computers and makes them appear to the users of the system as a single, coherent computer.

<Info>
**Interview Frequency**: High (System Design & OS overlap)
**Key Topics**: RPC, Distributed Shared Memory, Lamport Clocks, CAP Theorem
**Time to Master**: 10-12 hours
</Info>

---

## Remote Procedure Call (RPC)

RPC is the fundamental building block of distributed systems. It allows a program to execute a procedure on a remote address space as if it were a local procedure call.

### RPC Flow
1. **Client Stub**: Marshals arguments into a message.
2. **Network Transport**: Sends message to server.
3. **Server Stub**: Unmarshals arguments.
4. **Server Implementation**: Executes the function.
5. **Return**: Result travels back the reverse path.

![RPC Flow](/images/courses/rpc-flow.svg)

### Challenges
- **Failure Modes**: Partial failures (network down, server crash).
- **Semantics**:
    - **At-least-once**: Operation might happen multiple times (idempotency required).
    - **At-most-once**: Operation happens 0 or 1 time.
    - **Exactly-once**: Hard to achieve (requires heavy coordination).

---

## Distributed Shared Memory (DSM)

DSM provides the illusion of a shared physical memory space across physically separated computers.

### Architecture
- **Page-based DSM**: Similar to virtual memory. If a page is not local, a "page fault" triggers a network request to fetch it.
- **Consistency Models**:
    - **Strict Consistency**: Read returns most recent write (impossible in practice due to latency).
    - **Sequential Consistency**: Operations appear in some sequential order consistent with program order.
    - **Release Consistency**: Synchronization variables (locks) control visibility.

![DSM Architecture](/images/courses/dsm-architecture.svg)

---

## Distributed File Systems (DFS)

### Network File System (NFS)
- **Stateless Server**: Server doesn't track open files (robust to crashes).
- **Caching**: Clients cache file blocks.
- **Consistency**: "Close-to-open" consistency (changes visible after file close).

### Andrew File System (AFS)
- **Stateful**: Server tracks callbacks.
- **Whole-file caching**: Entire file downloaded to local disk.
- **Scalability**: Higher than NFS due to reduced server load.

---

## Clock Synchronization

In distributed systems, there is no global clock. We rely on **Logical Clocks** to order events.

### Lamport Timestamps
A simple counter to determine "happens-before" relationship ($a \to b$).
1. Increment counter before each event.
2. Send counter with message.
3. Receiver sets `counter = max(local_counter, msg_counter) + 1`.

![Lamport Clock](/images/courses/lamport-clock.svg)

### Vector Clocks
An array of counters (one per node) to detect **concurrency**.
- If $V(a) < V(b)$, then $a \to b$.
- If neither $V(a) < V(b)$ nor $V(b) < V(a)$, events are **concurrent**.

---

## Interview Deep Dive Questions

<AccordionGroup>
  <Accordion title="Q1: How does NFS handle server crashes?">
    **Answer:**
    NFS (v3) servers are **stateless**.
    - They don't keep track of which clients have files open.
    - Each request (READ/WRITE) contains all necessary info (file handle, offset).
    - If server crashes and reboots, clients just retry the request until it succeeds.
    - **Trade-off**: Locking is difficult (requires separate stateful Lock Manager).
  </Accordion>

  <Accordion title="Q2: Explain the difference between 'At-least-once' and 'At-most-once' RPC.">
    **Answer:**
    - **At-least-once**: Client retries until it gets a response.
        - Risk: Server might execute operation twice (e.g., deduct money twice).
        - Solution: Idempotent operations ($x = 5$ is safe, $x++$ is not).
    - **At-most-once**: Server tracks request IDs and rejects duplicates.
        - Risk: Request might be lost and never executed.
        - Use case: Non-idempotent operations where safety > liveness.
  </Accordion>

  <Accordion title="Q3: Why is 'Strict Consistency' impossible in distributed systems?">
    **Answer:**
    Strict consistency implies that a write is **instantaneously** visible to all nodes.
    - Speed of light limit ($c$) prevents instant communication.
    - If Node A writes $x=1$ at $t=0$, Node B (1000km away) cannot see it until $t > 3.3ms$.
    - We must settle for weaker models like Sequential or Eventual Consistency.
  </Accordion>
</AccordionGroup>
