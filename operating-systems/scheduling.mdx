---
title: "CPU Scheduling"
sidebarTitle: "Scheduling"
description: "Scheduling algorithms, CFS, real-time scheduling, and multi-core considerations"
icon: "clock"
---

# CPU Scheduling

The **CPU scheduler** decides which process/thread runs when, for how long, and on which CPU. Understanding scheduling is essential for performance optimization and is a frequent interview topic for systems roles.

<Info>
**Interview Frequency**: High  
**Key Topics**: Scheduling algorithms, CFS, real-time, multi-core  
**Time to Master**: 8-10 hours
</Info>

---

## Scheduling Goals

Different workloads have different priorities:

| Metric | Definition | Important For |
|--------|------------|---------------|
| **CPU Utilization** | % time CPU is busy | Maximizing throughput |
| **Throughput** | Jobs completed per time | Batch systems |
| **Turnaround Time** | Submit → Complete | Batch jobs |
| **Response Time** | Submit → First response | Interactive systems |
| **Waiting Time** | Time spent in ready queue | Fairness |
| **Fairness** | Equal CPU distribution | Multi-tenant |

<Warning>
**Trade-offs are inevitable!** Optimizing for throughput hurts response time. Optimizing for fairness may hurt throughput.
</Warning>

---

## When Does Scheduling Happen?

Scheduling decisions occur at these points:

```
┌─────────────────────────────────────────────────────────────────┐
│                     SCHEDULING TRIGGERS                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  1. Process terminates (exit)                                   │
│     └─ MUST schedule: running process is gone                  │
│                                                                  │
│  2. Process blocks (I/O, wait, sleep)                          │
│     └─ MUST schedule: running process can't continue           │
│                                                                  │
│  3. Process becomes ready (I/O complete, created)               │
│     └─ CAN schedule: might preempt current process             │
│                                                                  │
│  4. Timer interrupt (time slice expires)                        │
│     └─ CAN schedule: preemptive systems only                   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### Non-Preemptive vs Preemptive

| Type | When Context Switch Occurs | Examples |
|------|---------------------------|----------|
| **Non-preemptive** | Only on block/terminate | Old batch systems, Windows 3.1 |
| **Preemptive** | Also on timer, higher priority arrival | All modern OS |

---

## Classic Scheduling Algorithms

### First-Come, First-Served (FCFS)

The simplest algorithm: run processes in arrival order.

```
Process  | Arrival | Burst Time
---------|---------|------------
   P1    |    0    |     24
   P2    |    0    |      3
   P3    |    0    |      3

Timeline:
├─────────── P1 (24) ───────────┤── P2 ──┤── P3 ──┤
0                               24       27       30

Waiting times: P1=0, P2=24, P3=27
Average waiting time: (0 + 24 + 27) / 3 = 17
```

<Warning>
**Convoy Effect**: Short processes stuck behind long ones. If P2, P3 ran first: average wait = (0 + 3 + 6) / 3 = 3
</Warning>

### Shortest Job First (SJF)

Run the process with shortest burst time:

```
Process  | Arrival | Burst Time
---------|---------|------------
   P1    |    0    |      7
   P2    |    2    |      4
   P3    |    4    |      1
   P4    |    5    |      4

Non-preemptive SJF:
├─── P1 (7) ───┤── P3 ──┤──── P2 ────┤──── P4 ────┤
0              7        8           12           16

Preemptive SJF (SRTF - Shortest Remaining Time First):
├─ P1 ─┤─ P2 ─┤P3┤── P2 ──┤── P4 ──┤─── P1 ───┤
0      2      4  5        7       11          16
```

**Problem**: How do you know burst time in advance? 
**Solution**: Predict based on history (exponential averaging)

```
τₙ₊₁ = α × tₙ + (1 - α) × τₙ

where:
  tₙ = actual time of last burst
  τₙ = predicted time of last burst
  α  = weight (typically 0.5)
```

### Priority Scheduling

Each process has a priority; highest priority runs first:

```c
// Lower number = higher priority (typical convention)
struct process {
    int pid;
    int priority;
    int burst_time;
};

// Priority assignment factors:
// - Static: user-defined, process type
// - Dynamic: aging, I/O behavior, CPU usage
```

**Starvation Problem**: Low-priority processes may never run.

**Solution - Aging**: Increase priority of waiting processes over time.

```c
void age_priorities(Process *ready_queue, int count) {
    for (int i = 0; i < count; i++) {
        ready_queue[i].priority += ready_queue[i].wait_time / AGING_FACTOR;
    }
}
```

### Round Robin (RR)

Each process gets a fixed time quantum, then goes to back of queue:

```
Time quantum = 4

Process  | Burst Time
---------|------------
   P1    |     24
   P2    |      3
   P3    |      3

Timeline:
├─ P1 ─┤─ P2 ─┤─ P3 ─┤─ P1 ─┤─ P1 ─┤─ P1 ─┤─ P1 ─┤─ P1 ─┤
0      4      7     10     14     18     22     26     30

P2 finishes at 7, P3 at 10, P1 at 30
```

**Time Quantum Selection**:

| Quantum Size | Effect |
|--------------|--------|
| Too small | Too much context switch overhead |
| Too large | Approaches FCFS behavior |
| Rule of thumb | 80% of bursts should complete in one quantum |

---

## Multi-Level Feedback Queue (MLFQ)

The algorithm that combines multiple approaches:

```
┌─────────────────────────────────────────────────────────────────┐
│                    MULTI-LEVEL FEEDBACK QUEUE                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  Queue 0: Highest Priority (RR, quantum = 8ms)                  │
│  ┌───┬───┬───┐    ← New processes start here                   │
│  │P1 │P2 │P3 │    ← Interactive/IO-bound stay here             │
│  └───┴───┴───┘                                                  │
│       ↓ Used entire quantum? Demote                             │
│                                                                  │
│  Queue 1: Medium Priority (RR, quantum = 16ms)                  │
│  ┌───┬───┐                                                      │
│  │P4 │P5 │        ← CPU-bound processes sink here              │
│  └───┴───┘                                                      │
│       ↓ Used entire quantum? Demote                             │
│                                                                  │
│  Queue 2: Low Priority (FCFS or RR, quantum = 32ms)            │
│  ┌───┬───┬───┬───┐                                              │
│  │P6 │P7 │P8 │P9 │ ← Long-running batch processes              │
│  └───┴───┴───┴───┘                                              │
│                                                                  │
│  Rules:                                                         │
│  1. If A's priority > B's priority, A runs                     │
│  2. If same priority, round-robin                               │
│  3. New job enters highest queue                                │
│  4. Use full quantum → demote                                   │
│  5. Give up CPU (I/O) → stay or promote                        │
│  6. Periodic boost: all → highest queue (prevent starvation)   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

**MLFQ Advantages**:
- Interactive processes stay responsive
- CPU-bound processes get bulk CPU time
- Adapts to process behavior automatically
- No need to know burst time in advance

---

## Linux Completely Fair Scheduler (CFS)

The default Linux scheduler since 2.6.23:

### Core Concept: Virtual Runtime

```c
// Each task has a virtual runtime (vruntime)
// CFS always runs the task with lowest vruntime

struct sched_entity {
    struct rb_node run_node;  // Position in red-black tree
    u64 vruntime;             // Virtual runtime
    u64 sum_exec_runtime;     // Actual runtime
    // ...
};

// vruntime increases as task runs:
// vruntime += delta_exec * (NICE_0_WEIGHT / task_weight)

// Higher priority (lower nice) → lower weight → vruntime increases slower
// → task gets more CPU time
```

### Red-Black Tree for Task Selection

```
                    ┌─────────────────────────────────────────┐
                    │     CFS Red-Black Tree (by vruntime)    │
                    └─────────────────────────────────────────┘

                              [P3: 50ms]
                             /          \
                    [P1: 30ms]          [P5: 70ms]
                   /         \                    \
           [P2: 20ms]    [P4: 45ms]           [P6: 100ms]
              ↑
         Leftmost node = 
         next to run (O(1) cached)
```

### CFS Parameters

| Parameter | Default | Effect |
|-----------|---------|--------|
| `sched_latency_ns` | 6ms | Target scheduling period |
| `sched_min_granularity_ns` | 0.75ms | Minimum time slice |
| `sched_wakeup_granularity_ns` | 1ms | Minimum vruntime advantage to preempt |

### Nice Values and Weights

```
Nice value:  -20 ─────────── 0 ─────────── +19
Priority:    HIGH            NORMAL        LOW
Weight:      88761          1024           15

// A nice -20 task gets ~88761/1024 ≈ 87x more CPU than nice 0
// A nice +19 task gets ~15/1024 ≈ 1/68x as much CPU as nice 0
```

---

## Real-Time Scheduling

For tasks with hard deadlines:

### SCHED_FIFO and SCHED_RR

```c
#include <sched.h>

struct sched_param param;
param.sched_priority = 99;  // 1-99, higher = more urgent

// FIFO: runs until it voluntarily yields or blocks
sched_setscheduler(pid, SCHED_FIFO, &param);

// Round-robin: like FIFO but with time slicing among same priority
sched_setscheduler(pid, SCHED_RR, &param);
```

### Real-Time Scheduling Algorithms

<Tabs>
  <Tab title="Rate Monotonic">
    **Static priority** based on period: shorter period = higher priority
    
    ```
    Task | Period | Execution Time | Priority
    -----|--------|----------------|----------
    T1   |  20ms  |      5ms       |    3 (highest)
    T2   |  50ms  |     15ms       |    2
    T3   | 100ms  |     25ms       |    1 (lowest)
    ```
    
    **Schedulability test**: 
    $U = \sum_{i=1}^{n} \frac{C_i}{T_i} \leq n(2^{1/n} - 1)$
    
    For 3 tasks: U ≤ 0.78 (more tasks → approaches ln(2) ≈ 0.69)
  </Tab>
  <Tab title="Earliest Deadline First (EDF)">
    **Dynamic priority**: task with nearest deadline runs first
    
    ```
    Time 0:
      T1 deadline: 20, T2 deadline: 50
      Run T1 (deadline 20 is earliest)
    
    Time 5:
      T1 complete, T2 deadline still 50
      Run T2
    
    Time 20:
      New T1 instance, deadline: 40
      Preempt T2, run T1 (deadline 40 < 50)
    ```
    
    **Schedulability**: U ≤ 1.0 (optimal for uniprocessor)
  </Tab>
</Tabs>

---

## Multi-Core Scheduling

### Load Balancing

```
┌─────────────────────────────────────────────────────────────────┐
│                    MULTI-CORE SCHEDULING                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  CPU 0                CPU 1                CPU 2                │
│  ┌─────────┐          ┌─────────┐          ┌─────────┐         │
│  │ P1, P2  │          │ P3, P4  │          │  P5     │         │
│  │ P6, P7  │          │         │          │         │         │
│  └─────────┘          └─────────┘          └─────────┘         │
│      ↑                                          ↑               │
│      └──────────── Load Balancing ──────────────┘              │
│                 (migrate P6 or P7 to CPU 2)                     │
│                                                                  │
│  Considerations:                                                │
│  - Cache affinity: migrating invalidates cached data           │
│  - NUMA: memory may be "far" from new CPU                      │
│  - Balance vs overhead: don't migrate too often                │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### CPU Affinity

```c
#define _GNU_SOURCE
#include <sched.h>

// Set CPU affinity
cpu_set_t cpuset;
CPU_ZERO(&cpuset);
CPU_SET(0, &cpuset);  // Allow only CPU 0
CPU_SET(2, &cpuset);  // Also allow CPU 2

sched_setaffinity(pid, sizeof(cpuset), &cpuset);

// Get current affinity
sched_getaffinity(pid, sizeof(cpuset), &cpuset);
for (int i = 0; i < CPU_SETSIZE; i++) {
    if (CPU_ISSET(i, &cpuset)) {
        printf("Process can run on CPU %d\n", i);
    }
}
```

### NUMA Considerations

```
┌─────────────────────────────────────────────────────────────────┐
│                        NUMA Architecture                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌──────────────────┐          ┌──────────────────┐            │
│  │      Node 0      │          │      Node 1      │            │
│  │  ┌────┐  ┌────┐  │          │  ┌────┐  ┌────┐  │            │
│  │  │CPU0│  │CPU1│  │          │  │CPU2│  │CPU3│  │            │
│  │  └────┘  └────┘  │          │  └────┘  └────┘  │            │
│  │       ↕          │          │       ↕          │            │
│  │  ┌──────────┐    │          │  ┌──────────┐    │            │
│  │  │ Memory 0 │    │←─────────→│  │ Memory 1 │    │            │
│  │  │ (Local)  │    │   QPI/    │  │ (Local)  │    │            │
│  │  └──────────┘    │  UPI bus  │  └──────────┘    │            │
│  └──────────────────┘          └──────────────────┘            │
│                                                                  │
│  Access times (example):                                        │
│  - Local memory: 80ns                                           │
│  - Remote memory: 140ns (1.75x slower)                          │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

```c
#include <numaif.h>

// Allocate memory on specific node
void *ptr = numa_alloc_onnode(size, node);

// Set memory policy
unsigned long nodemask = 1 << 0;  // Node 0
set_mempolicy(MPOL_BIND, &nodemask, sizeof(nodemask) * 8);

// Move pages to specific node
move_pages(pid, count, pages, nodes, status, MPOL_MF_MOVE);
```

---

## Scheduling Classes in Linux

```
┌─────────────────────────────────────────────────────────────────┐
│                    LINUX SCHEDULING CLASSES                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  Priority    Class              Description                     │
│  ────────    ─────              ───────────                     │
│  Highest                                                        │
│     ↑     SCHED_DEADLINE    Earliest deadline first             │
│     │     SCHED_FIFO        Real-time FIFO                      │
│     │     SCHED_RR          Real-time round-robin               │
│     │     SCHED_OTHER       CFS (normal processes)              │
│     ↓     SCHED_BATCH       CPU-intensive batch                 │
│  Lowest   SCHED_IDLE        Only when system idle               │
│                                                                  │
│  Note: Real-time classes (FIFO, RR) always preempt CFS         │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## Interview Deep Dive Questions

<AccordionGroup>
  <Accordion title="Q1: Why doesn't Linux use simple priority scheduling?">
    **Answer:**
    
    **Problems with static priority**:
    1. **Starvation**: Low-priority processes may never run
    2. **Priority Inversion**: Low-priority process holds lock needed by high-priority
    3. **No adaptation**: Doesn't respond to changing process behavior
    
    **CFS solves these**:
    1. **Virtual runtime** ensures all processes eventually run
    2. **Proportional sharing** based on nice values, not absolute priority
    3. **Self-adjusting**: Interactive processes naturally maintain low vruntime
    
    **Still uses priorities for**:
    - Real-time scheduling (SCHED_FIFO, SCHED_RR)
    - Nice values influence CFS weight, not absolute priority
  </Accordion>
  
  <Accordion title="Q2: Explain the difference between turnaround time and response time">
    **Answer:**
    
    ```
    Time:    0────────5────────10────────15────────20
    
             Submit                 First          Complete
               ↓                    Output           ↓
               │←── Response Time ──→│               │
               │                                     │
               │←────────── Turnaround Time ─────────│
    ```
    
    - **Response Time**: Time from submission to first output/response
    - **Turnaround Time**: Time from submission to completion
    
    **Optimization conflicts**:
    - Interactive: Minimize response time (run briefly, often)
    - Batch: Minimize turnaround (run to completion, minimize overhead)
    
    **Example**:
    ```
    Job: 100ms total work
    Round-robin (10ms quantum):
      - Response time: 0-10ms (first quantum starts immediately if no queue)
      - Turnaround: varies based on competition
    
    FCFS:
      - Response time = waiting time in queue
      - Turnaround = waiting + 100ms
    ```
  </Accordion>
  
  <Accordion title="Q3: How does CFS handle a process that sleeps frequently?">
    **Answer:**
    
    **Scenario**: Interactive process (e.g., text editor) sleeps waiting for input
    
    **CFS behavior**:
    1. While sleeping, vruntime doesn't increase
    2. Other processes' vruntimes increase
    3. When process wakes, it has relatively low vruntime
    4. Low vruntime means it's near left of RB-tree
    5. Gets scheduled quickly → good response time
    
    **Sleeper fairness adjustment**:
    ```c
    // On wakeup, cap vruntime to not be too far behind
    vruntime = max(vruntime, min_vruntime - sched_latency)
    ```
    
    This prevents:
    - Process sleeping for 1 hour, waking with vruntime = 0
    - Monopolizing CPU to "catch up"
    
    **Result**: Interactive processes are naturally favored without explicit priority boost
  </Accordion>
  
  <Accordion title="Q4: Design a scheduler for a database server">
    **Answer:**
    
    **Requirements analysis**:
    - Mix of short queries and long batch jobs
    - Predictable latency for user-facing queries
    - Efficient use of CPU for analytics
    
    **Design**:
    
    1. **Multi-queue with priorities**:
       - Queue 1: Interactive queries (< 10ms expected)
       - Queue 2: Short transactions (< 100ms)
       - Queue 3: Long-running analytics
    
    2. **Scheduling policy**:
       - Preemptive within queues
       - Higher queues preempt lower
       - Time-based demotion (like MLFQ)
    
    3. **Adaptive classification**:
       ```python
       if query.estimated_cost < threshold_1:
           assign_to_queue_1()
       elif query.actual_runtime > threshold_2:
           demote_to_queue_3()
       ```
    
    4. **Resource limits**:
       - Queue 3 gets max 40% CPU (prevents starvation)
       - Aging promotes long-waiting queries
    
    **Real examples**: PostgreSQL uses similar concepts with parallel query limits and statement timeouts
  </Accordion>
  
  <Accordion title="Q5: What is priority inversion and how is it solved?">
    **Answer:**
    
    **Scenario**:
    ```
    Low priority (L): Holds lock X
    Medium priority (M): CPU-bound, no locks
    High priority (H): Waiting for lock X
    
    Timeline:
    1. L runs, acquires lock X
    2. H arrives, needs lock X, blocks
    3. M arrives, preempts L (M > L priority)
    4. M runs indefinitely
    5. H starves — blocked by M indirectly!
    ```
    
    **Solutions**:
    
    1. **Priority Inheritance**:
       - L inherits H's priority while holding X
       - L can preempt M, finish quickly, release X
       - H then runs
    
    2. **Priority Ceiling**:
       - Each lock has a ceiling (highest priority that may acquire it)
       - Process acquiring lock gets ceiling priority
       - Prevents blocking entirely
    
    3. **Random boosting** (Windows):
       - Randomly boost low-priority threads
       - Probabilistically solves inversion
    
    **Famous case**: Mars Pathfinder (1997) — priority inversion caused system resets until patched with priority inheritance
  </Accordion>
</AccordionGroup>

---

## Practice Exercises

<Steps>
  <Step title="Simulate MLFQ">
    Implement a multi-level feedback queue scheduler simulation. Track queue demotions and response times.
  </Step>
  <Step title="Measure Scheduling Latency">
    Write a program that measures scheduling latency by yielding and timing wake-up.
  </Step>
  <Step title="CPU Pinning Experiment">
    Compare performance of cache-sensitive workload with and without CPU affinity.
  </Step>
  <Step title="Priority Inversion Demo">
    Create a program that demonstrates priority inversion with pthreads and measure the effect.
  </Step>
</Steps>

---

## Key Takeaways

<CardGroup cols={2}>
  <Card title="CFS is Default" icon="linux">
    Linux uses virtual runtime for fair CPU sharing. No explicit priority queue.
  </Card>
  <Card title="MLFQ for Balance" icon="layer-group">
    Combines priority, round-robin, and adaptive demotion. Used by many OS.
  </Card>
  <Card title="Real-Time is Different" icon="clock">
    FIFO/RR with fixed priorities for hard deadlines. Rate Monotonic or EDF.
  </Card>
  <Card title="Multi-Core Adds Complexity" icon="microchip">
    Load balancing, cache affinity, NUMA awareness all matter for performance.
  </Card>
</CardGroup>

---

Next: [Virtual Memory](/operating-systems/virtual-memory) →
