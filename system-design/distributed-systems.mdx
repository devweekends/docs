---
title: "Distributed Systems"
description: "Consistency, Consensus, and handling failures in distributed systems"
icon: "share-nodes"
---

## What are Distributed Systems?

A distributed system is a collection of independent computers that appear to users as a single coherent system.

### Why Distributed?

<CardGroup cols={2}>
  <Card title="Scalability" icon="chart-line">
    Handle more load than a single machine
  </Card>
  <Card title="Reliability" icon="shield">
    Survive individual machine failures
  </Card>
  <Card title="Latency" icon="bolt">
    Serve users from nearby locations
  </Card>
  <Card title="Compliance" icon="globe">
    Data locality requirements
  </Card>
</CardGroup>

## The Eight Fallacies

Things developers wrongly assume about networks:

1. **The network is reliable** → Packets get lost
2. **Latency is zero** → Cross-region calls take 100+ ms
3. **Bandwidth is infinite** → Large payloads slow things down
4. **The network is secure** → Always encrypt
5. **Topology doesn't change** → Servers come and go
6. **There is one administrator** → Multiple teams, policies
7. **Transport cost is zero** → Data transfer costs money
8. **The network is homogeneous** → Different hardware everywhere

## Consistency Models

### Strong Consistency

All nodes see the same data at the same time.

![Strong Consistency](/images/system-design/consistency-patterns.svg)

### Eventual Consistency

All nodes will eventually have the same data.



### Consistency Levels

| Level | Description | Trade-off |
|-------|-------------|-----------|
| **Strong** | All reads see latest write | High latency |
| **Eventual** | Reads may be stale | Low latency |
| **Causal** | Respects cause-effect | Medium |
| **Read-your-writes** | See your own writes | Good UX |
| **Session** | Consistency within session | Practical |

## Consensus Algorithms

How do distributed nodes agree on a value?

### Paxos (Simplified)

![Paxos Simplified](/images/system-design/paxos-simplified.svg)

### Raft (Easier to Understand)

![Raft Consensus](/images/system-design/raft-consensus.svg)

## Distributed Transactions

### Two-Phase Commit (2PC)

![Two-Phase Commit](/images/system-design/two-phase-commit.svg)

### Saga Pattern

![Saga Pattern](/images/system-design/saga-pattern.svg)

### Choreography vs Orchestration

```
Choreography (Event-driven)

Order ─► OrderCreated event
              │
    ┌─────────┼─────────┐
    ▼         ▼         ▼
Inventory  Payment  Shipping
    │         │         │
    └─────────┴─────────┘
          Events

• No central controller
• Services react to events
• More decoupled


Orchestration (Command-driven)

    ┌───────────────────┐
    │   Saga Manager    │
    └─────────┬─────────┘
              │
    ┌─────────┼─────────┐
    ▼         ▼         ▼
Inventory  Payment  Shipping
    
• Central controller
• Explicit flow control
• Easier to understand
```

## Handling Failures

### Circuit Breaker Pattern

![Circuit Breaker](/images/system-design/circuit-breaker.svg)

```python
class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout=60):
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.state = "CLOSED"
        self.last_failure_time = None
    
    def call(self, func):
        if self.state == "OPEN":
            if time.time() - self.last_failure_time > self.timeout:
                self.state = "HALF_OPEN"
            else:
                raise CircuitOpenException()
        
        try:
            result = func()
            self.on_success()
            return result
        except Exception as e:
            self.on_failure()
            raise
    
    def on_success(self):
        self.failure_count = 0
        self.state = "CLOSED"
    
    def on_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        if self.failure_count >= self.failure_threshold:
            self.state = "OPEN"
```

### Retry with Exponential Backoff

```python
import time
import random

def retry_with_backoff(func, max_retries=5, base_delay=1):
    for attempt in range(max_retries):
        try:
            return func()
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            
            # Exponential backoff with jitter
            delay = base_delay * (2 ** attempt)
            jitter = random.uniform(0, delay * 0.1)
            time.sleep(delay + jitter)
            
            print(f"Retry {attempt + 1}/{max_retries} after {delay:.2f}s")
```

### Bulkhead Pattern

Isolate failures to prevent cascade.

![Bulkhead Pattern](/images/system-design/bulkhead-pattern.svg)

## Key Takeaways

| Concept | Remember |
|---------|----------|
| **CAP Theorem** | Pick 2 of 3: Consistency, Availability, Partition Tolerance |
| **Consensus** | Use Raft for leader election, state machine replication |
| **Transactions** | 2PC for strong consistency, Sagas for microservices |
| **Failures** | Design for failure: retries, circuit breakers, bulkheads |

<Warning>
**Distributed systems are hard.** Every network call can fail, be slow, or return stale data. Design for failure from day one.
</Warning>
