---
title: "System Design Fundamentals"
description: "Core concepts every system designer must know"
icon: "book"
---

<Tip>
**Interview Essential**: These fundamentals are the building blocks of every system design. Interviewers expect you to naturally incorporate these concepts without being asked.
</Tip>

## Quick Reference Card

```
┌─────────────────────────────────────────────────────────────────┐
│              FUNDAMENTALS CHEAT SHEET                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  SCALING                                                        │
│  • Vertical = bigger machine (easy but limited)                 │
│  • Horizontal = more machines (complex but unlimited)           │
│                                                                 │
│  AVAILABILITY (memorize these!)                                 │
│  • 99.9% = 8.7 hours downtime/year                             │
│  • 99.99% = 52 minutes downtime/year                           │
│  • 99.999% = 5 minutes downtime/year                           │
│                                                                 │
│  CAP THEOREM                                                    │
│  • CP = Bank, inventory (consistency > availability)           │
│  • AP = Social media, cache (availability > consistency)       │
│                                                                 │
│  LATENCY NUMBERS (Jeff Dean's famous list)                     │
│  • L1 cache: 0.5 ns                                            │
│  • RAM: 100 ns                                                 │
│  • SSD: 100 μs                                                 │
│  • HDD: 10 ms                                                  │
│  • Same datacenter: 0.5 ms                                     │
│  • Cross-continent: 150 ms                                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Scalability

Scalability is the system's ability to handle increased load.

### Vertical vs Horizontal Scaling

```
Vertical Scaling              Horizontal Scaling
(Scale Up)                    (Scale Out)

┌─────────────┐               ┌───────┐ ┌───────┐ ┌───────┐
│             │               │Server │ │Server │ │Server │
│   Bigger    │               │   1   │ │   2   │ │   3   │
│   Server    │               └───┬───┘ └───┬───┘ └───┬───┘
│             │                   │         │         │
│  More CPU   │                   └────┬────┴────┬────┘
│  More RAM   │                        │         │
│             │                   ┌────┴─────────┴────┐
└─────────────┘                   │   Load Balancer   │
                                  └───────────────────┘
```

<CardGroup cols={2}>
  <Card title="Vertical Scaling" icon="arrow-up">
    **Pros**: Simple, no code changes
    
    **Cons**: Hardware limits, single point of failure, expensive
  </Card>
  <Card title="Horizontal Scaling" icon="arrows-left-right">
    **Pros**: Unlimited scale, fault tolerant, cost-effective
    
    **Cons**: Complex, stateless requirement, data consistency
  </Card>
</CardGroup>

## Latency vs Throughput

| Metric | Definition | Example |
|--------|------------|---------|
| **Latency** | Time to complete one request | 200ms response time |
| **Throughput** | Requests handled per unit time | 10,000 requests/second |
| **Bandwidth** | Maximum data transfer rate | 1 Gbps network |

### Latency Percentiles

```
p50 (median):  50% of requests faster than this
p95:           95% of requests faster than this
p99:           99% of requests faster than this
p99.9:         99.9% of requests faster than this

Example:
p50 = 100ms   (typical request)
p95 = 200ms   (slow request)
p99 = 500ms   (very slow request)
p99.9 = 2s    (worst case)
```

## Availability

Availability = Uptime / (Uptime + Downtime)

### The "Nines" of Availability

| Availability | Downtime/Year | Downtime/Month |
|-------------|---------------|----------------|
| 99% (two 9s) | 3.65 days | 7.3 hours |
| 99.9% (three 9s) | 8.76 hours | 43.8 minutes |
| 99.99% (four 9s) | 52.6 minutes | 4.38 minutes |
| 99.999% (five 9s) | 5.26 minutes | 26.3 seconds |

### Achieving High Availability

```
┌─────────────────────────────────────────────────────────────┐
│                     Redundancy at Every Layer               │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│    Users                                                    │
│      │                                                      │
│      ▼                                                      │
│  ┌────────┐    ┌────────┐                                  │
│  │  DNS   │────│  DNS   │  (Multiple DNS providers)       │
│  └────────┘    └────────┘                                  │
│      │                                                      │
│      ▼                                                      │
│  ┌────────┐    ┌────────┐                                  │
│  │  CDN   │────│  CDN   │  (Multiple edge locations)      │
│  └────────┘    └────────┘                                  │
│      │                                                      │
│      ▼                                                      │
│  ┌────────┐    ┌────────┐                                  │
│  │   LB   │────│   LB   │  (Active-passive failover)      │
│  └────────┘    └────────┘                                  │
│      │                                                      │
│      ▼                                                      │
│  ┌──────┐ ┌──────┐ ┌──────┐                               │
│  │ App  │ │ App  │ │ App  │  (Multiple instances)         │
│  └──────┘ └──────┘ └──────┘                               │
│      │                                                      │
│      ▼                                                      │
│  ┌────────┐    ┌────────┐                                  │
│  │Primary │────│Replica │  (Database replication)         │
│  │   DB   │    │   DB   │                                  │
│  └────────┘    └────────┘                                  │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

## CAP Theorem

In a distributed system, you can only guarantee 2 out of 3:

```
                    Consistency
                        ▲
                       /│\
                      / │ \
                     /  │  \
                    /   │   \
                   /    │    \
                  /  CA │ CP  \
                 /      │      \
                /───────┼───────\
               /        │        \
              /    AP   │         \
             /          │          \
            ▼───────────┴───────────▼
    Availability                Partition
                              Tolerance
```

<CardGroup cols={3}>
  <Card title="Consistency (C)" icon="equals">
    All nodes see the same data at the same time
  </Card>
  <Card title="Availability (A)" icon="circle-check">
    Every request gets a response (success or failure)
  </Card>
  <Card title="Partition Tolerance (P)" icon="network-wired">
    System works despite network partitions
  </Card>
</CardGroup>

### Real-World Trade-offs

| System | Choice | Reason |
|--------|--------|--------|
| Banking | CP | Consistency is critical |
| Social Media | AP | Availability preferred |
| Shopping Cart | AP | Can merge conflicts later |
| Inventory | CP | Need accurate counts |

## ACID vs BASE

### ACID (Traditional Databases)

| Property | Description |
|----------|-------------|
| **Atomicity** | All operations succeed or all fail |
| **Consistency** | Data is always valid |
| **Isolation** | Transactions don't interfere |
| **Durability** | Committed data survives crashes |

### BASE (NoSQL Databases)

| Property | Description |
|----------|-------------|
| **Basically Available** | System is always accessible |
| **Soft state** | State may change over time |
| **Eventually consistent** | System will become consistent |

## Consistency Patterns

### Strong Consistency

```
Write ──► Primary DB ──► Replica 1
              │
              └──────► Replica 2
              
Read returns only after ALL replicas updated
```

### Eventual Consistency

```
Write ──► Primary DB ─ ─ ─► Replica 1 (async)
              │
              └─ ─ ─ ─ ─► Replica 2 (async)
              
Read may return stale data temporarily
```

### Read-Your-Writes Consistency

```
User writes ──► Primary
User reads  ──► Primary (same user reads from primary)
Others read ──► Replica (may be stale)
```

## Back-of-the-Envelope Estimation

### Common Calculations

```python
# Daily Active Users (DAU) to QPS
DAU = 100_000_000  # 100 million
requests_per_user_per_day = 10
seconds_per_day = 86400

QPS = (DAU * requests_per_user_per_day) / seconds_per_day
# = 1,000,000,000 / 86,400 ≈ 11,574 QPS

# Peak QPS (2-3x average)
peak_QPS = QPS * 2.5  # ≈ 29,000 QPS
```

### Storage Estimation

```python
# Example: Twitter-like service
users = 500_000_000
tweets_per_user_per_day = 2
tweet_size = 280  # characters
metadata_size = 200  # bytes

daily_tweets = users * tweets_per_user_per_day
# = 1,000,000,000 tweets/day

daily_storage = daily_tweets * (tweet_size + metadata_size)
# = 1B * 480 bytes = 480 GB/day

yearly_storage = daily_storage * 365
# = 175 TB/year (just text, not including media)
```

### Memory Estimation

```python
# Cache sizing (80/20 rule)
# 20% of data serves 80% of requests

daily_requests = 1_000_000_000
request_size = 500  # bytes (average response)
cache_hit_ratio = 0.8

# Cache 20% of daily unique requests
cache_size = 0.2 * daily_requests * request_size
# = 100 GB of cache
```

<Note>
**Interview Tip**: Don't worry about exact numbers. Round liberally and show your reasoning. 86,400 ≈ 100,000 is fine for estimation.
</Note>

## Interview Questions on Fundamentals

<Accordion title="When would you choose CP over AP?">
**Answer**: Choose CP (Consistency over Availability) when:
- **Financial systems**: Bank transfers, payments - incorrect balance is worse than unavailability
- **Inventory management**: Overselling is costly (e.g., airline seats)
- **Booking systems**: Double-booking causes real-world problems
- **Leader election**: Only one leader should exist at a time

**Key phrase**: "In this case, returning wrong data is worse than returning no data."
</Accordion>

<Accordion title="How do you achieve 99.99% availability?">
**Answer**: Redundancy at every layer:
1. Multiple DNS providers
2. CDN with many edge locations
3. Load balancers in active-passive or active-active mode
4. Multiple application servers (stateless)
5. Database replication (primary + replicas)
6. Multi-region deployment
7. Health checks and automatic failover
8. Circuit breakers to prevent cascade failures
</Accordion>

<Accordion title="Explain eventual consistency with an example">
**Answer**: "When you post on social media, your friend might not see it for a few seconds because the data needs to propagate across replicas. This is acceptable because:
1. Availability is more important than instant consistency
2. The delay is usually sub-second and imperceptible
3. The data will eventually be consistent everywhere

Compare to a bank transfer where you MUST see accurate balance immediately - that needs strong consistency."
</Accordion>

<Accordion title="How do you estimate QPS quickly?">
**Answer**: Use the "divide by 100,000" rule:
- DAU × requests per day ÷ 100,000 ≈ QPS
- Example: 100M DAU × 10 requests = 1B / 100,000 = 10,000 QPS
- Peak = 2-3x average

For storage: 
- 1 request = ~500 bytes → 10,000 QPS = 5 MB/second = 432 GB/day
</Accordion>
