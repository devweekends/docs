---
title: "Database Engineering Mastery"
description: "Complete learning path from SQL basics to advanced database internals and PostgreSQL mastery"
icon: "database"
---

# Database Engineering Learning Path

A structured roadmap to master database engineering — from writing your first query to understanding storage engines, replication, and performance tuning at scale.

<Info>
This guide is designed for engineers who want to truly understand databases, not just use them. Each phase builds on the previous, creating deep intuition for how data systems work under the hood.
</Info>

---

## Phase 1: SQL Foundations (2-3 weeks)

Master the language of relational databases before diving into internals.

### Core SQL Concepts

<Steps>
  <Step title="Basic Queries">
    SELECT, FROM, WHERE, ORDER BY, LIMIT
    ```sql
    SELECT name, email, created_at
    FROM users
    WHERE status = 'active'
    ORDER BY created_at DESC
    LIMIT 10;
    ```
  </Step>
  <Step title="Filtering & Operators">
    AND, OR, IN, BETWEEN, LIKE, IS NULL, NOT
    ```sql
    SELECT * FROM orders
    WHERE status IN ('pending', 'processing')
      AND total_amount BETWEEN 100 AND 1000
      AND shipping_address IS NOT NULL;
    ```
  </Step>
  <Step title="Aggregations">
    COUNT, SUM, AVG, MIN, MAX, GROUP BY, HAVING
    ```sql
    SELECT category, 
           COUNT(*) as product_count,
           AVG(price) as avg_price
    FROM products
    GROUP BY category
    HAVING COUNT(*) > 10;
    ```
  </Step>
  <Step title="Joins Mastery">
    INNER JOIN, LEFT/RIGHT JOIN, FULL OUTER JOIN, CROSS JOIN, Self Joins
    ```sql
    SELECT o.id, o.total, c.name, c.email
    FROM orders o
    INNER JOIN customers c ON o.customer_id = c.id
    LEFT JOIN shipping s ON o.id = s.order_id
    WHERE o.created_at > '2024-01-01';
    ```
  </Step>
  <Step title="Subqueries & CTEs">
    Common Table Expressions for readable, maintainable queries
    ```sql
    WITH monthly_sales AS (
      SELECT DATE_TRUNC('month', created_at) as month,
             SUM(total) as revenue
      FROM orders
      WHERE status = 'completed'
      GROUP BY DATE_TRUNC('month', created_at)
    )
    SELECT month, revenue,
           LAG(revenue) OVER (ORDER BY month) as prev_month,
           revenue - LAG(revenue) OVER (ORDER BY month) as growth
    FROM monthly_sales;
    ```
  </Step>
  <Step title="Window Functions">
    ROW_NUMBER, RANK, DENSE_RANK, LAG, LEAD, PARTITION BY
    ```sql
    SELECT name, department, salary,
           RANK() OVER (PARTITION BY department ORDER BY salary DESC) as dept_rank,
           salary - AVG(salary) OVER (PARTITION BY department) as diff_from_avg
    FROM employees;
    ```
  </Step>
</Steps>

### Practice Resources

<CardGroup cols={2}>
  <Card title="SQLBolt" icon="bolt" href="https://sqlbolt.com/">
    Interactive SQL tutorials with instant feedback
  </Card>
  <Card title="LeetCode Database" icon="code" href="https://leetcode.com/problemset/database/">
    50+ SQL problems from easy to hard
  </Card>
  <Card title="Mode SQL Tutorial" icon="chart-line" href="https://mode.com/sql-tutorial/">
    Real-world analytics-focused SQL
  </Card>
  <Card title="PostgreSQL Exercises" icon="dumbbell" href="https://pgexercises.com/">
    PostgreSQL-specific practice problems
  </Card>
</CardGroup>

---

## Phase 2: Database Design & Modeling (2-3 weeks)

Learn to design databases that scale and maintain data integrity.

### Normalization Deep Dive

<AccordionGroup>
  <Accordion title="1NF - First Normal Form">
    **Rule**: Eliminate repeating groups; each column contains atomic values.
    
    ❌ **Bad Design**:
    ```
    | order_id | products              |
    |----------|------------------------|
    | 1        | "laptop, mouse, keyboard" |
    ```
    
    ✅ **Good Design**:
    ```
    | order_id | product   |
    |----------|-----------|
    | 1        | laptop    |
    | 1        | mouse     |
    | 1        | keyboard  |
    ```
  </Accordion>
  
  <Accordion title="2NF - Second Normal Form">
    **Rule**: Meet 1NF + every non-key column depends on the entire primary key.
    
    ❌ **Bad** (partial dependency):
    ```
    | order_id | product_id | product_name | quantity |
    ```
    `product_name` depends only on `product_id`, not the full key.
    
    ✅ **Good**: Separate into Orders and Products tables.
  </Accordion>
  
  <Accordion title="3NF - Third Normal Form">
    **Rule**: Meet 2NF + no transitive dependencies.
    
    ❌ **Bad** (transitive dependency):
    ```
    | employee_id | department_id | department_name |
    ```
    `department_name` depends on `department_id`, not `employee_id`.
    
    ✅ **Good**: Create separate Departments table.
  </Accordion>
  
  <Accordion title="When to Denormalize">
    - Read-heavy workloads with expensive JOINs
    - Reporting/analytics databases
    - Caching layers and materialized views
    - When you understand the trade-offs (data redundancy, update anomalies)
  </Accordion>
</AccordionGroup>

### Entity Relationship Modeling

```
┌─────────────────────────────────────────────────────────────────────┐
│                    E-Commerce Database Schema                        │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  ┌──────────┐       ┌──────────────┐       ┌───────────────┐        │
│  │  Users   │       │    Orders    │       │  Order_Items  │        │
│  ├──────────┤       ├──────────────┤       ├───────────────┤        │
│  │ id (PK)  │──┐    │ id (PK)      │──┐    │ id (PK)       │        │
│  │ email    │  └───▶│ user_id (FK) │  └───▶│ order_id (FK) │        │
│  │ name     │       │ status       │       │ product_id(FK)│◀──┐    │
│  │ created  │       │ total        │       │ quantity      │   │    │
│  └──────────┘       │ created_at   │       │ unit_price    │   │    │
│                     └──────────────┘       └───────────────┘   │    │
│                                                                 │    │
│  ┌──────────────┐                         ┌───────────────┐    │    │
│  │  Categories  │                         │   Products    │    │    │
│  ├──────────────┤                         ├───────────────┤    │    │
│  │ id (PK)      │◀────────────────────────│ category_id   │    │    │
│  │ name         │                         │ id (PK)       │────┘    │
│  │ parent_id    │─┐ (self-reference)      │ name          │         │
│  └──────────────┘ │                       │ price         │         │
│         ▲         │                       │ stock         │         │
│         └─────────┘                       └───────────────┘         │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

### Constraints & Data Integrity

```sql
CREATE TABLE orders (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    status VARCHAR(20) NOT NULL DEFAULT 'pending'
        CHECK (status IN ('pending', 'processing', 'shipped', 'delivered', 'cancelled')),
    total_amount DECIMAL(10, 2) NOT NULL CHECK (total_amount >= 0),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    -- Composite unique constraint
    CONSTRAINT unique_user_order_time UNIQUE (user_id, created_at)
);

-- Partial index for active orders only
CREATE INDEX idx_active_orders ON orders(user_id, created_at) 
WHERE status NOT IN ('delivered', 'cancelled');
```

---

## Phase 3: ACID & Transactions (1-2 weeks)

Understanding transactions is crucial for building reliable applications.

### ACID Properties Explained

<Tabs>
  <Tab title="Atomicity">
    **All or Nothing** — A transaction either completes entirely or has no effect.
    
    ```sql
    BEGIN;
    
    -- Deduct from sender
    UPDATE accounts SET balance = balance - 100 WHERE id = 1;
    
    -- Add to receiver
    UPDATE accounts SET balance = balance + 100 WHERE id = 2;
    
    -- Both succeed or both fail
    COMMIT;
    ```
    
    If the server crashes between the two UPDATEs, PostgreSQL will rollback both changes on recovery.
  </Tab>
  
  <Tab title="Consistency">
    **Valid State Transitions** — Database moves from one valid state to another.
    
    ```sql
    -- This will fail due to CHECK constraint
    UPDATE accounts SET balance = balance - 1000 WHERE id = 1;
    -- Error: violates check constraint "accounts_balance_check"
    
    -- Constraints enforce business rules at the database level
    ALTER TABLE accounts ADD CONSTRAINT positive_balance 
        CHECK (balance >= 0);
    ```
  </Tab>
  
  <Tab title="Isolation">
    **Concurrent Transaction Separation** — Transactions don't interfere with each other.
    
    ```sql
    -- Transaction 1
    BEGIN;
    SELECT balance FROM accounts WHERE id = 1; -- Returns 1000
    -- ... some time passes ...
    UPDATE accounts SET balance = balance - 100 WHERE id = 1;
    COMMIT;
    
    -- Transaction 2 (concurrent)
    BEGIN;
    SELECT balance FROM accounts WHERE id = 1; -- What does this return?
    -- Depends on isolation level!
    COMMIT;
    ```
  </Tab>
  
  <Tab title="Durability">
    **Permanent Changes** — Once committed, data survives system failures.
    
    PostgreSQL achieves durability through:
    - **Write-Ahead Logging (WAL)**: Changes logged before applied
    - **Checkpoints**: Periodic flushing of dirty pages to disk
    - **fsync**: Ensuring data reaches physical storage
    
    ```sql
    -- Configure durability level
    SET synchronous_commit = on;  -- Wait for WAL to disk (safest)
    SET synchronous_commit = off; -- Faster, risk losing last few ms
    ```
  </Tab>
</Tabs>

### Isolation Levels Deep Dive

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         Isolation Levels                                 │
├────────────────────┬──────────────┬──────────────┬─────────────────────┤
│ Level              │ Dirty Read   │ Non-Repeatable│ Phantom Read       │
│                    │              │ Read          │                    │
├────────────────────┼──────────────┼──────────────┼─────────────────────┤
│ READ UNCOMMITTED   │ Possible     │ Possible     │ Possible           │
│ READ COMMITTED     │ Prevented    │ Possible     │ Possible           │
│ REPEATABLE READ    │ Prevented    │ Prevented    │ Possible (not PG)  │
│ SERIALIZABLE       │ Prevented    │ Prevented    │ Prevented          │
└────────────────────┴──────────────┴──────────────┴─────────────────────┘

PostgreSQL's REPEATABLE READ also prevents phantom reads (MVCC implementation)
```

### Practical Transaction Patterns

```sql
-- Pattern 1: Retry on serialization failure
DO $$
DECLARE
    retry_count INT := 0;
BEGIN
    LOOP
        BEGIN
            -- Your transaction logic here
            UPDATE inventory SET quantity = quantity - 1 
            WHERE product_id = 123 AND quantity > 0;
            
            IF NOT FOUND THEN
                RAISE EXCEPTION 'Out of stock';
            END IF;
            
            INSERT INTO orders (product_id, quantity) VALUES (123, 1);
            RETURN;
            
        EXCEPTION WHEN serialization_failure OR deadlock_detected THEN
            retry_count := retry_count + 1;
            IF retry_count > 3 THEN
                RAISE;
            END IF;
            -- Wait before retry (exponential backoff)
            PERFORM pg_sleep(0.1 * retry_count);
        END;
    END LOOP;
END $$;

-- Pattern 2: Advisory Locks for application-level locking
SELECT pg_advisory_lock(hashtext('process_user_' || user_id::text));
-- ... do work ...
SELECT pg_advisory_unlock(hashtext('process_user_' || user_id::text));
```

---

## Phase 4: Indexing Mastery (2-3 weeks)

Indexes are the key to database performance. Understanding them deeply separates good engineers from great ones.

### Index Types & When to Use Them

<AccordionGroup>
  <Accordion title="B-Tree Index (Default)">
    **Best for**: Equality and range queries, sorting
    
    ```sql
    -- Automatically created for PRIMARY KEY and UNIQUE constraints
    CREATE INDEX idx_users_email ON users(email);
    
    -- Supports operators: <, <=, =, >=, >, BETWEEN, IN, IS NULL
    -- Also supports LIKE 'prefix%' (but not '%suffix')
    
    -- Multi-column index (order matters!)
    CREATE INDEX idx_orders_user_date ON orders(user_id, created_at DESC);
    -- Efficient for: WHERE user_id = X AND created_at > Y
    -- Also for: WHERE user_id = X ORDER BY created_at DESC
    -- NOT efficient for: WHERE created_at > Y (without user_id)
    ```
    
    **How B-Trees Work**:
    ```
                        [50]
                       /    \
                   [25,35]  [75,90]
                  /   |  \    |   \
              [10,20][30][40,45][60,70][80,95]
    
    - Balanced tree (O(log n) lookups)
    - Nodes contain sorted keys
    - Leaf nodes linked for range scans
    ```
  </Accordion>
  
  <Accordion title="Hash Index">
    **Best for**: Exact equality lookups only
    
    ```sql
    CREATE INDEX idx_sessions_token ON sessions USING hash(token);
    
    -- Only supports = operator
    -- Faster than B-Tree for pure equality (no range queries)
    -- Not WAL-logged before PostgreSQL 10 (crash unsafe)
    ```
  </Accordion>
  
  <Accordion title="GIN (Generalized Inverted Index)">
    **Best for**: Full-text search, arrays, JSONB
    
    ```sql
    -- Full-text search
    CREATE INDEX idx_articles_search ON articles 
    USING gin(to_tsvector('english', title || ' ' || content));
    
    SELECT * FROM articles 
    WHERE to_tsvector('english', title || ' ' || content) 
          @@ to_tsquery('english', 'postgresql & performance');
    
    -- JSONB containment queries
    CREATE INDEX idx_products_attrs ON products USING gin(attributes);
    
    SELECT * FROM products 
    WHERE attributes @> '{"color": "red", "size": "large"}';
    
    -- Array operations
    CREATE INDEX idx_posts_tags ON posts USING gin(tags);
    SELECT * FROM posts WHERE tags && ARRAY['javascript', 'react'];
    ```
  </Accordion>
  
  <Accordion title="GiST (Generalized Search Tree)">
    **Best for**: Geometric data, range types, full-text (phrase search)
    
    ```sql
    -- Geographic queries (with PostGIS)
    CREATE INDEX idx_locations_geom ON locations USING gist(geom);
    
    SELECT * FROM locations 
    WHERE ST_DWithin(geom, ST_MakePoint(-73.9857, 40.7484)::geography, 1000);
    
    -- Range overlap queries
    CREATE INDEX idx_bookings_period ON bookings USING gist(during);
    SELECT * FROM bookings WHERE during && '[2024-01-01, 2024-01-07]'::daterange;
    ```
  </Accordion>
  
  <Accordion title="BRIN (Block Range Index)">
    **Best for**: Very large tables with naturally sorted data (time-series)
    
    ```sql
    -- Ideal for append-only tables sorted by timestamp
    CREATE INDEX idx_logs_created ON logs USING brin(created_at);
    
    -- Much smaller than B-Tree (stores min/max per block range)
    -- Effective when data is physically clustered by the indexed column
    ```
  </Accordion>
</AccordionGroup>

### Index Analysis & Optimization

```sql
-- Check if indexes are being used
EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)
SELECT * FROM orders WHERE user_id = 123 AND created_at > '2024-01-01';

-- Key things to look for:
-- 1. Index Scan vs Seq Scan (Index is better for selective queries)
-- 2. Actual rows vs estimated rows (if off, run ANALYZE)
-- 3. Buffers: shared hit vs read (hits are from cache)

-- Find unused indexes (potential candidates for removal)
SELECT schemaname, relname, indexrelname, idx_scan, idx_tup_read
FROM pg_stat_user_indexes
WHERE idx_scan = 0
ORDER BY pg_relation_size(indexrelid) DESC;

-- Find missing indexes (tables with many sequential scans)
SELECT schemaname, relname, seq_scan, idx_scan,
       seq_scan - idx_scan AS too_many_seq_scans,
       pg_size_pretty(pg_relation_size(relid)) AS size
FROM pg_stat_user_tables
WHERE seq_scan > idx_scan
ORDER BY seq_scan - idx_scan DESC;

-- Index bloat detection
SELECT
    indexrelname AS index_name,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
    idx_scan AS times_used
FROM pg_stat_user_indexes
ORDER BY pg_relation_size(indexrelid) DESC
LIMIT 10;
```

### Partial & Expression Indexes

```sql
-- Partial index: only index what you query
CREATE INDEX idx_orders_pending ON orders(created_at)
WHERE status = 'pending';
-- Much smaller, much faster for: WHERE status = 'pending' ORDER BY created_at

-- Expression index: index computed values
CREATE INDEX idx_users_lower_email ON users(lower(email));
-- Now this uses the index:
SELECT * FROM users WHERE lower(email) = 'john@example.com';

-- Covering index: include extra columns to avoid table lookup
CREATE INDEX idx_orders_user_covering ON orders(user_id) 
INCLUDE (status, total_amount);
-- Index-only scan: SELECT status, total_amount FROM orders WHERE user_id = 123
```

---

## Phase 5: Query Optimization (2-3 weeks)

Learn to read execution plans and optimize slow queries.

### Understanding EXPLAIN ANALYZE

```sql
EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)
SELECT u.name, COUNT(o.id) as order_count, SUM(o.total) as total_spent
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
WHERE u.created_at > '2024-01-01'
GROUP BY u.id, u.name
HAVING COUNT(o.id) > 5
ORDER BY total_spent DESC
LIMIT 10;
```

**Reading the Plan** (inside out, bottom up):

```
Limit  (cost=1234.56..1234.78 rows=10 width=48) (actual time=45.2..45.3 rows=10 loops=1)
  ->  Sort  (cost=1234.56..1240.12 rows=2224 width=48) (actual time=45.2..45.2 rows=10 loops=1)
        Sort Key: (sum(o.total)) DESC
        Sort Method: top-N heapsort  Memory: 26kB
        ->  HashAggregate  (cost=1100.00..1200.00 rows=2224 width=48) (actual time=40.1..42.3 rows=1500 loops=1)
              Group Key: u.id
              Filter: (count(o.id) > 5)
              Rows Removed by Filter: 3500
              ->  Hash Right Join  (cost=100.00..900.00 rows=25000 width=40) (actual time=5.2..25.4 rows=25000 loops=1)
                    Hash Cond: (o.user_id = u.id)
                    ->  Seq Scan on orders o  (cost=0.00..500.00 rows=30000 width=24) (actual time=0.01..8.5 rows=30000 loops=1)
                    ->  Hash  (cost=80.00..80.00 rows=5000 width=24) (actual time=4.8..4.8 rows=5000 loops=1)
                          Buckets: 8192  Batches: 1  Memory Usage: 350kB
                          ->  Index Scan using idx_users_created on users u  (cost=0.29..80.00 rows=5000 width=24)
                                Index Cond: (created_at > '2024-01-01')
Planning Time: 0.5 ms
Execution Time: 45.5 ms
```

### Common Query Anti-Patterns

<Tabs>
  <Tab title="N+1 Queries">
    ❌ **Problem**: Fetching related data in a loop
    ```python
    users = db.query("SELECT * FROM users LIMIT 100")
    for user in users:
        orders = db.query(f"SELECT * FROM orders WHERE user_id = {user.id}")
        # 101 queries total!
    ```
    
    ✅ **Solution**: Use JOINs or batch fetching
    ```sql
    SELECT u.*, o.id as order_id, o.total
    FROM users u
    LEFT JOIN orders o ON u.id = o.user_id
    WHERE u.id IN (1, 2, 3, ...);
    ```
  </Tab>
  
  <Tab title="SELECT *">
    ❌ **Problem**: Fetching all columns when you need few
    ```sql
    SELECT * FROM users WHERE id = 1;
    -- Fetches 50 columns including large TEXT blobs
    ```
    
    ✅ **Solution**: Select only needed columns
    ```sql
    SELECT id, name, email FROM users WHERE id = 1;
    -- Enables covering index scans, reduces I/O
    ```
  </Tab>
  
  <Tab title="Functions on Indexed Columns">
    ❌ **Problem**: Wrapping indexed columns in functions
    ```sql
    SELECT * FROM users WHERE YEAR(created_at) = 2024;
    -- Cannot use index on created_at!
    ```
    
    ✅ **Solution**: Rewrite to preserve index usage
    ```sql
    SELECT * FROM users 
    WHERE created_at >= '2024-01-01' AND created_at < '2025-01-01';
    -- Uses index!
    ```
  </Tab>
  
  <Tab title="OR Conditions">
    ❌ **Problem**: OR often prevents index usage
    ```sql
    SELECT * FROM products WHERE category_id = 5 OR brand_id = 10;
    -- May result in sequential scan
    ```
    
    ✅ **Solution**: Use UNION or separate indexes
    ```sql
    SELECT * FROM products WHERE category_id = 5
    UNION
    SELECT * FROM products WHERE brand_id = 10;
    -- Each query can use its respective index
    ```
  </Tab>
</Tabs>

---

## Phase 6: Database Internals (3-4 weeks)

Understanding how databases work under the hood.

### Storage Engine Architecture

```
┌───────────────────────────────────────────────────────────────────────┐
│                      PostgreSQL Architecture                          │
├───────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  Client Connection                                                    │
│         │                                                             │
│         ▼                                                             │
│  ┌─────────────┐                                                      │
│  │   Parser    │ ──▶ Parse SQL into query tree                       │
│  └─────────────┘                                                      │
│         │                                                             │
│         ▼                                                             │
│  ┌─────────────┐                                                      │
│  │  Analyzer   │ ──▶ Semantic analysis, resolve names                │
│  └─────────────┘                                                      │
│         │                                                             │
│         ▼                                                             │
│  ┌─────────────┐                                                      │
│  │  Rewriter   │ ──▶ Apply rules (views, RLS)                        │
│  └─────────────┘                                                      │
│         │                                                             │
│         ▼                                                             │
│  ┌─────────────┐     ┌─────────────────────────────────┐             │
│  │  Planner/   │ ──▶ │ Generate execution plans        │             │
│  │  Optimizer  │     │ Cost-based selection            │             │
│  └─────────────┘     │ Uses statistics (pg_statistic)  │             │
│         │            └─────────────────────────────────┘             │
│         ▼                                                             │
│  ┌─────────────┐                                                      │
│  │  Executor   │ ──▶ Execute the chosen plan                         │
│  └─────────────┘                                                      │
│         │                                                             │
│         ▼                                                             │
│  ┌─────────────────────────────────────────────────────┐             │
│  │              Shared Buffer Pool                      │             │
│  │  ┌────┬────┬────┬────┬────┬────┬────┬────┐         │             │
│  │  │Page│Page│Page│Page│Page│Page│Page│Page│         │             │
│  │  └────┴────┴────┴────┴────┴────┴────┴────┘         │             │
│  └───────────────────────────────────────────────────────┘             │
│         │                    │                                        │
│         ▼                    ▼                                        │
│  ┌─────────────┐      ┌─────────────┐                                │
│  │ Background  │      │    WAL      │                                │
│  │   Writer    │      │   Writer    │                                │
│  └─────────────┘      └─────────────┘                                │
│         │                    │                                        │
│         ▼                    ▼                                        │
│  ┌─────────────┐      ┌─────────────┐                                │
│  │  Data Files │      │  WAL Files  │                                │
│  │  (Tables,   │      │  (Write-    │                                │
│  │   Indexes)  │      │   Ahead Log)│                                │
│  └─────────────┘      └─────────────┘                                │
│                                                                       │
└───────────────────────────────────────────────────────────────────────┘
```

### MVCC (Multi-Version Concurrency Control)

PostgreSQL uses MVCC to allow readers and writers to not block each other.

```sql
-- Every row has hidden system columns
SELECT xmin, xmax, ctid, * FROM users WHERE id = 1;

-- xmin: Transaction ID that inserted this row version
-- xmax: Transaction ID that deleted/updated this row version (0 if live)
-- ctid: Physical location (page, offset)
```

```
Transaction Timeline with MVCC:
────────────────────────────────────────────────────────────────────

T1 (txid=100): BEGIN
               UPDATE users SET name='Alice' WHERE id=1;
               -- Creates new row version with xmin=100
               -- Old version gets xmax=100
               
T2 (txid=101): BEGIN (REPEATABLE READ)
               SELECT * FROM users WHERE id=1;
               -- Sees OLD version (xmax=100 not yet committed)
               
T1:            COMMIT;
               -- xmin=100 now considered committed
               
T2:            SELECT * FROM users WHERE id=1;
               -- Still sees OLD version (snapshot taken at BEGIN)
               
T2:            COMMIT;

T3 (txid=102): SELECT * FROM users WHERE id=1;
               -- Sees NEW version (xmin=100 committed before T3 started)
```

### Vacuum & Dead Tuple Management

```sql
-- Check table bloat
SELECT 
    schemaname, relname,
    n_live_tup, n_dead_tup,
    round(100.0 * n_dead_tup / nullif(n_live_tup + n_dead_tup, 0), 2) as dead_ratio,
    last_vacuum, last_autovacuum
FROM pg_stat_user_tables
ORDER BY n_dead_tup DESC;

-- Manual vacuum (for maintenance windows)
VACUUM (VERBOSE, ANALYZE) large_table;

-- Aggressive vacuum to reclaim disk space
VACUUM FULL large_table;  -- Warning: locks table exclusively

-- Configure autovacuum for high-traffic tables
ALTER TABLE orders SET (
    autovacuum_vacuum_scale_factor = 0.01,  -- Vacuum at 1% dead tuples
    autovacuum_analyze_scale_factor = 0.005,
    autovacuum_vacuum_cost_delay = 10
);
```

---

## Phase 7: Replication & High Availability (2-3 weeks)

Build systems that survive failures.

### Replication Topologies

<Tabs>
  <Tab title="Streaming Replication">
    **Primary → Standby(s)**: WAL records streamed in real-time
    
    ```
    ┌─────────────┐         WAL Stream         ┌─────────────┐
    │   Primary   │ ──────────────────────────▶│   Standby   │
    │  (Read/Write)│                           │ (Read-Only) │
    └─────────────┘                            └─────────────┘
    ```
    
    ```sql
    -- On Primary: postgresql.conf
    wal_level = replica
    max_wal_senders = 5
    synchronous_standby_names = 'standby1'
    
    -- On Standby: recovery.conf / postgresql.conf (v12+)
    primary_conninfo = 'host=primary port=5432 user=repl'
    ```
  </Tab>
  
  <Tab title="Logical Replication">
    **Selective table replication** with transformation support
    
    ```sql
    -- Publisher (source)
    CREATE PUBLICATION my_pub FOR TABLE users, orders;
    
    -- Subscriber (destination)
    CREATE SUBSCRIPTION my_sub
    CONNECTION 'host=source dbname=mydb user=repl'
    PUBLICATION my_pub;
    ```
    
    Use cases:
    - Cross-version upgrades
    - Selective data replication
    - Multi-tenant to single-tenant migration
  </Tab>
  
  <Tab title="Synchronous vs Async">
    **Synchronous**: Commit waits for standby confirmation
    ```sql
    -- Strong durability, higher latency
    synchronous_commit = on
    synchronous_standby_names = 'FIRST 1 (standby1, standby2)'
    ```
    
    **Asynchronous**: Commit returns immediately
    ```sql
    -- Lower latency, risk of data loss on failover
    synchronous_commit = local
    ```
    
    **Quorum**: Commit when N standbys confirm
    ```sql
    synchronous_standby_names = 'ANY 2 (standby1, standby2, standby3)'
    ```
  </Tab>
</Tabs>

### Connection Pooling

```
Without Pooling:                    With PgBouncer:
┌──────┐ ┌──────┐ ┌──────┐         ┌──────┐ ┌──────┐ ┌──────┐
│ App1 │ │ App2 │ │ App3 │         │ App1 │ │ App2 │ │ App3 │
└──┬───┘ └──┬───┘ └──┬───┘         └──┬───┘ └──┬───┘ └──┬───┘
   │        │        │                 │        │        │
   │ 100    │ 100    │ 100            └────────┼────────┘
   │ conns  │ conns  │ conns                   │
   │        │        │                         │ 300 client conns
   ▼        ▼        ▼                         ▼
┌─────────────────────────────┐         ┌─────────────┐
│      PostgreSQL             │         │  PgBouncer  │ ─── 20 PG conns ───▶ PostgreSQL
│      (300 backends!)        │         └─────────────┘
└─────────────────────────────┘
```

```ini
# pgbouncer.ini
[databases]
mydb = host=localhost port=5432 dbname=mydb

[pgbouncer]
listen_port = 6432
pool_mode = transaction          # Options: session, transaction, statement
max_client_conn = 1000
default_pool_size = 20
reserve_pool_size = 5
```

---

## Phase 8: Performance Tuning (Ongoing)

### PostgreSQL Configuration Tuning

```sql
-- Memory settings (adjust based on available RAM)
shared_buffers = '4GB'              -- 25% of RAM for dedicated DB server
effective_cache_size = '12GB'       -- 75% of RAM (OS cache estimate)
work_mem = '256MB'                  -- Per-operation memory (careful with concurrency)
maintenance_work_mem = '1GB'        -- For VACUUM, CREATE INDEX

-- WAL settings
wal_buffers = '64MB'
checkpoint_completion_target = 0.9
max_wal_size = '4GB'

-- Parallelism
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
parallel_tuple_cost = 0.01
parallel_setup_cost = 100

-- Query planner
random_page_cost = 1.1              -- Lower for SSDs (default 4.0 for HDD)
effective_io_concurrency = 200      -- Higher for SSDs
```

### Monitoring Queries

```sql
-- Current running queries
SELECT pid, now() - pg_stat_activity.query_start AS duration, query, state
FROM pg_stat_activity
WHERE (now() - pg_stat_activity.query_start) > interval '30 seconds'
  AND state != 'idle';

-- Lock monitoring
SELECT blocked_locks.pid AS blocked_pid,
       blocked_activity.usename AS blocked_user,
       blocking_locks.pid AS blocking_pid,
       blocking_activity.usename AS blocking_user,
       blocked_activity.query AS blocked_statement
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks 
    ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page
    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple
    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid
    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid
    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid
    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid
    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;

-- Table statistics
SELECT relname, 
       seq_scan, idx_scan,
       n_tup_ins, n_tup_upd, n_tup_del,
       n_live_tup, n_dead_tup
FROM pg_stat_user_tables
ORDER BY n_live_tup DESC;
```

---

## Recommended Learning Resources

### Video Courses

<CardGroup cols={2}>
  <Card title="Fundamentals of Database Engineering" icon="play" href="https://www.udemy.com/course/database-engines-crash-course/">
    **Hussein Nasser** (Udemy) — Comprehensive 25+ hour course covering everything from ACID to sharding. Best investment for serious database learning.
  </Card>
  <Card title="Hussein Nasser YouTube" icon="youtube" href="https://www.youtube.com/@haborSoftware">
    Free deep dives into database internals, PostgreSQL features, and real-world case studies.
  </Card>
  <Card title="CMU Database Systems" icon="graduation-cap" href="https://www.youtube.com/playlist?list=PLSE8ODhjZXjbj8BMuIrRcacnQh20hmY9g">
    **Andy Pavlo** — University-level course covering database internals in depth. Advanced but invaluable.
  </Card>
  <Card title="PostgreSQL Tutorial" icon="elephant" href="https://www.postgresqltutorial.com/">
    Excellent free resource for PostgreSQL-specific learning with practical examples.
  </Card>
</CardGroup>

### Books

| Book | Author | Focus Area |
|------|--------|------------|
| **Designing Data-Intensive Applications** | Martin Kleppmann | Distributed systems, data modeling, replication |
| **PostgreSQL 14 Internals** | Egor Rogov | Deep dive into PostgreSQL architecture |
| **High Performance MySQL** | Baron Schwartz et al. | MySQL optimization (concepts transfer) |
| **Database Internals** | Alex Petrov | Storage engines, distributed databases |
| **SQL Performance Explained** | Markus Winand | Indexing and query optimization |

### Practice Platforms

<CardGroup cols={3}>
  <Card title="pgexercises.com" icon="dumbbell" href="https://pgexercises.com/">
    PostgreSQL-specific exercises
  </Card>
  <Card title="LeetCode Database" icon="code" href="https://leetcode.com/problemset/database/">
    SQL problem solving
  </Card>
  <Card title="HackerRank SQL" icon="terminal" href="https://www.hackerrank.com/domains/sql">
    Structured SQL challenges
  </Card>
</CardGroup>

---

## Learning Timeline Summary

```
Week 1-3:   SQL Foundations → Write complex queries confidently
Week 4-6:   Database Design → Model data correctly from the start
Week 7-8:   ACID & Transactions → Build reliable applications
Week 9-11:  Indexing → Make queries fast
Week 12-14: Query Optimization → Debug slow queries like a pro
Week 15-18: Database Internals → Understand the "why" behind everything
Week 19-21: Replication & HA → Build systems that don't go down
Week 22+:   Performance Tuning → Continuous improvement

Total: ~5-6 months of dedicated learning to reach advanced level
```

<Tip>
**Pro Tip**: Set up a local PostgreSQL instance from day one. Every concept you learn, try it hands-on. Theory without practice doesn't stick.
</Tip>

<Warning>
Databases are a deep field. Don't rush. It's better to truly understand indexes before moving to internals than to skim everything and retain nothing.
</Warning>
