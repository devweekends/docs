---
title: "Reliability & Fault Tolerance"
description: "Building resilient systems that survive failures"
icon: "shield-halved"
---

<Warning>
**Senior Level**: Fault tolerance is what separates good systems from great ones. Interviewers expect senior engineers to design for failure from day one.
</Warning>

## Design for Failure Mindset

```
┌─────────────────────────────────────────────────────────────────┐
│              Murphy's Law for Distributed Systems               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  "Anything that can fail, will fail."                          │
│                                                                 │
│  Servers crash           → Design for N-1 availability         │
│  Networks partition      → Handle split-brain scenarios        │
│  Disks fail              → Replicate data                      │
│  Deploys break things    → Canary releases, rollbacks          │
│  Dependencies fail       → Circuit breakers, fallbacks         │
│  Traffic spikes          → Auto-scaling, load shedding         │
│  Data centers go offline → Multi-region deployment             │
│                                                                 │
│  Netflix Chaos Engineering Principle:                          │
│  "If you want a resilient system, break it on purpose."        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Redundancy Patterns

### Active-Passive (Standby)

```
┌─────────────────────────────────────────────────────────────────┐
│                   Active-Passive Pattern                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│         Normal Operation              After Failover            │
│         ────────────────              ──────────────            │
│                                                                 │
│         ┌───────────┐                 ┌───────────┐            │
│         │  Active   │                 │  Active   │            │
│         │  Server   │────┐       ┌────│  Server   │            │
│         │  (Live)   │    │       │    │ (crashed) │            │
│         └─────┬─────┘    │       │    └───────────┘            │
│               │          │       │                              │
│    Traffic ───┤          │       │                              │
│               │    Heartbeat     │                              │
│               │          │       │                              │
│         ┌─────▼─────┐    │       │    ┌───────────┐            │
│         │  Passive  │◄───┘       └────│  Passive  │◄── Traffic │
│         │  Server   │                 │  Server   │            │
│         │ (Standby) │                 │ (Now Live)│            │
│         └───────────┘                 └───────────┘            │
│                                                                 │
│  Failover triggers:                                            │
│  • Heartbeat timeout (5-30 seconds)                            │
│  • Health check failures                                       │
│  • Manual trigger                                              │
│                                                                 │
│  RTO (Recovery Time): 10-60 seconds                            │
│  RPO (Data Loss): 0 if sync replication, seconds if async     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Active-Active

```
┌─────────────────────────────────────────────────────────────────┐
│                   Active-Active Pattern                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│                      Load Balancer                              │
│                           │                                     │
│              ┌────────────┼────────────┐                       │
│              │            │            │                        │
│              ▼            ▼            ▼                        │
│         ┌────────┐   ┌────────┐   ┌────────┐                   │
│         │ Active │   │ Active │   │ Active │                   │
│         │   1    │   │   2    │   │   3    │                   │
│         └───┬────┘   └───┬────┘   └───┬────┘                   │
│             │            │            │                         │
│             └────────────┼────────────┘                         │
│                          │                                      │
│                    Shared State                                 │
│                    (Database/Cache)                             │
│                                                                 │
│  Benefits:                                                     │
│  • No failover delay (instant)                                 │
│  • Full utilization of all servers                             │
│  • Horizontal scalability                                      │
│                                                                 │
│  Challenges:                                                   │
│  • Stateless servers required                                  │
│  • Shared state must be highly available                       │
│  • More complex routing                                        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Multi-Region Active-Active

```
┌─────────────────────────────────────────────────────────────────┐
│              Multi-Region Active-Active                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│                      Global DNS                                 │
│                (GeoDNS / Route53)                               │
│                         │                                       │
│         ┌───────────────┴───────────────┐                      │
│         │                               │                       │
│    US-EAST                         EU-WEST                     │
│    ┌─────────────────┐       ┌─────────────────┐              │
│    │    Region       │       │    Region       │              │
│    │  ┌───────────┐  │       │  ┌───────────┐  │              │
│    │  │ App Tier  │  │       │  │ App Tier  │  │              │
│    │  └─────┬─────┘  │       │  └─────┬─────┘  │              │
│    │        │        │       │        │        │              │
│    │  ┌─────▼─────┐  │       │  ┌─────▼─────┐  │              │
│    │  │ Database  │◄─┼─Async─┼──│ Database  │  │              │
│    │  │ Primary   │──┼─Async─┼─►│ Primary   │  │              │
│    │  └───────────┘  │       │  └───────────┘  │              │
│    └─────────────────┘       └─────────────────┘              │
│                                                                 │
│  Conflict Resolution Strategies:                               │
│  • Last-Write-Wins (simple but data loss)                      │
│  • Vector Clocks (detects conflicts)                           │
│  • CRDTs (automatic merge)                                     │
│  • Custom merge logic (app-specific)                           │
│                                                                 │
│  Data Locality:                                                │
│  • User data lives in home region                              │
│  • Reads: Always local                                         │
│  • Writes: Local with async replication                        │
│  • Cross-region reads: When necessary (follow)                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Resilience Patterns

### Circuit Breaker (Deep Dive)

```python
from enum import Enum
from datetime import datetime, timedelta
import threading

class CircuitState(Enum):
    CLOSED = "closed"      # Normal operation
    OPEN = "open"          # Failing fast
    HALF_OPEN = "half_open"  # Testing if recovered

class CircuitBreaker:
    """
    Production-grade circuit breaker with:
    - Failure threshold
    - Success threshold for recovery
    - Timeout for open state
    - Thread safety
    """
    
    def __init__(
        self,
        failure_threshold: int = 5,
        success_threshold: int = 3,
        timeout_seconds: int = 30
    ):
        self.failure_threshold = failure_threshold
        self.success_threshold = success_threshold
        self.timeout = timedelta(seconds=timeout_seconds)
        
        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None
        self.lock = threading.Lock()
    
    def call(self, func, *args, **kwargs):
        with self.lock:
            if not self._can_execute():
                raise CircuitOpenError("Circuit is OPEN")
        
        try:
            result = func(*args, **kwargs)
            self._on_success()
            return result
        except Exception as e:
            self._on_failure()
            raise
    
    def _can_execute(self) -> bool:
        if self.state == CircuitState.CLOSED:
            return True
        
        if self.state == CircuitState.OPEN:
            # Check if timeout has passed
            if datetime.now() - self.last_failure_time > self.timeout:
                self.state = CircuitState.HALF_OPEN
                self.success_count = 0
                return True
            return False
        
        # HALF_OPEN: allow limited requests
        return True
    
    def _on_success(self):
        with self.lock:
            if self.state == CircuitState.HALF_OPEN:
                self.success_count += 1
                if self.success_count >= self.success_threshold:
                    # Service recovered!
                    self.state = CircuitState.CLOSED
                    self.failure_count = 0
            elif self.state == CircuitState.CLOSED:
                self.failure_count = 0
    
    def _on_failure(self):
        with self.lock:
            self.failure_count += 1
            self.last_failure_time = datetime.now()
            
            if self.state == CircuitState.HALF_OPEN:
                # Failed during recovery test
                self.state = CircuitState.OPEN
            elif self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN


# Usage with fallback
circuit = CircuitBreaker(failure_threshold=5, timeout_seconds=30)

def get_user_with_fallback(user_id):
    try:
        return circuit.call(user_service.get_user, user_id)
    except CircuitOpenError:
        # Return cached data or default
        return cache.get(f"user:{user_id}") or {"id": user_id, "name": "Unknown"}
```

### Retry Strategies

```
┌─────────────────────────────────────────────────────────────────┐
│                   Retry Strategies                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  IMMEDIATE RETRY                                                │
│  ────────────────                                               │
│  Retry immediately (no delay)                                  │
│  Use: Transient network glitches                               │
│  Risk: Amplifies load on failing service                       │
│                                                                 │
│  Attempt: 1     2     3                                        │
│           ├─────┼─────┼                                        │
│           │     │     │                                        │
│           ▼     ▼     ▼                                        │
│                                                                 │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  FIXED DELAY                                                    │
│  ───────────                                                    │
│  Wait same amount between retries                              │
│  Use: Simple cases                                             │
│                                                                 │
│  Attempt: 1     2     3                                        │
│           ├──1s─┼──1s─┼                                        │
│           │     │     │                                        │
│           ▼     ▼     ▼                                        │
│                                                                 │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  EXPONENTIAL BACKOFF                                            │
│  ─────────────────────                                          │
│  Double delay each retry: 1s, 2s, 4s, 8s...                    │
│  Use: Standard approach for most retries                       │
│                                                                 │
│  Attempt: 1     2        3              4                      │
│           ├──1s─┼───2s───┼─────4s──────┼                       │
│           │     │        │             │                        │
│           ▼     ▼        ▼             ▼                        │
│                                                                 │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  EXPONENTIAL BACKOFF WITH JITTER (RECOMMENDED)                 │
│  ─────────────────────────────────────────────                  │
│  Add randomness to prevent thundering herd                     │
│                                                                 │
│  delay = min(cap, base * 2^attempt) + random(0, 1000ms)        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

```python
import random
import asyncio

async def retry_with_exponential_backoff(
    func,
    max_retries: int = 5,
    base_delay: float = 1.0,
    max_delay: float = 60.0,
    jitter: bool = True,
    retryable_exceptions: tuple = (Exception,)
):
    """
    Retry with exponential backoff and optional jitter
    """
    last_exception = None
    
    for attempt in range(max_retries):
        try:
            return await func()
        except retryable_exceptions as e:
            last_exception = e
            
            if attempt == max_retries - 1:
                raise  # Last attempt, raise exception
            
            # Calculate delay
            delay = min(max_delay, base_delay * (2 ** attempt))
            
            # Add jitter (±25%)
            if jitter:
                delay = delay * (0.75 + random.random() * 0.5)
            
            print(f"Attempt {attempt + 1} failed, retrying in {delay:.2f}s")
            await asyncio.sleep(delay)
    
    raise last_exception
```

### Bulkhead Pattern

```
┌─────────────────────────────────────────────────────────────────┐
│                   Bulkhead Pattern                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Inspired by ship compartments that prevent total flooding     │
│                                                                 │
│  WITHOUT BULKHEAD:                                              │
│  ─────────────────                                              │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │              Shared Thread Pool (100)                   │   │
│  │  ┌───────────────────────────────────────────────────┐  │   │
│  │  │ Service A │ Service B │ Service C │ Service D     │  │   │
│  │  └───────────────────────────────────────────────────┘  │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  If Service B is slow → Uses all 100 threads                   │
│  → Services A, C, D also fail!                                 │
│                                                                 │
│  WITH BULKHEAD:                                                 │
│  ──────────────                                                 │
│  ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐  │
│  │ Service A  │ │ Service B  │ │ Service C  │ │ Service D  │  │
│  │ Pool: 25   │ │ Pool: 25   │ │ Pool: 25   │ │ Pool: 25   │  │
│  └────────────┘ └────────────┘ └────────────┘ └────────────┘  │
│                                                                 │
│  If Service B is slow → Only B's 25 threads blocked           │
│  → Services A, C, D continue working!                          │
│                                                                 │
│  Implementation options:                                       │
│  • Separate thread pools per dependency                        │
│  • Semaphores to limit concurrent calls                        │
│  • Separate processes per service                              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

```python
import asyncio
from contextlib import asynccontextmanager

class Bulkhead:
    """
    Limits concurrent calls to a dependency
    """
    
    def __init__(self, name: str, max_concurrent: int):
        self.name = name
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.max_concurrent = max_concurrent
        self.current = 0
    
    @asynccontextmanager
    async def acquire(self, timeout: float = 10.0):
        try:
            acquired = await asyncio.wait_for(
                self.semaphore.acquire(),
                timeout=timeout
            )
            self.current += 1
            yield
        except asyncio.TimeoutError:
            raise BulkheadFullError(
                f"Bulkhead '{self.name}' is full ({self.max_concurrent} concurrent)"
            )
        finally:
            self.semaphore.release()
            self.current -= 1


# Usage
payment_bulkhead = Bulkhead("payment-service", max_concurrent=20)
inventory_bulkhead = Bulkhead("inventory-service", max_concurrent=50)

async def process_order(order):
    async with payment_bulkhead.acquire():
        payment = await payment_service.charge(order)
    
    async with inventory_bulkhead.acquire():
        await inventory_service.reserve(order.items)
```

## Health Checks

### Health Check Types

```
┌─────────────────────────────────────────────────────────────────┐
│                   Health Check Types                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  LIVENESS CHECK                                                 │
│  ─────────────                                                  │
│  "Is the process running?"                                     │
│  If fails: Restart the container/process                       │
│                                                                 │
│  GET /health/live → 200 OK                                     │
│                                                                 │
│  Check:                                                        │
│  • Process responding                                          │
│  • Not deadlocked                                              │
│                                                                 │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  READINESS CHECK                                                │
│  ───────────────                                                │
│  "Can it handle traffic?"                                      │
│  If fails: Remove from load balancer                           │
│                                                                 │
│  GET /health/ready → 200 OK or 503 Not Ready                   │
│                                                                 │
│  Check:                                                        │
│  • Database connection works                                   │
│  • Cache connection works                                      │
│  • Required dependencies reachable                             │
│  • Warmup complete                                             │
│                                                                 │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  DEEP HEALTH CHECK (Use sparingly!)                            │
│  ────────────────                                               │
│  "Is everything working?"                                      │
│  Used for: Monitoring dashboards, not load balancers           │
│                                                                 │
│  GET /health/deep → { db: ok, cache: ok, queue: ok }          │
│                                                                 │
│  Warning: Can be expensive, rate limit!                        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

```python
from fastapi import FastAPI, Response
from datetime import datetime

app = FastAPI()

@app.get("/health/live")
async def liveness():
    """Just checks if the process is alive"""
    return {"status": "alive", "timestamp": datetime.utcnow().isoformat()}

@app.get("/health/ready")
async def readiness(response: Response):
    """Checks if we can handle traffic"""
    checks = {}
    
    # Check database
    try:
        await db.execute("SELECT 1")
        checks["database"] = "ok"
    except Exception as e:
        checks["database"] = f"error: {str(e)}"
        response.status_code = 503
    
    # Check Redis
    try:
        await redis.ping()
        checks["redis"] = "ok"
    except Exception as e:
        checks["redis"] = f"error: {str(e)}"
        response.status_code = 503
    
    # Check if warmup complete
    if not app.state.warmup_complete:
        checks["warmup"] = "in progress"
        response.status_code = 503
    else:
        checks["warmup"] = "complete"
    
    return {
        "status": "ready" if response.status_code == 200 else "not ready",
        "checks": checks
    }
```

## Timeouts

### Timeout Hierarchy

```
┌─────────────────────────────────────────────────────────────────┐
│                   Timeout Strategy                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Client ──► API Gateway ──► Service A ──► Service B ──► DB    │
│    │            │               │             │           │     │
│    │            │               │             │           │     │
│   10s          8s              5s            3s          1s    │
│    │            │               │             │           │     │
│    └────────────┴───────────────┴─────────────┴───────────┘     │
│                                                                 │
│  Rule: Outer timeout > Inner timeout                           │
│  Why: Give inner calls time to fail and retry                  │
│                                                                 │
│  Example settings:                                             │
│  • Database query: 1 second (+ 1 retry = 2s max)               │
│  • Internal service: 3 seconds (includes DB time)              │
│  • API endpoint: 8 seconds (includes all internal)             │
│  • Client: 10 seconds (includes network latency)               │
│                                                                 │
│  Anti-pattern:                                                 │
│  • Client: 5s, Service: 10s → Client times out, but server    │
│    keeps working! Wasted resources.                            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Deadline Propagation

```python
import time
from contextvars import ContextVar

# Context variable for deadline
deadline_ctx: ContextVar[float] = ContextVar('deadline', default=None)

def with_deadline(timeout_seconds: float):
    """Set deadline for current request"""
    deadline = time.time() + timeout_seconds
    deadline_ctx.set(deadline)
    return deadline

def remaining_time() -> float:
    """Get remaining time until deadline"""
    deadline = deadline_ctx.get()
    if deadline is None:
        return float('inf')
    return max(0, deadline - time.time())

async def call_service(service_name: str, payload: dict):
    """Call service with propagated deadline"""
    remaining = remaining_time()
    
    if remaining <= 0:
        raise DeadlineExceeded("Request deadline already passed")
    
    # Use remaining time as timeout (with buffer)
    timeout = min(remaining * 0.9, 30.0)  # 90% of remaining, max 30s
    
    try:
        async with asyncio.timeout(timeout):
            return await http_client.post(
                f"http://{service_name}/api",
                json=payload,
                headers={"X-Deadline": str(deadline_ctx.get())}
            )
    except asyncio.TimeoutError:
        raise DeadlineExceeded(f"Timeout calling {service_name}")
```

## Graceful Degradation

```
┌─────────────────────────────────────────────────────────────────┐
│              Graceful Degradation Strategies                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  STRATEGY 1: Fallback to Cache                                 │
│  ─────────────────────────────                                  │
│  Primary: Real-time data                                       │
│  Fallback: Cached data (might be stale)                        │
│                                                                 │
│  Example: Product catalog                                      │
│  • Try: Get from product service                               │
│  • Fallback: Return cached product info                        │
│                                                                 │
│  STRATEGY 2: Fallback to Default                               │
│  ────────────────────────────────                               │
│  Primary: Personalized content                                 │
│  Fallback: Generic content                                     │
│                                                                 │
│  Example: Recommendations                                      │
│  • Try: Get personalized recommendations                       │
│  • Fallback: Show trending/popular items                       │
│                                                                 │
│  STRATEGY 3: Feature Flags                                     │
│  ───────────────────────────                                    │
│  Disable non-critical features when under stress               │
│                                                                 │
│  Example: E-commerce under load                                │
│  • Disable: Product reviews, recommendations                   │
│  • Keep: Core checkout flow                                    │
│                                                                 │
│  STRATEGY 4: Read-Only Mode                                    │
│  ─────────────────────────────                                  │
│  When writes fail, allow reads only                            │
│                                                                 │
│  Example: Social media                                         │
│  • Can't post/like (write)                                     │
│  • Can still browse feed (read)                                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Senior Interview Questions

<Accordion title="How do you achieve 99.99% availability?">
**Key components**:
1. **Redundancy**: At least 2 of everything (servers, DBs, regions)
2. **Load balancing**: Automatic failover when node fails
3. **Health checks**: Detect failures in seconds
4. **Auto-scaling**: Handle traffic spikes
5. **Multi-region**: Survive region outages
6. **Chaos engineering**: Regularly test failure scenarios

**Math**: 99.99% = 52 minutes downtime/year
- Single component at 99.9% can't achieve 99.99%
- Need redundancy: 2 components at 99.9% = 99.9999% (if independent)
</Accordion>

<Accordion title="How do you handle partial failures in distributed transactions?">
**Saga Pattern**:
1. Each step has a compensating action
2. If step N fails, run compensations for steps N-1 to 1
3. Track saga state in database

**Example**:
```
1. Create order → Compensate: Cancel order
2. Reserve inventory → Compensate: Release inventory
3. Charge payment → Compensate: Refund payment
4. Ship order → Compensate: Cancel shipment

If step 3 fails:
- Refund payment (if partially charged)
- Release inventory
- Cancel order
```
</Accordion>

<Accordion title="How do you prevent cascading failures?">
**Defense layers**:
1. **Circuit breakers**: Stop calling failing service
2. **Timeouts**: Don't wait forever
3. **Bulkheads**: Isolate failures to one service
4. **Rate limiting**: Prevent overload
5. **Load shedding**: Reject low-priority requests
6. **Fallbacks**: Degrade gracefully

**Key insight**: "Fast failure is better than slow failure. If a service is struggling, fail fast and use fallback."
</Accordion>

<Accordion title="How do you test system reliability?">
**Chaos Engineering approach**:
1. **Define steady state**: Normal metrics (latency, error rate)
2. **Form hypothesis**: "System handles server failure"
3. **Inject failure**: Kill a server
4. **Observe**: Did metrics stay within bounds?
5. **Fix and repeat**

**Types of failures to test**:
- Server crashes
- Network partitions
- High latency
- Disk full
- Memory exhaustion
- Clock skew
- Dependency outages
</Accordion>
