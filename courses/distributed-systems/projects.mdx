---
title: "Capstone Projects"
sidebarTitle: "Capstone Projects"
description: "Apply your distributed systems knowledge by building production-grade systems from scratch."
icon: "laptop-code"
---

# Capstone Projects

The best way to master distributed systems is to build them. These projects are designed to challenge your understanding of consensus, replication, partitioning, and fault tolerance.

<Info>
**Staff+ Level Expectation**: For these projects, don't just "make it work." Focus on **observability**, **determinism**, **performance benchmarking**, and **rigorous testing** (e.g., Jepsen-style failure injection).
</Info>

---

## Project 1: Distributed Key-Value Store (The "Mini-Etcd")

Build a strongly consistent, sharded key-value store that survives node failures and network partitions.

### Technical Requirements
- **Consensus**: Implement the **Raft protocol** from scratch (Leader Election, Log Replication, Safety).
- **Storage**: Use an **LSM-tree** or **B-Tree** for local storage on each node.
- **Partitioning**: Implement **Multi-Raft** or **Sharding** to scale beyond a single Raft group.
- **API**: gRPC or Thrift interface for clients.
- **Client Library**: Implement a client with transparent retries and leader discovery.

### Milestones
1.  **Single-Node Store**: Basic GET/PUT with persistence.
2.  **Raft Leader Election**: Nodes can elect a leader and handle heartbeats.
3.  **Log Replication**: Leader replicates entries to followers; commits only after quorum.
4.  **Log Compaction**: Implement snapshots to prevent logs from growing infinitely.
5.  **Sharding**: Partition keys across multiple Raft groups using consistent hashing.

### Challenge: Jepsen Testing
Use a tool like **Maelstrom** or a custom Docker-based orchestrator to inject:
- **Network Partitions**: Can your system maintain consistency during a split-brain?
- **Process Crashes**: Does the system recover state after a reboot?
- **Clock Skew**: Does your implementation rely too heavily on synchronized clocks?

---

## Project 2: Distributed Message Queue (The "Mini-Kafka")

Design and build a high-throughput, partitioned message queue.

### Technical Requirements
- **Storage**: Use a **segmented append-only log** with zero-copy I/O (sendfile).
- **Replication**: Implement **In-Sync Replicas (ISR)** model for high availability.
- **Coordination**: Use Zookeeper or a custom Raft-based controller for metadata (partitions, leader election).
- **Consumption**: Implement **Consumer Groups** with server-side partition rebalancing.
- **Durability**: Configurable `acks` (0, 1, all).

### Milestones
1.  **Append-Only Log**: Efficient disk storage with index files.
2.  **Producer/Consumer API**: Basic pub-sub functionality.
3.  **Partitioning**: Distribute data across multiple brokers.
4.  **Replication**: High-watermark tracking and follower synchronization.
5.  **Consumer Rebalancing**: Automatically reassign partitions when a consumer joins or leaves.

### Challenge: Exactly-Once Semantics
Implement **Transactional Producing** and **Idempotent Consumers**. Ensure that even if a producer retries, a message is only written once, and even if a consumer crashes, it processes each message exactly once.

---

## Project 3: Distributed Rate Limiter (The "Edge-Limiter")

Build a globally distributed rate limiting service with sub-millisecond latency.

### Technical Requirements
- **Algorithm**: Implement **Generic Cell Rate Algorithm (GCRA)** or **Sliding Window**.
- **State Management**: Hybrid approach (Local cache + Centralized sync).
- **Communication**: Gossip protocol (SWIM) for cluster membership and health checking.
- **Performance**: Must handle 100k+ RPS with < 1ms overhead.

### Milestones
1.  **Local Limiter**: Memory-efficient bucket implementation.
2.  **Cluster Discovery**: Nodes find each other via Gossip.
3.  **State Synchronization**: Efficiently sync counters across nodes without a central bottleneck.
4.  **Observability**: Real-time metrics on dropped vs. allowed requests.

---

## How to Approach These Projects

1.  **Start with the Spec**: Write down your safety and liveness guarantees before coding.
2.  **Instrument Early**: Add tracing and metrics from Day 1. You can't debug a distributed system without them.
3.  **Simulate Failures**: Don't wait for production to see if your Raft implementation works. Use **Deterministic Simulation Testing**.
4.  **Code in Go, Rust, or Java**: These languages have the best ecosystems for distributed systems (gRPC, Raft libraries for reference, etc.).

---

## Recommended Resources
- **Maelstrom**: A workbench for learning distributed systems by implementation.
- **Distributed Systems Labs (MIT 6.824)**: The gold standard for academic DistSys projects.
- **FoundationDB Papers**: Excellent insights into simulation testing.
