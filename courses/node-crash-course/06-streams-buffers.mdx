---
title: "06. Streams & Buffers"
description: "Understand how to handle data efficiently with Streams and Buffers."
---

# Streams & Buffers

## Buffers

JavaScript (in the browser) has historically been poor at handling binary data. Node.js introduced the `Buffer` class to handle binary data efficiently.

A **Buffer** is a chunk of memory that stores raw binary data. It is similar to an array of integers but corresponds to a raw memory allocation outside the V8 heap.

### Creating a Buffer

```javascript
// Create a buffer of 10 bytes
const buf1 = Buffer.alloc(10);

// Create a buffer from a string
const buf2 = Buffer.from('Hello World');

console.log(buf2); 
// Output: <Buffer 48 65 6c 6c 6f 20 57 6f 72 6c 64>
console.log(buf2.toString()); 
// Output: Hello World
```

## Streams

Streams are objects that let you read data from a source or write data to a destination in continuous chunks.

There are four types of streams:
1.  **Readable**: Stream you can read from (e.g., `fs.createReadStream`).
2.  **Writable**: Stream you can write to (e.g., `fs.createWriteStream`).
3.  **Duplex**: Stream that is both Readable and Writable (e.g., `net.Socket`).
4.  **Transform**: Stream that can modify or transform the data as it is written and read (e.g., `zlib.createGzip`).

### Why Streams?

If you want to read a massive file (e.g., 2GB video) and send it to a client:
- **Without Streams**: You read the entire 2GB into memory. If 100 users do this, your server crashes.
- **With Streams**: You read small chunks (e.g., 64KB) and send them one by one. Memory usage remains low.

### Readable Stream Example

```javascript
const fs = require('fs');

const readStream = fs.createReadStream('largefile.txt', { encoding: 'utf8' });

readStream.on('data', (chunk) => {
  console.log('Received chunk:', chunk.length);
});

readStream.on('end', () => {
  console.log('Finished reading file.');
});
```

### Piping

Piping is a mechanism where we provide the output of one stream as the input to another stream. It is mainly used to get data from one stream and pass it to another.

```javascript
const fs = require('fs');
const zlib = require('zlib');

const gzip = zlib.createGzip();
const readStream = fs.createReadStream('input.txt');
const writeStream = fs.createWriteStream('input.txt.gz');

// Read -> Compress -> Write
readStream.pipe(gzip).pipe(writeStream);
```

## Summary

- **Buffers** are used to handle binary data.
- **Streams** allow processing large data efficiently by breaking it into chunks.
- **Piping** connects a readable stream to a writable stream.
- Using streams prevents high memory consumption when handling large files.
