---
title: "Project: Image Similarity Search Engine"
sidebarTitle: "Project 1"
description: "Build a real image search engine using vectors and similarity measures"
icon: "code"
---

# Project 1: Image Similarity Search Engine

Build a working image search engine that finds similar images using vector representations and cosine similarity. This project integrates everything you've learned about vectors, dot products, and similarity measures.

<Info>
**Estimated Time**: 2-3 hours  
**Difficulty**: Beginner  
**Concepts Used**: Vectors, dot product, cosine similarity, normalization  
**Dataset**: 1000 product images
</Info>

---

## Project Overview

### What You'll Build

An image search engine that:
1. Converts images to vector representations
2. Computes similarity between images
3. Returns the top-K most similar images to a query
4. Visualizes results

### Why This Matters

**Real-World Applications**:
- **E-commerce**: "Find similar products"
- **Pinterest**: Visual search
- **Google Images**: Reverse image search
- **Fashion**: "Find this outfit"

**ML Concepts**:
- Feature extraction (images → vectors)
- Similarity metrics (cosine similarity)
- Nearest neighbor search
- High-dimensional vector spaces

---

## Part 1: Understanding the Problem

### How Do We Represent Images as Vectors?

**Method 1: Raw Pixels** (Simple but effective for similar images)

```python
import numpy as np
from PIL import Image

def image_to_vector_simple(image_path, size=(64, 64)):
    """
    Convert image to a vector using raw pixel values.
    
    Args:
        image_path: Path to image file
        size: Resize dimensions (smaller = faster)
    
    Returns:
        1D numpy array of pixel values
    """
    # Load and convert to grayscale
    img = Image.open(image_path).convert('L')
    
    # Resize to standard size
    img = img.resize(size)
    
    # Convert to numpy array and flatten
    img_array = np.array(img)
    vector = img_array.flatten()
    
    # Normalize to [0, 1]
    vector = vector / 255.0
    
    return vector

# Example
img_vector = image_to_vector_simple('product1.jpg')
print(f"Vector shape: {img_vector.shape}")  # (4096,) for 64x64
print(f"First 10 values: {img_vector[:10]}")
```

**Why normalize?** So all images are on the same scale (0-1 instead of 0-255).

**Method 2: Color Histogram** (Better for different viewpoints)

```python
def image_to_histogram(image_path, bins=32):
    """
    Convert image to color histogram vector.
    
    Args:
        image_path: Path to image file
        bins: Number of bins per color channel
    
    Returns:
        1D numpy array of histogram values
    """
    # Load image (keep RGB)
    img = Image.open(image_path).convert('RGB')
    img_array = np.array(img)
    
    # Compute histogram for each channel
    hist_r = np.histogram(img_array[:,:,0], bins=bins, range=(0, 256))[0]
    hist_g = np.histogram(img_array[:,:,1], bins=bins, range=(0, 256))[0]
    hist_b = np.histogram(img_array[:,:,2], bins=bins, range=(0, 256))[0]
    
    # Concatenate
    vector = np.concatenate([hist_r, hist_g, hist_b])
    
    # Normalize
    vector = vector / vector.sum()
    
    return vector

# Example
hist_vector = image_to_histogram('product1.jpg')
print(f"Histogram shape: {hist_vector.shape}")  # (96,) for 32 bins × 3 channels
```

**Why histograms?** They're invariant to small translations and rotations.

---

## Part 2: Computing Similarity

### Cosine Similarity (Direction-Based)

```python
def cosine_similarity(v1, v2):
    """
    Compute cosine similarity between two vectors.
    
    Formula: cos(θ) = (v1 · v2) / (||v1|| ||v2||)
    
    Returns:
        Similarity score in [-1, 1]
        1 = identical direction
        0 = orthogonal
        -1 = opposite direction
    """
    dot_product = np.dot(v1, v2)
    norm_v1 = np.linalg.norm(v1)
    norm_v2 = np.linalg.norm(v2)
    
    # Avoid division by zero
    if norm_v1 == 0 or norm_v2 == 0:
        return 0.0
    
    return dot_product / (norm_v1 * norm_v2)

# Test
v1 = np.array([1, 2, 3])
v2 = np.array([2, 4, 6])  # Same direction, different magnitude
v3 = np.array([1, 0, 0])  # Different direction

print(f"v1 vs v2: {cosine_similarity(v1, v2):.3f}")  # 1.0 (identical)
print(f"v1 vs v3: {cosine_similarity(v1, v3):.3f}")  # 0.267 (different)
```

### Euclidean Distance (Position-Based)

```python
def euclidean_distance(v1, v2):
    """
    Compute Euclidean distance between two vectors.
    
    Formula: ||v1 - v2|| = sqrt(Σ(v1_i - v2_i)²)
    
    Returns:
        Distance (0 = identical, larger = more different)
    """
    return np.linalg.norm(v1 - v2)

# Test
print(f"v1 vs v2: {euclidean_distance(v1, v2):.3f}")  # 3.742
print(f"v1 vs v3: {euclidean_distance(v1, v3):.3f}")  # 2.449
```

**Which to use?**
- **Cosine**: When magnitude doesn't matter (text, images with different brightness)
- **Euclidean**: When absolute values matter (coordinates, measurements)

For images, **cosine similarity** is usually better!

---

## Part 3: Building the Search Engine

### Step 1: Create Image Database

```python
import os
from glob import glob
from tqdm import tqdm

class ImageSearchEngine:
    def __init__(self, image_dir, method='histogram'):
        """
        Initialize search engine.
        
        Args:
            image_dir: Directory containing images
            method: 'pixels' or 'histogram'
        """
        self.image_dir = image_dir
        self.method = method
        self.image_paths = []
        self.image_vectors = []
        
    def index_images(self):
        """
        Convert all images to vectors and store them.
        """
        # Find all images
        extensions = ['*.jpg', '*.jpeg', '*.png']
        for ext in extensions:
            self.image_paths.extend(glob(os.path.join(self.image_dir, ext)))
        
        print(f"Found {len(self.image_paths)} images")
        
        # Convert to vectors
        print("Converting images to vectors...")
        for img_path in tqdm(self.image_paths):
            try:
                if self.method == 'pixels':
                    vector = image_to_vector_simple(img_path)
                else:
                    vector = image_to_histogram(img_path)
                
                self.image_vectors.append(vector)
            except Exception as e:
                print(f"Error processing {img_path}: {e}")
        
        # Convert to numpy array for faster computation
        self.image_vectors = np.array(self.image_vectors)
        
        print(f"Indexed {len(self.image_vectors)} images")
        print(f"Vector shape: {self.image_vectors.shape}")
    
    def search(self, query_path, top_k=5):
        """
        Find top-K most similar images to query.
        
        Args:
            query_path: Path to query image
            top_k: Number of results to return
        
        Returns:
            List of (image_path, similarity_score) tuples
        """
        # Convert query to vector
        if self.method == 'pixels':
            query_vector = image_to_vector_simple(query_path)
        else:
            query_vector = image_to_histogram(query_path)
        
        # Compute similarities with all images
        similarities = []
        for i, img_vector in enumerate(self.image_vectors):
            sim = cosine_similarity(query_vector, img_vector)
            similarities.append((self.image_paths[i], sim))
        
        # Sort by similarity (descending)
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # Return top-K
        return similarities[:top_k]
    
    def search_fast(self, query_path, top_k=5):
        """
        Faster version using vectorized operations.
        """
        # Convert query to vector
        if self.method == 'pixels':
            query_vector = image_to_vector_simple(query_path)
        else:
            query_vector = image_to_histogram(query_path)
        
        # Vectorized cosine similarity
        # cos(θ) = (A · B) / (||A|| ||B||)
        
        # Normalize query vector
        query_norm = query_vector / np.linalg.norm(query_vector)
        
        # Normalize all database vectors
        db_norms = np.linalg.norm(self.image_vectors, axis=1, keepdims=True)
        db_normalized = self.image_vectors / db_norms
        
        # Compute all similarities at once (matrix-vector multiplication!)
        similarities = db_normalized @ query_norm
        
        # Get top-K indices
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        # Return results
        results = [(self.image_paths[i], similarities[i]) for i in top_indices]
        return results
```

### Step 2: Use the Search Engine

```python
# Initialize
engine = ImageSearchEngine('product_images/', method='histogram')

# Index all images
engine.index_images()

# Search
query_image = 'query.jpg'
results = engine.search_fast(query_image, top_k=5)

# Display results
print(f"\nTop 5 similar images to {query_image}:")
for i, (img_path, score) in enumerate(results, 1):
    print(f"{i}. {os.path.basename(img_path)}: {score:.3f}")
```

**Output**:
```
Found 1000 images
Converting images to vectors...
100%|████████████████████| 1000/1000 [00:15<00:00, 65.2it/s]
Indexed 1000 images
Vector shape: (1000, 96)

Top 5 similar images to query.jpg:
1. product_042.jpg: 0.987
2. product_156.jpg: 0.923
3. product_089.jpg: 0.891
4. product_234.jpg: 0.876
5. product_567.jpg: 0.854
```

---

## Part 4: Visualizing Results

```python
import matplotlib.pyplot as plt

def visualize_results(query_path, results, num_results=5):
    """
    Display query image and top results.
    """
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # Query image
    query_img = Image.open(query_path)
    axes[0, 0].imshow(query_img)
    axes[0, 0].set_title('Query Image', fontsize=14, fontweight='bold')
    axes[0, 0].axis('off')
    
    # Hide extra subplot
    axes[0, 1].axis('off')
    axes[0, 2].axis('off')
    
    # Top results
    for i, (img_path, score) in enumerate(results[:num_results]):
        row = 1 + i // 3
        col = i % 3
        
        if row < 2:  # Only show first 3 results
            img = Image.open(img_path)
            axes[row, col].imshow(img)
            axes[row, col].set_title(f'#{i+1}: {score:.3f}', fontsize=12)
            axes[row, col].axis('off')
    
    plt.tight_layout()
    plt.savefig('search_results.png', dpi=150, bbox_inches='tight')
    plt.show()

# Use it
visualize_results(query_image, results)
```

---

## Part 5: Performance Analysis

### Timing Comparison

```python
import time

# Slow version (loop)
start = time.time()
results_slow = engine.search(query_image, top_k=5)
time_slow = time.time() - start

# Fast version (vectorized)
start = time.time()
results_fast = engine.search_fast(query_image, top_k=5)
time_fast = time.time() - start

print(f"Slow version: {time_slow:.3f}s")
print(f"Fast version: {time_fast:.3f}s")
print(f"Speedup: {time_slow/time_fast:.1f}x")
```

**Output**:
```
Slow version: 0.245s
Fast version: 0.003s
Speedup: 81.7x
```

**Why so much faster?** Vectorized operations use optimized C/Fortran code and can leverage CPU SIMD instructions!

### Memory Usage

```python
import sys

# Size of database
num_images = len(engine.image_vectors)
vector_dim = engine.image_vectors.shape[1]
total_bytes = engine.image_vectors.nbytes

print(f"Number of images: {num_images}")
print(f"Vector dimension: {vector_dim}")
print(f"Total memory: {total_bytes / 1024 / 1024:.2f} MB")
print(f"Per image: {total_bytes / num_images / 1024:.2f} KB")
```

---

## Part 6: Improvements & Extensions

### 1. Better Feature Extraction

```python
# Use pre-trained neural network (ResNet, VGG, etc.)
from torchvision import models, transforms
import torch

def image_to_vector_deep(image_path):
    """
    Extract features using pre-trained ResNet.
    """
    # Load pre-trained model
    model = models.resnet18(pretrained=True)
    model.eval()
    
    # Remove final classification layer
    feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])
    
    # Preprocess image
    transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0)
    
    # Extract features
    with torch.no_grad():
        features = feature_extractor(img_tensor)
    
    # Flatten to vector
    vector = features.squeeze().numpy()
    
    return vector

# This gives 512-dimensional vectors with much better semantic understanding!
```

### 2. Faster Search with Approximate Nearest Neighbors

```python
# For large databases (millions of images), use FAISS or Annoy
import faiss

def build_faiss_index(vectors):
    """
    Build FAISS index for fast approximate search.
    """
    dimension = vectors.shape[1]
    
    # Create index
    index = faiss.IndexFlatL2(dimension)  # L2 distance
    
    # Add vectors
    index.add(vectors.astype('float32'))
    
    return index

def search_faiss(index, query_vector, top_k=5):
    """
    Search using FAISS index.
    """
    query = query_vector.astype('float32').reshape(1, -1)
    distances, indices = index.search(query, top_k)
    return indices[0], distances[0]

# Usage
index = build_faiss_index(engine.image_vectors)
indices, distances = search_faiss(index, query_vector, top_k=5)
```

### 3. Multi-Modal Search

```python
def search_by_text_and_image(text_query, image_query, alpha=0.5):
    """
    Combine text and image search.
    
    Args:
        text_query: Text description
        image_query: Image path
        alpha: Weight for image similarity (1-alpha for text)
    """
    # Get image similarity
    img_similarities = engine.search_fast(image_query, top_k=100)
    
    # Get text similarity (using image captions)
    # text_similarities = search_by_text(text_query, top_k=100)
    
    # Combine scores
    # combined = alpha * img_sim + (1-alpha) * text_sim
    
    pass  # Implementation left as exercise
```

---

## Challenges & Exercises

### Challenge 1: Batch Search

Modify the search engine to handle multiple queries at once:

```python
def search_batch(self, query_paths, top_k=5):
    """
    Search for multiple queries simultaneously.
    
    Args:
        query_paths: List of query image paths
        top_k: Number of results per query
    
    Returns:
        List of result lists
    """
    # TODO: Implement this!
    # Hint: Convert all queries to vectors, then use matrix multiplication
    pass
```

<details>
<summary>Solution</summary>

```python
def search_batch(self, query_paths, top_k=5):
    # Convert all queries to vectors
    query_vectors = []
    for path in query_paths:
        if self.method == 'pixels':
            vec = image_to_vector_simple(path)
        else:
            vec = image_to_histogram(path)
        query_vectors.append(vec)
    
    query_vectors = np.array(query_vectors)
    
    # Normalize
    query_norms = np.linalg.norm(query_vectors, axis=1, keepdims=True)
    query_normalized = query_vectors / query_norms
    
    db_norms = np.linalg.norm(self.image_vectors, axis=1, keepdims=True)
    db_normalized = self.image_vectors / db_norms
    
    # Matrix multiplication: (num_queries, dim) @ (dim, num_db) = (num_queries, num_db)
    similarities = query_normalized @ db_normalized.T
    
    # Get top-K for each query
    results = []
    for i in range(len(query_paths)):
        top_indices = np.argsort(similarities[i])[::-1][:top_k]
        query_results = [(self.image_paths[j], similarities[i, j]) for j in top_indices]
        results.append(query_results)
    
    return results
```
</details>

### Challenge 2: Evaluation Metrics

Implement precision@K and recall@K:

```python
def evaluate_search(ground_truth, predictions, k=5):
    """
    Evaluate search quality.
    
    Args:
        ground_truth: Set of relevant image IDs
        predictions: List of predicted image IDs (ordered by relevance)
        k: Number of top results to consider
    
    Returns:
        precision, recall
    """
    # TODO: Implement this!
    pass
```

### Challenge 3: Diversity

Modify search to return diverse results (not all similar to each other):

```python
def search_diverse(self, query_path, top_k=5, diversity_weight=0.3):
    """
    Return diverse results.
    
    Strategy: Penalize results similar to already selected results.
    """
    # TODO: Implement this!
    pass
```

---

## Complete Code

Here's the full working implementation:

```python
# image_search.py

import numpy as np
from PIL import Image
import os
from glob import glob
from tqdm import tqdm
import matplotlib.pyplot as plt

def image_to_vector_simple(image_path, size=(64, 64)):
    img = Image.open(image_path).convert('L')
    img = img.resize(size)
    img_array = np.array(img)
    vector = img_array.flatten()
    vector = vector / 255.0
    return vector

def image_to_histogram(image_path, bins=32):
    img = Image.open(image_path).convert('RGB')
    img_array = np.array(img)
    
    hist_r = np.histogram(img_array[:,:,0], bins=bins, range=(0, 256))[0]
    hist_g = np.histogram(img_array[:,:,1], bins=bins, range=(0, 256))[0]
    hist_b = np.histogram(img_array[:,:,2], bins=bins, range=(0, 256))[0]
    
    vector = np.concatenate([hist_r, hist_g, hist_b])
    vector = vector / vector.sum()
    
    return vector

def cosine_similarity(v1, v2):
    dot_product = np.dot(v1, v2)
    norm_v1 = np.linalg.norm(v1)
    norm_v2 = np.linalg.norm(v2)
    
    if norm_v1 == 0 or norm_v2 == 0:
        return 0.0
    
    return dot_product / (norm_v1 * norm_v2)

class ImageSearchEngine:
    def __init__(self, image_dir, method='histogram'):
        self.image_dir = image_dir
        self.method = method
        self.image_paths = []
        self.image_vectors = []
        
    def index_images(self):
        extensions = ['*.jpg', '*.jpeg', '*.png']
        for ext in extensions:
            self.image_paths.extend(glob(os.path.join(self.image_dir, ext)))
        
        print(f"Found {len(self.image_paths)} images")
        
        print("Converting images to vectors...")
        for img_path in tqdm(self.image_paths):
            try:
                if self.method == 'pixels':
                    vector = image_to_vector_simple(img_path)
                else:
                    vector = image_to_histogram(img_path)
                
                self.image_vectors.append(vector)
            except Exception as e:
                print(f"Error processing {img_path}: {e}")
        
        self.image_vectors = np.array(self.image_vectors)
        
        print(f"Indexed {len(self.image_vectors)} images")
        print(f"Vector shape: {self.image_vectors.shape}")
    
    def search_fast(self, query_path, top_k=5):
        if self.method == 'pixels':
            query_vector = image_to_vector_simple(query_path)
        else:
            query_vector = image_to_histogram(query_path)
        
        query_norm = query_vector / np.linalg.norm(query_vector)
        
        db_norms = np.linalg.norm(self.image_vectors, axis=1, keepdims=True)
        db_normalized = self.image_vectors / db_norms
        
        similarities = db_normalized @ query_norm
        
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = [(self.image_paths[i], similarities[i]) for i in top_indices]
        return results

def visualize_results(query_path, results, num_results=5):
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    query_img = Image.open(query_path)
    axes[0, 0].imshow(query_img)
    axes[0, 0].set_title('Query Image', fontsize=14, fontweight='bold')
    axes[0, 0].axis('off')
    
    axes[0, 1].axis('off')
    axes[0, 2].axis('off')
    
    for i, (img_path, score) in enumerate(results[:3]):
        img = Image.open(img_path)
        axes[1, i].imshow(img)
        axes[1, i].set_title(f'#{i+1}: {score:.3f}', fontsize=12)
        axes[1, i].axis('off')
    
    plt.tight_layout()
    plt.savefig('search_results.png', dpi=150, bbox_inches='tight')
    plt.show()

if __name__ == '__main__':
    # Initialize and run
    engine = ImageSearchEngine('images/', method='histogram')
    engine.index_images()
    
    query = 'query.jpg'
    results = engine.search_fast(query, top_k=5)
    
    print(f"\nTop 5 similar images:")
    for i, (path, score) in enumerate(results, 1):
        print(f"{i}. {os.path.basename(path)}: {score:.3f}")
    
    visualize_results(query, results)
```

---

## Key Takeaways

✅ **Images can be represented as vectors** (pixels, histograms, deep features)  
✅ **Cosine similarity** measures how similar two vectors are  
✅ **Vectorized operations** are much faster than loops  
✅ **Matrix multiplication** enables batch processing  
✅ **Real-world ML** uses these exact techniques at scale  

---

## What's Next?

You've built a working image search engine using linear algebra! Next, we'll explore **eigenvalues and eigenvectors** to build even more powerful applications like face recognition and dimensionality reduction.

<Card title="Next: Eigenvalues & Eigenvectors" icon="arrow-right" href="/courses/math-for-ml-linear-algebra/04-eigenvalues">
  Learn the math behind PCA and face recognition
</Card>
