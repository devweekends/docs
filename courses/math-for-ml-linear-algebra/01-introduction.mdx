---
title: "Introduction to Linear Algebra for ML"
sidebarTitle: "Introduction"
description: "Why linear algebra is the language of machine learning"
icon: "rocket"
---

<Frame>
  <img src="/images/courses/math-for-ml-linear-algebra/linear-algebra-intro-concept.svg" alt="Linear Algebra for Machine Learning" />
</Frame>

# Linear Algebra for Machine Learning

## Have You Ever Wondered...

- How does **Spotify** know that if you like Coldplay, you might also like Imagine Dragons?
- How does **Instagram** apply those fancy filters to your photos in milliseconds?
- How does **Netflix** predict you'll rate a movie 4.2 stars before you've even watched it?
- How does **Google Photos** find all pictures of your dog without you tagging them?

**The answer to ALL of these is Linear Algebra.**

Not calculus. Not statistics. Linear Algebra. The math of lists, tables, and transformations.

<Warning>
**Real Talk**: You probably took linear algebra in college, got confused by abstract proofs about "vector spaces" and "linear independence," passed the exam, and forgot everything.

This time is different. We're going to make you **see** linear algebra, **use** it, and actually **enjoy** it.
</Warning>

<Info>
**Estimated Time**: 16-20 hours  
**Difficulty**: Beginner-friendly (we assume you forgot everything)  
**Prerequisites**: Basic Python, willingness to experiment  
**What You'll Build**: Spotify-style song recommender, Instagram-style filters, Netflix-style rating predictor
</Info>

---

## The "Aha!" Moment: Everything is a List of Numbers

Here's the secret that unlocks all of machine learning:

**Anything can be turned into a list of numbers. And once it's numbers, math can work magic.**

### Your Favorite Song → Numbers

```python
# Spotify represents every song as ~12 numbers
billie_eilish_bad_guy = [
    0.70,   # danceability (0-1)
    0.43,   # energy (0-1)  
    0.56,   # speechiness (0-1)
    0.32,   # acousticness (0-1)
    0.00,   # instrumentalness (0-1)
    0.36,   # liveness (0-1)
    0.68,   # valence/happiness (0-1)
    135.0,  # tempo (BPM)
    # ... more features
]

# This list IS a vector. That's it. A vector is just a list of numbers.
```

### Your Face → Numbers

```python
# A 100x100 pixel selfie = 10,000 numbers (brightness of each pixel)
# A neural network can compress this to just 128 numbers that capture "you-ness"

your_face_embedding = [0.23, -0.45, 0.89, ..., 0.12]  # 128 numbers

# Similar faces have similar numbers!
```

### A Netflix Movie → Numbers

```python
# Every movie can be described by hidden factors
inception = [
    0.95,   # "mind-bending" factor
    0.80,   # "action" factor  
    0.20,   # "romance" factor
    0.60,   # "visual spectacle" factor
    # ...
]
```

**This is the core insight**: Once everything is numbers, we can:
- **Compare** things (how similar are two songs?)
- **Transform** things (apply a filter to a photo)
- **Find patterns** (what do users who liked X also like?)
- **Compress** things (store a 10MB image in 100KB)

![Everything is Numbers](/images/courses/math-for-ml-linear-algebra/everything-is-numbers.svg)

---

## What You'll Actually Learn (And Why You'll Care)

<AccordionGroup>
  <Accordion title="Module 1: Vectors" icon="arrow-right">
    **Real-World Examples You Already Know:**
    - **GPS Navigation**: Your location is a vector `[latitude, longitude]`. Distance between two places? Vector math.
    - **Fitness Trackers**: Your daily stats `[steps, calories, heart_rate, sleep_hours]` — that's a vector describing your day.
    - **Job Matching**: LinkedIn represents you as `[skills, experience, education, location]` and finds similar candidates.
    - **Dating Apps**: Tinder/Hinge match you based on preference vectors. Similar vectors = potential match.
    
    **What You'll Build**: A similarity search engine (works for songs, jobs, or anything).
  </Accordion>
  
  <Accordion title="Module 2: Matrices" icon="grid">
    **Real-World Examples You Already Know:**
    - **Photo Editing**: Every Instagram filter is a matrix multiplication. Brightness, contrast, blur — all matrix operations.
    - **Video Games**: When you rotate your character, move the camera, or zoom in — that's matrix math happening 60 times per second.
    - **Spreadsheets**: Excel pivot tables, VLOOKUP across sheets — you're doing matrix operations without knowing it.
    - **Maps/GPS**: Transforming GPS coordinates to screen pixels involves matrix multiplication.
    
    **What You'll Build**: Your own photo filter app and a 2D game transformation engine.
  </Accordion>
  
  <Accordion title="Module 3: Eigenvalues & PCA" icon="compress">
    **Real-World Examples You Already Know:**
    - **Surveys**: 50 questions reduce to 3-4 "personality types" — that's PCA finding the key dimensions.
    - **Stock Market**: Hundreds of stocks move together because of 5-10 hidden factors (economy, interest rates, oil prices).
    - **Customer Segments**: Millions of customers cluster into 5-6 types based on purchasing patterns.
    - **Compression**: JPEG images keep 90% quality with 10% file size by keeping only the important eigenvectors.
    
    **What You'll Build**: Image compressor and customer segmentation system.
  </Accordion>
  
  <Accordion title="Module 4: SVD & Recommendations" icon="stars">
    **Real-World Examples You Already Know:**
    - **"Customers who bought X also bought Y"**: Amazon uses matrix factorization to find these patterns.
    - **YouTube Recommendations**: "Because you watched X" — they decomposed your viewing history.
    - **Spell Check**: "Did you mean...?" often uses SVD to find similar words.
    - **Fraud Detection**: Normal transactions form patterns; fraud breaks those patterns.
    
    **What You'll Build**: A working recommendation engine using real MovieLens data.
  </Accordion>
</AccordionGroup>

---

## Your Learning Journey

<Steps>
  <Step title="Week 1-2: Vectors">
    Learn to see everything as vectors. Build a song/image similarity search engine.
  </Step>
  <Step title="Week 2-3: Matrices">
    Master transformations. Build Instagram-style photo filters from scratch.
  </Step>
  <Step title="Week 3-4: Eigenvalues & PCA">
    Find hidden patterns. Compress images, reduce dimensions, and understand what your data really contains.
  </Step>
  <Step title="Week 4-5: SVD & Recommendations">
    The crown jewel. Build a Netflix-style recommendation engine that predicts ratings.
  </Step>
</Steps>

---

## Why Most Math Courses Fail (And How This One's Different)

<Tabs>
  <Tab title="Traditional Course">
    1. Definition of a vector space
    2. Axioms of vector addition  
    3. Proof of linear independence
    4. Abstract theorem
    5. *"Exercise left to the reader"*
    6. **Student falls asleep**
  </Tab>
  <Tab title="This Course">
    1. **"How does your GPS calculate the fastest route?"**
    2. Locations are vectors. Distances are vector operations.
    3. Here's how Google Maps actually works.
    4. **Here's working code you can run**
    5. **Now modify it for your own project**
    6. *"Oh, THAT's what a dot product does!"*
  </Tab>
</Tabs>

<Tip>
**Our Promise**: Every concept will be:
- Explained with a **real-world app** you use daily
- Visualized with **clear diagrams**
- Coded in **Python you can run**
- Practiced with **projects you'll want to show off**
</Tip>

---

## Prerequisites (Honestly, Not Much)

**What You Need:**
- Basic Python: Variables, lists, loops, functions  
- Willingness to experiment: Run code, break things, learn  
- Curiosity: Wonder how apps work under the hood  

**What You DON'T Need:**
- Previous linear algebra knowledge (we start from scratch)  
- Mathematical proofs (we focus on intuition and code)  
- Perfect grades in math (many engineers struggle with math — that's okay!)  

---

## Setup (5 Minutes)

```bash
# Create a new environment and install what we need
pip install numpy matplotlib jupyter scikit-learn pillow

# Start Jupyter to follow along
jupyter notebook
```

That's it. No complex setup. Let's go.

---

## The Projects You'll Build

By the end of this course, you'll have a portfolio of **real, working projects**:

<CardGroup cols={2}>
  <Card title="Song Recommender" icon="music">
    Find similar songs using vector similarity. Input: a song you like. Output: 10 songs you'll probably love.
  </Card>
  <Card title="Photo Filter App" icon="camera">
    Apply blur, sharpen, edge detection, and custom effects using matrix operations.
  </Card>
  <Card title="Image Compressor" icon="compress">
    Compress images to 10% of their size while keeping them recognizable. Understand how JPEG works.
  </Card>
  <Card title="Movie Recommender" icon="film">
    Predict user ratings for movies they haven't seen. The actual technique Netflix uses.
  </Card>
</CardGroup>

---

## Quick Taste: Vector Similarity in Action

Before we dive deep, let's see the magic in action. This is what you'll fully understand by the end of Module 1:

```python
import numpy as np

# Three songs represented as vectors [energy, danceability, acousticness]
blinding_lights = np.array([0.73, 0.51, 0.00])  # The Weeknd
levitating = np.array([0.69, 0.70, 0.03])        # Dua Lipa
someone_like_you = np.array([0.34, 0.50, 0.75])  # Adele

def similarity(song_a, song_b):
    """Cosine similarity - how similar are two vectors?"""
    return np.dot(song_a, song_b) / (np.linalg.norm(song_a) * np.linalg.norm(song_b))

print(f"Blinding Lights vs Levitating: {similarity(blinding_lights, levitating):.2f}")
print(f"Blinding Lights vs Someone Like You: {similarity(blinding_lights, someone_like_you):.2f}")

# Output:
# Blinding Lights vs Levitating: 0.94  (very similar! both are upbeat pop)
# Blinding Lights vs Someone Like You: 0.54  (less similar - different vibes)
```

**That's it.** That's the core of how Spotify recommendations work. Vectors + similarity.

Now imagine doing this with 100 dimensions instead of 3, and millions of songs. That's what you'll build.  

---

## By the End of This Course

You will:

✅ **See** vectors and matrices everywhere (in apps, in data, in neural networks)  
✅ **Build** 4 portfolio-worthy ML projects from scratch  
✅ **Read** ML papers and actually understand the notation  
✅ **Debug** ML models because you understand what's happening inside  
✅ **Explain** to others why linear algebra powers AI  

Most importantly: You'll **stop being scared of math** in ML papers. When you see:

$$\mathbf{y} = W\mathbf{x} + \mathbf{b}$$

You'll think: *"Oh, that's just transforming a vector with a matrix. Like applying a filter to an image."*

---

## Ready?

Let's stop talking and start building. The next module introduces vectors by asking a simple question:

**"How does Spotify know what song to play next?"**

<Card title="Next: Vectors — The Language of Similarity" icon="arrow-right" href="/courses/math-for-ml-linear-algebra/02-vectors">
  Learn what vectors really are, why everything is a vector, and how to measure similarity between any two things.
</Card>
