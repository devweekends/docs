---
title: "Gradients & Multivariable Calculus"
sidebarTitle: "Gradients"
description: "Optimizing functions with many variables - the key to deep learning"
icon: "mountain"
---

# Gradients & Multivariable Calculus

## Your Challenge: The CEO's Dilemma

In the previous module, you optimized **one** thing (price). But in the real world, you rarely control just one variable.

Imagine you're the CEO of a tech startup. You have **two** powerful levers to pull:
1. **Price** ($x$): How much you charge
2. **Ad Spend** ($y$): How much you spend on marketing

**Your Goal**: Maximize Profit.

The problem is, these variables interact!
- High price + Low ads = No sales
- Low price + High ads = Lots of sales, but high costs
- High price + High ads = Premium brand? Or wasted money?

You are standing on a complex "Profit Landscape" with hills and valleys. You want to find the highest peak (maximum profit).

**The Catch**: You're blindfolded (or in a thick fog). You can't see the peak. You can only feel the slope under your feet.

### The Hiker in the Fog

![Hiker Gradient Analogy](/images/courses/math-for-ml-calculus/hiker-gradient-analogy.svg)

This is the classic intuition for **Gradients**.

Imagine you're hiking up a mountain in dense fog:
1. You can't see the summit.
2. You want to go up as fast as possible.
3. What do you do?

You feel the ground with your foot:
- **Step East ($x$)**: Is it going up or down? (Partial Derivative w.r.t $x$)
- **Step North ($y$)**: Is it going up or down? (Partial Derivative w.r.t $y$)

If East is steep uphill, and North is slightly uphill, you move **mostly East, slightly North**.

**The Gradient is your Compass.** It combines these two slopes into ONE arrow that points **steepest uphill**.

---

## What Is a Gradient?

### Intuitive Definition

**Gradient = The Direction of Steepest Ascent**

It answers: *"Which combination of changes ($x$ and $y$) will increase my output the fastest?"*

### Mathematical Definition

The gradient (symbol $\nabla$, pronounced "del") is just a vector holding all the partial derivatives:

$$
\nabla f = \begin{bmatrix} \frac{\partial f}{\partial x} \\ \frac{\partial f}{\partial y} \end{bmatrix}
$$

- **Top number**: Slope in $x$ direction (Price)
- **Bottom number**: Slope in $y$ direction (Ad Spend)

### Let's Solve Your CEO Problem

Suppose your Profit function is:
$$ P(x, y) = -x^2 - y^2 + 10x + 8y $$

Let's find the gradient at your current position: Price = 2, Ad Spend = 3.

```python
import numpy as np

def profit_gradient(x, y):
    # Partial derivative for Price (x): -2x + 10
    # (Treat y as constant, derivative of -y² is 0)
    dp_dx = -2*x + 10
    
    # Partial derivative for Ad Spend (y): -2y + 8
    # (Treat x as constant, derivative of -x² is 0)
    dp_dy = -2*y + 8
    
    return np.array([dp_dx, dp_dy])

# Your current strategy
current_price = 2
current_ad_spend = 3

grad = profit_gradient(current_price, current_ad_spend)

print(f"Current Position: Price=${current_price}, Ads=${current_ad_spend}")
print(f"Gradient Vector: {grad}")
```

**Output**:
```
Current Position: Price=$2, Ads=$3
Gradient Vector: [6, 2]
```

**What this tells you**:
- **6 (x-component)**: Increasing Price is VERY profitable right now.
- **2 (y-component)**: Increasing Ad Spend is MILDLY profitable.
- **Decision**: You should increase BOTH, but focus 3x more effort on raising Price!

**Key Insight**: The gradient doesn't just tell you "up" - it tells you the **exact mix** of changes to make.

---

---

## Example 1: Optimizing Your Business

### The Problem

Let's formalize your CEO problem. You want to maximize Revenue based on two investments:
- $x$ = Advertising Budget ($1000s)
- $y$ = Product Quality Investment ($1000s)

**Your Revenue Function**:
$$ R(x, y) = 100x + 80y - x^2 - y^2 - 0.5xy $$

**Your Goal**: Find the perfect budget allocation ($x, y$) that maximizes $R$.

### Visualizing Your Landscape

Here is what your revenue landscape looks like. The gradient (red arrow) shows you the fastest way to the top.

![Steepest Ascent Visual](/images/courses/math-for-ml-calculus/steepest-ascent-visual.svg)

### Step 1: Compute the Gradient

You need to find the partial derivatives (the slope in each direction):

1. **Slope w.r.t Ad Budget ($x$)**:
   $$ \frac{\partial R}{\partial x} = 100 - 2x - 0.5y $$
   *(Treat $y$ as constant number)*

2. **Slope w.r.t Quality ($y$)**:
   $$ \frac{\partial R}{\partial y} = 80 - 2y - 0.5x $$
   *(Treat $x$ as constant number)*

**Your Gradient Vector**:
$$ \nabla R = \begin{bmatrix} 100 - 2x - 0.5y \\ 80 - 2y - 0.5x \end{bmatrix} $$

### Step 2: Check Your Current Strategy

Suppose you are currently spending:
- $x = 20$ ($20k on Ads)
- $y = 15$ ($15k on Quality)

Let's plug these into your gradient:

```python
import numpy as np

def revenue_gradient(x, y):
    dR_dx = 100 - 2*x - 0.5*y
    dR_dy = 80 - 2*y - 0.5*x
    return np.array([dR_dx, dR_dy])

# Your current allocation
x, y = 20, 15
grad = revenue_gradient(x, y)

print(f"Current allocation: Ad=${x}k, Quality=${y}k")
print(f"Gradient: {grad}")
```

**Output**:
```
Current allocation: Ad=$20k, Quality=$15k
Gradient: [52.5, 40.0]
```

**Interpretation**:
- **52.5**: Increasing Ad spend is HIGHLY profitable.
- **40.0**: Increasing Quality is ALSO profitable, but slightly less so.
- **Action**: Increase both, but prioritize Ads slightly more.

### Step 3: Find the Optimal Allocation

To find the absolute peak, you want the point where the slope is ZERO in all directions (flat top).

**Set Gradient to 0**:
$$
\begin{cases}
100 - 2x - 0.5y = 0 \\
80 - 2y - 0.5x = 0
\end{cases}
$$

Solving this system (using linear algebra or substitution):

```python
# Solve system of equations
# 2x + 0.5y = 100
# 0.5x + 2y = 80

A = np.array([[2, 0.5], [0.5, 2]])
b = np.array([100, 80])
optimal = np.linalg.solve(A, b)

x_opt, y_opt = optimal
print(f"Optimal Ad Budget: ${x_opt:.2f}k")
print(f"Optimal Quality Budget: ${y_opt:.2f}k")
```

**Output**:
```
Optimal Ad Budget: $42.67k
Optimal Quality Budget: $29.33k
```

**Result**: You found the perfect strategy! Spend $42.6k on ads and $29.3k on quality to maximize revenue.

**Real Application**: Google uses this exact math to optimize ad auctions, balancing multiple metrics (CTR, bid price, user relevance) simultaneously.

---

---

## Example 2: Optimizing Your Grades

### The Problem

You want to maximize your overall GPA across 3 subjects:
- $x$ = hours/week on Math
- $y$ = hours/week on English  
- $z$ = hours/week on Science

**Your GPA Function**:
$$ G(x, y, z) = \sqrt{x} + \sqrt{y} + \sqrt{z} - 0.01(x^2 + y^2 + z^2) $$
*(Square roots represent learning; squared terms represent burnout/fatigue)*

**Constraint**: You only have 30 hours/week total.

### Computing Your Gradient

The gradient tells you: *"If I add 1 hour of study, which subject gives the biggest GPA boost?"*

```python
def gpa_gradient(x, y, z):
    # Partial derivatives (marginal benefit - marginal cost)
    dG_dx = 0.5/np.sqrt(x) - 0.02*x
    dG_dy = 0.5/np.sqrt(y) - 0.02*y
    dG_dz = 0.5/np.sqrt(z) - 0.02*z
    return np.array([dG_dx, dG_dy, dG_dz])

# Your current schedule
x, y, z = 10, 12, 8  # hours per subject

grad = gpa_gradient(x, y, z)

print(f"Current Schedule: Math={x}h, English={y}h, Science={z}h")
print(f"Gradient: {grad}")
```

**Output**:
```
Current Schedule: Math=10h, English=12h, Science=8h
Gradient: [-0.042, -0.096, 0.017]
```

**Interpretation**:
- **Math (-0.042)**: Negative! Studying MORE math will actually LOWER your GPA (burnout).
- **English (-0.096)**: Very Negative! You are over-studying English.
- **Science (+0.017)**: Positive! You should shift time to Science.

**Action**: Study less English/Math, study more Science!

---

## Example 3: Tuning Your Recommendation System

### The Problem

You are building a Netflix-style recommender. You have 3 knobs to tune:
- $\alpha$ = Recency weight (how much recent views matter)
- $\beta$ = Popularity weight (how much overall hits matter)
- $\gamma$ = Personalization weight (how much user history matters)

**Your Error Function** (Lower is better):
$$ E(\alpha, \beta, \gamma) = (\alpha - 0.6)^2 + (\beta - 0.3)^2 + (\gamma - 0.8)^2 + 0.1\alpha\beta $$

**Goal**: Find the knob settings that minimize error.

### Gradient Descent Optimization

Since we want to MINIMIZE error, we move **opposite** to the gradient.

```python
def error_gradient(alpha, beta, gamma):
    dE_dalpha = 2*(alpha - 0.6) + 0.1*beta
    dE_dbeta = 2*(beta - 0.3) + 0.1*alpha
    dE_dgamma = 2*(gamma - 0.8)
    return np.array([dE_dalpha, dE_dbeta, dE_dgamma])

# Start with random settings
params = np.array([0.2, 0.5, 0.4])
learning_rate = 0.1

print("Optimizing your system...")
for step in range(15):
    grad = error_gradient(*params)
    params = params - learning_rate * grad  # Move OPPOSITE to gradient
    
    if step % 5 == 0:
        print(f"Step {step}: α={params[0]:.2f}, β={params[1]:.2f}, γ={params[2]:.2f}")

print(f"Optimal Settings: α={params[0]:.2f}, β={params[1]:.2f}, γ={params[2]:.2f}")
```

**Real Application**: Real recommendation systems optimize thousands of such parameters automatically using this exact method!

---

## Directional Derivatives: Choosing Your Path

### The Question

The gradient tells you the **steepest** way up. But what if you can't go that way? What if you want to go Northeast?

**Directional Derivative** answers: *"How fast will I climb if I walk in THIS specific direction?"*

![Directional Derivative Compass](/images/courses/math-for-ml-calculus/directional-derivative-compass.svg)

### The Formula

To find the rate of change in direction $\mathbf{v}$:

$$
\text{Rate} = \nabla f \cdot \mathbf{v} \quad (\text{Dot Product})
$$

- If direction is same as gradient → Max rate (Steepest ascent)
- If direction is perpendicular → Zero rate (Walking flat)
- If direction is opposite → Negative rate (Steepest descent)

```python
# Gradient at your position
grad = np.array([39, 40])

# You want to move Northeast (45 degrees)
direction = np.array([1, 1]) 
direction = direction / np.linalg.norm(direction) # Normalize length to 1

# How fast will you climb?
rate = np.dot(grad, direction)
print(f"Climbing rate in Northeast direction: {rate:.2f}")
```

**Key Insight**: The dot product measures "alignment". The more your direction aligns with the gradient, the faster you climb!

---

## Hessian Matrix (Second Derivatives)

### What Is It?

Matrix of all second partial derivatives:

$$
H = \begin{bmatrix}
\frac{\partial^2 f}{\partial x^2} & \frac{\partial^2 f}{\partial x \partial y} \\
\frac{\partial^2 f}{\partial y \partial x} & \frac{\partial^2 f}{\partial y^2}
\end{bmatrix}
$$

### Why It Matters

**Hessian tells you about curvature**:
- Positive definite → Local minimum
- Negative definite → Local maximum
- Indefinite → Saddle point

```python
# Example: f(x,y) = x² + y²
def hessian_simple():
    return np.array([
        [2, 0],
        [0, 2]
    ])

H = hessian_simple()
eigenvalues = np.linalg.eigvals(H)
print(f"Eigenvalues: {eigenvalues}")
# Both positive → minimum!
```

---

## Practice Exercises

### Exercise 1: Profit Optimization

```python
# Profit function with 2 variables
def profit(x, y):
    return 50*x + 40*y - x**2 - y**2 - 0.5*x*y

# TODO:
# 1. Compute the gradient
# 2. Find the point where gradient = 0
# 3. Verify it's a maximum using the Hessian
```

<details>
<summary>Solution</summary>

```python
def profit_gradient(x, y):
    return np.array([50 - 2*x - 0.5*y, 40 - 2*y - 0.5*x])

# Solve ∇P = 0
# 50 - 2x - 0.5y = 0
# 40 - 2y - 0.5x = 0

A = np.array([[2, 0.5], [0.5, 2]])
b = np.array([50, 40])
optimal = np.linalg.solve(A, b)

print(f"Optimal: x={optimal[0]:.2f}, y={optimal[1]:.2f}")
print(f"Maximum profit: ${profit(*optimal):.2f}")

# Hessian
H = np.array([[-2, -0.5], [-0.5, -2]])
eigenvalues = np.linalg.eigvals(H)
print(f"Eigenvalues: {eigenvalues}")
# Both negative → maximum!
```
</details>

---

## Key Takeaways

✅ **Gradient** = vector of partial derivatives  
✅ **Points uphill** = direction of steepest ascent  
✅ **Optimization** = set gradient = 0  
✅ **Hessian** = tells you if it's min/max/saddle  
✅ **ML uses gradients** = to optimize millions of parameters  

---

## What's Next?

You now understand gradients for multi-variable functions. But how do we handle COMPOSITIONS of functions (like neural networks with many layers)?

That's the **chain rule** - and it's the key to backpropagation!

<Card title="Next: Chain Rule & Backpropagation" icon="arrow-right" href="/courses/math-for-ml-calculus/03-chain-rule">
  Discover how neural networks learn through backpropagation
</Card>
