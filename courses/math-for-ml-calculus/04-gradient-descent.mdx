---
title: "Gradient Descent"
sidebarTitle: "Gradient Descent"
description: "The algorithm that makes machines learn - understanding optimization through iteration"
icon: "arrow-trend-down"
---

# Gradient Descent

## Your Challenge: Lost in the Mountains

Imagine you are dropped onto a random spot in a vast, foggy mountain range at night.
- You can't see the bottom (the valley).
- You can't see more than 3 feet in front of you.
- You have no map.

**Your Goal**: Find the absolute lowest point in the entire valley (the minimum).

**How do you do it?**

You can't "solve" the mountain. You can't just teleport to the bottom.
You have to **feel** your way down.

1. You feel the slope under your feet.
2. You take a small step downhill.
3. You repeat this thousands of times.

Eventually, you reach the bottom.

### The Algorithm Visualized

![Gradient Descent Path](/images/courses/math-for-ml-calculus/gradient-descent-path.svg)

This is **Gradient Descent**. It's the "blind hiker" algorithm.

- **The Mountain**: Your Loss Function (Error).
- **Your Position**: The current weights of your model.
- **The Slope**: The Gradient.
- **The Step Size**: The Learning Rate.
- **The Bottom**: The Optimal Weights (Best Model).

---

## The Core Intuition

### Why We Need It

In high school math, you found the minimum by setting the derivative to zero:
$$ f'(x) = 0 $$

That works for simple parabolas like $x^2$.

But in Deep Learning, your function looks like a crumpled piece of paper in 1,000,000 dimensions. You **cannot** solve $f'(x) = 0$ algebraically. It's impossible.

So instead of solving for the answer directly, we **search** for it iteratively.

### The Code: A Simple Descent

Let's implement the "blind hiker" logic for a simple valley: $f(x) = x^2 - 4x + 5$.

```python
import numpy as np

# 1. The Mountain (Loss Function)
def f(x):
    return x**2 - 4*x + 5

# 2. The Slope (Gradient)
def gradient(x):
    return 2*x - 4  # Derivative of x² - 4x + 5

# 3. The Hike
x = 0  # Start at random spot
learning_rate = 0.1  # Size of each step

print(f"Start at x={x}")

for step in range(20):
    # Feel the slope
    grad = gradient(x)
    
    # Take a step downhill (opposite to gradient)
    x = x - learning_rate * grad
    
    print(f"Step {step+1}: Moved to x={x:.4f}, Height={f(x):.4f}")

print(f"\nReached bottom at x={x:.4f}")
```

**Output**:
```
Start at x=0
Step 1: Moved to x=0.4000, Height=3.5600
Step 2: Moved to x=0.7200, Height=2.6384
...
Step 20: Moved to x=1.9769, Height=1.0005
Reached bottom at x=1.9769
```

**Result**: You started at 0 and walked your way to ~2 (the true minimum). You solved it without algebra!

---

## The Algorithm

### Mathematical Formulation

**Update rule**:

$$
x_{new} = x_{old} - \alpha \cdot \nabla f(x_{old})
$$

Where:
- $\alpha$ = learning rate (step size)
- $\nabla f$ = gradient (direction of steepest ascent)
- We subtract because we want to go **downhill**

### Pseudocode

```
1. Initialize parameters randomly
2. Repeat until convergence:
   a. Compute gradient at current point
   b. Update parameters: x = x - α × gradient
   c. Check if converged (gradient ≈ 0)
3. Return optimized parameters
```

---

---

## Example 1: Training Your First Model

### The Problem

You want to predict house prices based on square footage.
$$ \text{Price} = w \cdot \text{sqft} + b $$

**Your Goal**: Find the best $w$ (weight) and $b$ (bias) that minimize the error.

### The Data

```python
# Training data
sqft = np.array([1.0, 1.5, 2.0, 2.5, 3.0]) # in 1000s sqft
prices = np.array([200, 250, 300, 350, 400])  # in $1000s
```

### Gradient Descent Training

```python
def predict(x, w, b):
    return w * x + b

def compute_gradients(w, b, x, y):
    n = len(x)
    pred = predict(x, w, b)
    error = pred - y
    
    # Gradients (Partial Derivatives of MSE)
    dL_dw = (2/n) * np.sum(error * x)
    dL_db = (2/n) * np.sum(error)
    return dL_dw, dL_db

# 1. Initialize randomly
w, b = 0.0, 0.0
learning_rate = 0.01

print("Training started...")
for epoch in range(1000):
    # 2. Compute Gradient
    grad_w, grad_b = compute_gradients(w, b, sqft, prices)
    
    # 3. Update Parameters (Step Downhill)
    w = w - learning_rate * grad_w
    b = b - learning_rate * grad_b
    
    if epoch % 100 == 0:
        loss = np.mean((predict(sqft, w, b) - prices)**2)
        print(f"Epoch {epoch}: Loss={loss:.2f}, w={w:.2f}, b={b:.2f}")

print(f"\nFinal Model: Price = {w:.2f} * sqft + {b:.2f}")
print("True Answer: Price = 100 * sqft + 100")
```

**Result**: Your model learned the relationship perfectly!

---

## Example 2: Optimizing Your Prices

### The Scenario

You run an e-commerce site. You control two things:
- $x_1$ = Ad spend ($1000s)
- $x_2$ = Discount percentage

**Your Revenue Function** (Unknown to you, but we simulate it):
$$ R(x_1, x_2) = 100x_1 + 50x_2 - x_1^2 - x_2^2 $$

**Your Goal**: Maximize Revenue (which means *minimizing* Negative Revenue).

### Gradient Descent Optimization

```python
def neg_revenue_gradient(x1, x2):
    # Gradient of -R (to minimize)
    # R = 100x + 50y - x^2 - y^2
    # dR/dx = 100 - 2x  ->  d(-R)/dx = 2x - 100
    # dR/dy = 50 - 2y   ->  d(-R)/dy = 2y - 50
    grad_x1 = 2*x1 - 100
    grad_x2 = 2*x2 - 50
    return np.array([grad_x1, grad_x2])

# Start with random strategy
strategy = np.array([0.0, 0.0]) # $0 ads, 0% discount
lr = 0.1

for step in range(50):
    grad = neg_revenue_gradient(strategy[0], strategy[1])
    strategy = strategy - lr * grad
    
    if step % 10 == 0:
        print(f"Step {step}: Ads=${strategy[0]:.2f}k, Discount={strategy[1]:.2f}%")

print(f"\nOptimal Strategy: Ads=${strategy[0]:.2f}k, Discount={strategy[1]:.2f}%")
```

**Output**:
```
Optimal Strategy: Ads=$50.00k, Discount=$25.00%
```

**Insight**: You found the optimal business strategy just by following the gradient!

---

## Example 3: Training Your Neural Network

### The Challenge

You want to train a simple neural network to solve a problem.
- **Input**: $x$
- **Target**: $y$
- **Model**: $y_{pred} = \sigma(wx + b)$

### The Code

```python
def sigmoid(z): return 1 / (1 + np.exp(-z))

# Training data (XOR-like)
X = np.array([0, 1])
y = np.array([0, 1])

# Initialize
w, b = 0.5, 0.0
lr = 1.0

print("Training Neural Network...")
for epoch in range(100):
    total_grad_w = 0
    total_grad_b = 0
    
    for i in range(len(X)):
        # Forward
        z = w * X[i] + b
        pred = sigmoid(z)
        
        # Backward (Chain Rule!)
        error = pred - y[i]
        dL_dpred = 2 * error
        dpred_dz = pred * (1 - pred)
        dz_dw = X[i]
        dz_db = 1
        
        grad_w = dL_dpred * dpred_dz * dz_dw
        grad_b = dL_dpred * dpred_dz * dz_db
        
        # Accumulate gradients
        total_grad_w += grad_w
        total_grad_b += grad_b
    
    # Update weights (Gradient Descent Step)
    w = w - lr * (total_grad_w / len(X))
    b = b - lr * (total_grad_b / len(X))

print(f"Final Weights: w={w:.2f}, b={b:.2f}")
print(f"Prediction for 0: {sigmoid(w*0 + b):.2f}")
print(f"Prediction for 1: {sigmoid(w*1 + b):.2f}")
```

**This is Deep Learning.** It's just Gradient Descent applied to a lot of weights!

---

## Learning Rate: The "Goldilocks" Problem

Choosing the step size ($\alpha$) is the most important decision you make.

![Learning Rate Comparison](/images/courses/math-for-ml-calculus/learning-rate-comparison.svg)

### 1. Too Small (The Turtle)
- **Symptom**: Loss decreases veeeery slowly.
- **Result**: You run out of time/patience before reaching the bottom.

### 2. Too Large (The Grasshopper)
- **Symptom**: Loss bounces around or even INCREASES.
- **Result**: You overshoot the valley and never converge.

### 3. Just Right (Goldilocks)
- **Symptom**: Loss decreases steadily and quickly.
- **Result**: You reach the minimum efficiently.

### How to Find It?
Start with 0.01 or 0.001. If loss is slow, increase it (0.1). If loss explodes, decrease it (0.0001).

---

## Variants of Gradient Descent

### Batch Gradient Descent

Uses **all** data points to compute gradient:

```python
# Compute gradient using ALL data
gradient = compute_gradient(all_data)
params = params - lr * gradient
```

**Pros**: Stable, smooth convergence  
**Cons**: Slow for large datasets

### Stochastic Gradient Descent (SGD)

Uses **one** data point at a time:

```python
for each data_point in dataset:
    gradient = compute_gradient(data_point)
    params = params - lr * gradient
```

**Pros**: Fast, can escape local minima  
**Cons**: Noisy, unstable

### Mini-Batch Gradient Descent

Uses **small batches** of data:

```python
for batch in dataset.batches(batch_size=32):
    gradient = compute_gradient(batch)
    params = params - lr * gradient
```

**Pros**: Best of both worlds  
**Cons**: Need to choose batch size

**This is what everyone uses in practice!**

---

## Convergence Criteria

### When to Stop?

**Option 1**: Gradient is small

```python
if np.linalg.norm(gradient) < 1e-6:
    break  # Converged!
```

**Option 2**: Loss stops improving

```python
if abs(loss_new - loss_old) < 1e-6:
    break  # Converged!
```

**Option 3**: Maximum iterations

```python
if epoch >= max_epochs:
    break  # Give up
```

---

## Practice Exercises

### Exercise 1: Implement Gradient Descent

```python
# Minimize f(x) = x⁴ - 3x³ + 2
# TODO:
# 1. Compute the derivative
# 2. Implement gradient descent
# 3. Find the minimum
# 4. Try different learning rates
```

<details>
<summary>Solution</summary>

```python
def f(x):
    return x**4 - 3*x**3 + 2

def gradient(x):
    return 4*x**3 - 9*x**2

x = 0  # Start
lr = 0.01
history = []

for step in range(100):
    grad = gradient(x)
    x = x - lr * grad
    history.append((x, f(x)))
    
    if abs(grad) < 1e-6:
        break

print(f"Minimum at x={x:.4f}, f(x)={f(x):.4f}")
```
</details>

---

## Key Takeaways

✅ **Gradient descent** = iterative optimization algorithm  
✅ **Follow gradient downhill** = move opposite to gradient  
✅ **Learning rate** = critical hyperparameter  
✅ **Mini-batch** = best practice for large datasets  
✅ **Powers all ML** = from linear regression to GPT  

---

## What's Next?

Gradient descent is powerful, but basic. Can we do better? Can we converge faster? Can we escape local minima?

Yes! **Advanced optimization techniques** like Momentum, Adam, and RMSprop!

<Card title="Next: Optimization Techniques" icon="arrow-right" href="/courses/math-for-ml-calculus/05-optimization">
  Learn the optimizers that power modern deep learning
</Card>
