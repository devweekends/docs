---
title: "Kafka Crash Course"
sidebarTitle: "Kafka Overview"
description: "Master event streaming with Apache Kafka"
icon: "stream"
---

<Frame>
  <img src="/images/courses/devops-tools/kafka-architecture.svg" alt="Kafka Architecture Overview" />
</Frame>

# Kafka Crash Course

> **"Kafka is a distributed event streaming platform capable of handling trillions of events a day."**

Learn to build real-time data pipelines and streaming applications with Apache Kafka.

---

## Why Kafka Matters

<CardGroup cols={2}>
  <Card title="High Throughput" icon="gauge-high">
    Millions of messages per second
  </Card>
  <Card title="Scalability" icon="arrows-maximize">
    Horizontal scaling, distributed by design
  </Card>
  <Card title="Durability" icon="hard-drive">
    Messages persist on disk, replicated
  </Card>
  <Card title="Real-Time" icon="bolt">
    Process streams in real-time
  </Card>
</CardGroup>

---

## The Story Behind Kafka

**2011**: LinkedIn created Kafka to handle their massive data pipeline needs.

**The Problem**:
- Traditional messaging couldn't handle LinkedIn's scale
- Needed to process billions of events daily
- Real-time analytics requirements
- Data integration across systems

**The Solution**: Apache Kafka
- Distributed, partitioned, replicated log
- High throughput (millions of messages/sec)
- Horizontal scalability
- Fault-tolerant and durable

**Today**: Kafka powers:
- **LinkedIn**: 7+ trillion messages/day
- **Netflix**: Real-time recommendations
- **Uber**: Trip data and analytics
- **Airbnb**: Payment processing
- **Twitter**: Real-time analytics

**Open Sourced**: 2011, became Apache project

---

## What You'll Learn

<Steps>
  <Step title="Fundamentals">
    Topics, partitions, brokers, producers, consumers
    [Start Here →](/courses/devops-tools/kafka-fundamentals)
  </Step>
  <Step title="Producers & Consumers">
    Publishing messages, consuming streams, configurations
    [Learn APIs →](/courses/devops-tools/kafka-producers-consumers)
  </Step>
  <Step title="Stream Processing">
    Kafka Streams, transformations, aggregations
    [Process Streams →](/courses/devops-tools/kafka-streams)
  </Step>
  <Step title="Operations">
    Clustering, replication, monitoring, production
    [Run in Production →](/courses/devops-tools/kafka-operations)
  </Step>
</Steps>

---

## Kafka vs RabbitMQ

| Feature | Kafka | RabbitMQ |
|---------|-------|----------|
| **Use Case** | Event streaming, logs | Task queues, RPC |
| **Throughput** | Very high (millions/sec) | High (thousands/sec) |
| **Message Retention** | Configurable (days/weeks) | Until consumed |
| **Ordering** | Per partition | Per queue |
| **Consumers** | Pull model | Push model |

---

## Course Structure

### Module 1: Fundamentals (2-3 hours)
Architecture, topics, partitions, brokers, offsets

### Module 2: Producers & Consumers (2-3 hours)
Publishing, consuming, serialization, configurations

### Module 3: Stream Processing (2 hours)
Kafka Streams API, transformations, stateful processing

### Module 4: Operations (2 hours)
Clustering, replication, monitoring, best practices

---

Ready to master Kafka? Start with [Kafka Fundamentals →](/courses/devops-tools/kafka-fundamentals)
