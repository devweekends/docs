---
title: "Kafka Producers & Consumers"
sidebarTitle: "Producers & Consumers"
description: "Publishing and consuming messages with Kafka APIs"
icon: "arrows-left-right"
---

# Kafka Producers & Consumers

Learn to build robust applications that publish and subscribe to Kafka topics.

---

## Producer API

Producers publish data to the topics of their choice.

### Key Responsibilities
- **Partitioning**: Deciding which partition to send the message to.
- **Serialization**: Converting key/value objects to bytes.
- **Compression**: Reducing network bandwidth (Snappy, Gzip, LZ4, Zstd).
- **Batching**: Grouping messages for efficiency.

### Java Example

```java
import org.apache.kafka.clients.producer.*;
import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        
        // Reliability Configs
        props.put("acks", "all"); // Wait for all replicas
        props.put("retries", 3);  // Retry on failure
        props.put("linger.ms", 1); // Wait 1ms to batch messages

        Producer<String, String> producer = new KafkaProducer<>(props);

        for (int i = 0; i < 100; i++) {
            producer.send(new ProducerRecord<>("my-topic", Integer.toString(i), "Message " + i),
                (metadata, exception) -> {
                    if (exception == null) {
                        System.out.printf("Sent to partition %d @ offset %d%n", 
                            metadata.partition(), metadata.offset());
                    } else {
                        exception.printStackTrace();
                    }
                });
        }
        producer.close();
    }
}
```

### Python Example (kafka-python)

```python
from kafka import KafkaProducer
import json

producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda x: json.dumps(x).encode('utf-8')
)

# Asynchronous send
future = producer.send('my-topic', value={'key': 'value'})
result = future.get(timeout=60)
```

---

## Consumer API

Consumers read data from topics. They subscribe to one or more topics and pull data.

### Consumer Groups & Rebalancing
- **Consumer Group**: A pool of consumers that share the work.
- **Rebalancing**: When a consumer joins/leaves, partitions are reassigned.

### Java Example

```java
import org.apache.kafka.clients.consumer.*;
import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class SimpleConsumer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "my-group");
        props.put("enable.auto.commit", "false"); // Manual commit for safety
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Arrays.asList("my-topic"));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
            for (ConsumerRecord<String, String> record : records) {
                System.out.printf("offset = %d, key = %s, value = %s%n", 
                    record.offset(), record.key(), record.value());
                
                // Process record...
            }
            consumer.commitSync(); // Commit offsets after processing
        }
    }
}
```

---

## Delivery Semantics

<CardGroup cols={3}>
  <Card title="At Most Once" icon="xmark">
    Messages may be lost, but never duplicated.
    *Commit offset **before** processing.*
  </Card>
  <Card title="At Least Once" icon="check">
    Messages are never lost, but may be duplicated.
    *Commit offset **after** processing.* (Default/Preferred)
  </Card>
  <Card title="Exactly Once" icon="check-double">
    Each message is delivered exactly once.
    *Requires Transactional API.*
  </Card>
</CardGroup>

---

## Important Configurations

### Producer Configs
| Config | Description | Recommended |
|--------|-------------|-------------|
| `acks` | How many replicas must acknowledge | `all` (for durability) |
| `retries` | Retry count on transient errors | `Integer.MAX_VALUE` |
| `enable.idempotence` | Prevent duplicates | `true` |
| `compression.type` | Compression algorithm | `snappy` or `lz4` |

### Consumer Configs
| Config | Description | Recommended |
|--------|-------------|-------------|
| `group.id` | Unique ID for the consumer group | Required |
| `auto.offset.reset` | What to do if no offset exists | `earliest` (start from beginning) |
| `enable.auto.commit` | Auto-commit offsets | `false` (manual control) |
| `max.poll.records` | Max records per poll | Tuned to processing speed |

---

## Best Practices

<AccordionGroup>
  <Accordion title="Handle Rebalancing" icon="scale-balanced">
    Handle `WakeupException` and close consumers gracefully to trigger a rebalance immediately rather than waiting for a timeout.
  </Accordion>
  
  <Accordion title="Idempotent Processing" icon="rotate">
    Since "At Least Once" is common, ensure your processing logic handles duplicates (e.g., using a database unique constraint).
  </Accordion>
  
  <Accordion title="Monitor Lag" icon="chart-line">
    **Consumer Lag** is the difference between the latest offset in the partition and the consumer's current offset. High lag means consumers are too slow.
  </Accordion>
</AccordionGroup>

---

Next: [Kafka Streams â†’](/courses/devops-tools/kafka-streams)
