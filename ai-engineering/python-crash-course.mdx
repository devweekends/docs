---
title: "Python Crash Course"
description: "Essential Python for AI Engineers - from basics to advanced patterns"
icon: "python"
---

<Note>
This is a quick-reference Python guide focused on AI/ML workflows. For a comprehensive Python course, see our [Complete Python Crash Course](/courses/python-crash-course/overview).
</Note>

## Getting Started

### 1. Install Python

Download Python 3.11+ from [python.org](https://python.org). Verify installation:

```bash
python --version  # Should show 3.11 or higher
```

### 2. Set Up Virtual Environment

Virtual environments keep project dependencies isolated and avoid conflicts.

```bash
# Create a virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (macOS/Linux)
source venv/bin/activate
```

### 3. Install AI Packages

```bash
pip install openai anthropic langchain chromadb pydantic python-dotenv
```

### 4. Manage Dependencies

```bash
# Save current packages
pip freeze > requirements.txt

# Install from requirements
pip install -r requirements.txt
```

---

## Python Core Syntax (AI Context)

### Variables & Types

```python
# Basic types
name = "Claude"  # str
temperature = 0.7  # float
max_tokens = 1000  # int
is_streaming = True  # bool

# Lists (ordered, mutable)
messages = ["Hello", "How are you?"]
messages.append("Great!")

# Dictionaries (key-value pairs)
config = {
    "model": "gpt-4",
    "temperature": 0.7,
    "max_tokens": 1000
}

# Tuples (immutable)
coordinates = (40.7128, -74.0060)
```

### Functions

```python
def generate_prompt(context: str, question: str) -> str:
    """Generate a prompt with context and question."""
    return f"Context: {context}\n\nQuestion: {question}"

# With default args
def call_api(prompt: str, temperature: float = 0.7, max_tokens: int = 1000):
    # API call logic here
    pass

# Lambda (anonymous functions)
multiply = lambda x, y: x * y
result = multiply(5, 3)  # 15
```

### Control Flow

```python
# If-else
if temperature < 0.3:
    style = "deterministic"
elif temperature < 0.7:
    style = "balanced"
else:
    style = "creative"

# For loops
for message in messages:
    print(message)

# List comprehension (faster, more Pythonic)
lengths = [len(msg) for msg in messages]
filtered = [msg for msg in messages if len(msg) > 10]

# While loop
retry_count = 0
while retry_count < 3:
    try:
        # Try API call
        break
    except Exception:
        retry_count += 1
```

### Error Handling

```python
try:
    response = api_call(prompt)
except APIError as e:
    print(f"API error: {e}")
except TimeoutError:
    print("Request timed out")
finally:
    # Always runs (cleanup code)
    close_connection()
```

---

## Data Structures for AI

### Working with JSON

```python
import json

# Parse JSON string
data = json.loads('{"model": "gpt-4", "temp": 0.7}')

# Convert to JSON string
json_str = json.dumps({"result": "success"})

# Read from file
with open("config.json") as f:
    config = json.load(f)

# Write to file
with open("output.json", "w") as f:
    json.dump(results, f, indent=2)
```

### List Operations

```python
# Slicing
messages[0]      # First item
messages[-1]     # Last item
messages[1:3]    # Items 1-2
messages[:2]     # First 2 items
messages[2:]     # From item 2 to end

# Common operations
len(messages)           # Length
messages.extend([...])  # Add multiple items
messages.remove(item)   # Remove specific item
messages.pop()          # Remove & return last item

# Sorting
sorted_list = sorted(numbers)
messages.sort(key=lambda x: len(x))  # Sort by length
```

### Dictionary Operations

```python
# Access
value = config["model"]
value = config.get("model", "default")  # Safe access

# Check existence
if "model" in config:
    print(config["model"])

# Iteration
for key, value in config.items():
    print(f"{key}: {value}")

# Merge dictionaries
combined = {**config1, **config2}

# Dictionary comprehension
squares = {x: x**2 for x in range(5)}
```

---

## Object-Oriented Python for AI

### Classes & Dataclasses

```python
from dataclasses import dataclass
from typing import List, Optional

@dataclass
class Message:
    role: str
    content: str
    tokens: Optional[int] = None

class ChatBot:
    def __init__(self, model: str = "gpt-4"):
        self.model = model
        self.messages: List[Message] = []
    
    def add_message(self, role: str, content: str) -> None:
        msg = Message(role=role, content=content)
        self.messages.append(msg)
    
    def get_history(self) -> list[dict]:
        return [
            {"role": m.role, "content": m.content}
            for m in self.messages
        ]
    
    def clear(self) -> None:
        self.messages = []

# Usage
bot = ChatBot(model="gpt-4o")
bot.add_message("user", "Hello!")
bot.add_message("assistant", "Hi there!")
print(bot.get_history())
```

**Why dataclasses?** Reduces boilerplate for data objects. Perfect for API responses, configuration objects, and structured data.

### Type Hints (Modern Python)

```python
from typing import List, Dict, Optional, Union

def process_batch(
    items: List[str],
    config: Dict[str, any],
    timeout: Optional[float] = None
) -> List[Dict[str, Union[str, int]]]:
    """Process a batch of items with config."""
    results = []
    for item in items:
        result = {"text": item, "length": len(item)}
        results.append(result)
    return results
```

**Why type hints?** Better IDE support, catch bugs early, and self-documenting code.

---

## Advanced Patterns for AI Engineering

### Decorators (Reusable Logic)

Decorators add functionality to functions without modifying their code—perfect for retries, timing, logging, and caching.

```python
import functools
import time
from typing import Callable

def timer(func: Callable) -> Callable:
    """Measure execution time"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        duration = time.time() - start
        print(f"{func.__name__} took {duration:.2f}s")
        return result
    return wrapper

def retry(max_attempts: int = 3, delay: float = 1.0):
    """Retry decorator with exponential backoff"""
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_attempts - 1:
                        raise
                    wait_time = delay * (2 ** attempt)
                    print(f"Retry {attempt + 1}/{max_attempts} in {wait_time}s")
                    time.sleep(wait_time)
        return wrapper
    return decorator

def cache_result(func: Callable) -> Callable:
    """Simple caching decorator"""
    cache = {}
    @functools.wraps(func)
    def wrapper(*args):
        if args not in cache:
            cache[args] = func(*args)
        return cache[args]
    return wrapper

# Usage
@retry(max_attempts=3, delay=2.0)
@timer
def call_llm(prompt: str) -> str:
    # Simulated API call
    return "response"
```

**Use cases:**
- `@timer` - Profile slow functions
- `@retry` - Handle flaky API calls
- `@cache_result` - Avoid redundant LLM calls

### Context Managers (Resource Management)

Context managers ensure resources are properly managed—files closed, connections released, timers stopped.

```python
from contextlib import contextmanager
import time

@contextmanager
def timer_context(label: str):
    """Time a block of code"""
    start = time.time()
    try:
        yield
    finally:
        duration = time.time() - start
        print(f"{label}: {duration:.2f}s")

@contextmanager
def temporary_config(new_config: dict):
    """Temporarily change config, then restore"""
    old_config = config.copy()
    config.update(new_config)
    try:
        yield
    finally:
        config.clear()
        config.update(old_config)

# Usage
with timer_context("Embedding generation"):
    embeddings = generate_embeddings(texts)

with open("data.txt") as f:
    content = f.read()
```

**Use cases:**
- File I/O
- Database connections
- Timing code blocks
- Temporary state changes

### Async/Await (Concurrency)

```python
import asyncio
from typing import List

async def fetch_completion(prompt: str) -> str:
    """Simulated async API call"""
    await asyncio.sleep(1)  # Simulate network delay
    return f"Response to: {prompt}"

async def process_batch(prompts: List[str]) -> List[str]:
    """Process multiple prompts concurrently"""
    tasks = [fetch_completion(p) for p in prompts]
    results = await asyncio.gather(*tasks)
    return results

# Run async code
prompts = ["Question 1", "Question 2", "Question 3"]
results = asyncio.run(process_batch(prompts))
```

**Why async?** Process multiple API calls concurrently. 10 sequential 1s calls = 10s. 10 concurrent = ~1s.

---

## File Operations

```python
# Read entire file
with open("data.txt") as f:
    content = f.read()

# Read line by line (memory efficient)
with open("large_file.txt") as f:
    for line in f:
        process(line.strip())

# Write to file
with open("output.txt", "w") as f:
    f.write("Hello, world!\n")

# Append to file
with open("log.txt", "a") as f:
    f.write(f"{timestamp}: Event\n")

# Check if file exists
from pathlib import Path
if Path("config.json").exists():
    # Load config
    pass
```

---

## Environment Variables (.env)

```python
from dotenv import load_dotenv
import os

# Load from .env file
load_dotenv()

# Access variables
api_key = os.getenv("OPENAI_API_KEY")
db_url = os.getenv("DATABASE_URL", "default_url")
```

**.env file:**
```
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
DATABASE_URL=postgresql://...
```

**Never commit `.env` files!** Add to `.gitignore`.

---

## Essential Libraries for AI

### HTTP Requests

```python
import requests

# GET request
response = requests.get("https://api.example.com/data")
data = response.json()

# POST request
response = requests.post(
    "https://api.example.com/generate",
    json={"prompt": "Hello", "max_tokens": 100},
    headers={"Authorization": f"Bearer {api_key}"}
)
```

### Data Manipulation (Pandas)

```python
import pandas as pd

# Read CSV
df = pd.read_csv("data.csv")

# Basic operations
df.head()           # First 5 rows
df.describe()       # Statistics
df["column"].mean() # Column average

# Filter
filtered = df[df["score"] > 0.8]

# Group by
grouped = df.groupby("category")["score"].mean()
```

### Date & Time

```python
from datetime import datetime, timedelta

now = datetime.now()
timestamp = now.isoformat()

# Add time
tomorrow = now + timedelta(days=1)
hour_ago = now - timedelta(hours=1)

# Parse string
dt = datetime.fromisoformat("2024-01-15T10:30:00")
```

---

## Common AI Patterns

### Loading Environment Variables

```python
from dotenv import load_dotenv
import os

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY not set")
```

### Building Prompts

```python
def build_rag_prompt(context: str, question: str) -> str:
    """Build RAG prompt with context."""
    return f"""Use the following context to answer the question.

Context:
{context}

Question: {question}

Answer:"""

# Template with f-strings
system_prompt = f"""You are an AI assistant with expertise in {domain}.
Your responses should be {tone} and {length}."""
```

### Batching Requests

```python
def batch_process(items: List[str], batch_size: int = 10):
    """Process items in batches"""
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        results = process_batch(batch)
        yield results
```

### Rate Limiting

```python
import time

def rate_limited_call(func, calls_per_minute: int = 60):
    """Rate limit function calls"""
    delay = 60.0 / calls_per_minute
    
    def wrapper(*args, **kwargs):
        time.sleep(delay)
        return func(*args, **kwargs)
    
    return wrapper
```

---

## Next Steps

<CardGroup cols={2}>
  <Card title="Complete Python Course" icon="graduation-cap" href="/courses/python-crash-course/overview">
    Deep dive into Python fundamentals, data structures, OOP, and more
  </Card>
  
  <Card title="FastAPI Crash Course" icon="bolt" href="/ai-engineering/fastapi-crash-course">
    Build production APIs for AI applications
  </Card>
  
  <Card title="Async Patterns" icon="arrows-spin" href="/ai-engineering/async-patterns">
    Master concurrent programming for AI workloads
  </Card>
  
  <Card title="LLM Fundamentals" icon="brain" href="/ai-engineering/llm-fundamentals">
    Start building with language models
  </Card>
</CardGroup>

---

## Quick Reference

### Common Commands

```bash
# Python version
python --version

# Install package
pip install package-name

# Install from requirements
pip install -r requirements.txt

# Create requirements file
pip freeze > requirements.txt

# Create virtual environment
python -m venv venv

# Activate venv (Windows)
venv\Scripts\activate

# Activate venv (macOS/Linux)
source venv/bin/activate

# Deactivate venv
deactivate

# Run Python file
python script.py

# Interactive Python shell
python

# Install specific version
pip install package-name==1.2.3
```

### Style Guidelines (PEP 8)

```python
# Naming conventions
class MyClass:          # PascalCase for classes
    pass

def my_function():      # snake_case for functions/variables
    pass

CONSTANT_VALUE = 100    # UPPER_CASE for constants

# Line length: max 79-88 characters
# Imports at top, grouped: standard lib, third-party, local
# Use 4 spaces for indentation (not tabs)
# Two blank lines between top-level functions/classes
# One blank line between methods
```

### Type Hints Quick Reference

```python
from typing import List, Dict, Optional, Union, Callable, Any

def func(
    text: str,                          # String
    count: int,                         # Integer
    ratio: float,                       # Float
    is_valid: bool,                     # Boolean
    items: List[str],                   # List of strings
    config: Dict[str, int],             # Dict with str keys, int values
    callback: Callable[[str], int],     # Function: str -> int
    optional: Optional[str] = None,     # Can be str or None
    either: Union[str, int],            # Can be str OR int
    anything: Any                       # Any type
) -> tuple[str, int]:                   # Returns tuple
    return ("result", 42)
```

---

## Troubleshooting

### "Module not found" error

```bash
# Make sure venv is activated
# Then reinstall
pip install -r requirements.txt
```

### "pip: command not found"

```bash
# Use python -m pip instead
python -m pip install package-name
```

### Import errors in VS Code

1. Select correct Python interpreter: `Ctrl+Shift+P` → "Python: Select Interpreter"
2. Choose the one in your `venv` folder

### Slow pip installs

```bash
# Use a faster mirror
pip install --index-url https://pypi.org/simple package-name
```

---

<Tip>
**Pro Tips:**
- Use virtual environments for EVERY project
- Pin package versions in production (`package==1.2.3`)
- Use type hints—they catch bugs before runtime
- Learn list/dict comprehensions—they're faster and more Pythonic
- Use `python-dotenv` for API keys and secrets
</Tip>
