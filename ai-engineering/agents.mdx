---
title: "AI Agents"
description: "Build autonomous agents with tools, memory, and reasoning capabilities"
icon: "robot"
---

## What Are AI Agents?

AI Agents are LLMs that can **take actions** autonomously. Instead of just generating text, they can:
- Use tools (search, code execution, APIs)
- Make decisions based on observations
- Maintain memory across interactions
- Plan multi-step tasks

<Note>
**Agent = LLM + Tools + Memory + Reasoning Loop**
</Note>

## The ReAct Pattern

Most agents follow the **ReAct** (Reasoning + Acting) pattern:

```
Thought: I need to find the weather in Tokyo
Action: get_weather(location="Tokyo")
Observation: {"temperature": 22, "condition": "sunny"}
Thought: Now I can answer the user
Final Answer: The weather in Tokyo is sunny with 22Â°C
```

## Building a Simple Agent

```python
from openai import OpenAI
import json

client = OpenAI()

# Define tools
tools = [
    {
        "type": "function",
        "function": {
            "name": "search_web",
            "description": "Search the web for current information",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Search query"}
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "calculate",
            "description": "Perform mathematical calculations",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {"type": "string", "description": "Math expression to evaluate"}
                },
                "required": ["expression"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get current weather for a location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {"type": "string"}
                },
                "required": ["location"]
            }
        }
    }
]

# Tool implementations
def search_web(query: str) -> str:
    # In production, use actual search API
    return f"Search results for '{query}': [mock results]"

def calculate(expression: str) -> str:
    try:
        result = eval(expression)  # Use safer evaluation in production
        return str(result)
    except Exception as e:
        return f"Error: {e}"

def get_weather(location: str) -> str:
    # Mock weather data
    return json.dumps({"location": location, "temp": 22, "condition": "sunny"})

tool_functions = {
    "search_web": search_web,
    "calculate": calculate,
    "get_weather": get_weather
}

def run_agent(user_message: str, max_iterations: int = 5) -> str:
    """Run agent loop with tool use"""
    messages = [
        {
            "role": "system",
            "content": """You are a helpful assistant with access to tools.
            Use tools when needed to answer questions accurately.
            Always explain your reasoning."""
        },
        {"role": "user", "content": user_message}
    ]
    
    for i in range(max_iterations):
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            tools=tools,
            tool_choice="auto"
        )
        
        message = response.choices[0].message
        messages.append(message)
        
        # Check if done (no tool calls)
        if not message.tool_calls:
            return message.content
        
        # Execute tool calls
        for tool_call in message.tool_calls:
            function_name = tool_call.function.name
            arguments = json.loads(tool_call.function.arguments)
            
            # Execute the function
            result = tool_functions[function_name](**arguments)
            
            # Add result to messages
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": result
            })
    
    return "Max iterations reached"

# Usage
answer = run_agent("What's 15% tip on a $85 bill, and what's the weather in Paris?")
print(answer)
```

## Agent with Memory

```python
class AgentWithMemory:
    def __init__(self, system_prompt: str = None):
        self.client = OpenAI()
        self.conversation_history = []
        self.tool_history = []
        self.system_prompt = system_prompt or "You are a helpful assistant with memory."
        
    def remember(self, key: str, value: str):
        """Store information in agent's memory"""
        self.tool_history.append({"type": "memory", "key": key, "value": value})
    
    def recall(self, key: str) -> str:
        """Recall information from memory"""
        for item in reversed(self.tool_history):
            if item.get("key") == key:
                return item["value"]
        return None
    
    def get_context(self) -> str:
        """Build context from memory"""
        memory_items = [f"- {item['key']}: {item['value']}" 
                       for item in self.tool_history if item["type"] == "memory"]
        if memory_items:
            return "Remembered information:\n" + "\n".join(memory_items)
        return ""
    
    def chat(self, user_message: str) -> str:
        """Chat with memory context"""
        context = self.get_context()
        
        messages = [{"role": "system", "content": f"{self.system_prompt}\n\n{context}"}]
        messages.extend(self.conversation_history)
        messages.append({"role": "user", "content": user_message})
        
        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=messages
        )
        
        assistant_message = response.choices[0].message.content
        
        # Update conversation history
        self.conversation_history.append({"role": "user", "content": user_message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        
        return assistant_message

# Usage
agent = AgentWithMemory()
agent.remember("user_name", "Alex")
agent.remember("preference", "prefers Python over JavaScript")

print(agent.chat("What's my name?"))  # Uses memory
print(agent.chat("Recommend a language for me"))  # Uses preference
```

## Code Execution Agent

```python
import subprocess
import tempfile
import os

def execute_python(code: str) -> str:
    """Safely execute Python code in sandbox"""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        f.write(code)
        temp_file = f.name
    
    try:
        result = subprocess.run(
            ['python', temp_file],
            capture_output=True,
            text=True,
            timeout=10
        )
        output = result.stdout or result.stderr
        return output[:1000]  # Limit output
    except subprocess.TimeoutExpired:
        return "Execution timed out"
    except Exception as e:
        return f"Error: {e}"
    finally:
        os.unlink(temp_file)

# Add to tools
code_tool = {
    "type": "function",
    "function": {
        "name": "execute_python",
        "description": "Execute Python code and return the output",
        "parameters": {
            "type": "object",
            "properties": {
                "code": {"type": "string", "description": "Python code to execute"}
            },
            "required": ["code"]
        }
    }
}
```

## Planning Agent

For complex tasks, agents can plan before acting:

```python
def planning_agent(task: str) -> str:
    """Agent that plans before executing"""
    
    # Step 1: Create a plan
    plan_response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """You are a planning assistant. Given a task, create a step-by-step plan.
                Return as JSON: {"steps": ["step 1", "step 2", ...]}"""
            },
            {"role": "user", "content": f"Create a plan for: {task}"}
        ],
        response_format={"type": "json_object"}
    )
    
    plan = json.loads(plan_response.choices[0].message.content)
    steps = plan.get("steps", [])
    
    # Step 2: Execute each step
    results = []
    for i, step in enumerate(steps):
        print(f"Executing step {i+1}: {step}")
        
        step_result = run_agent(f"Execute this step: {step}\n\nPrevious results: {results}")
        results.append({"step": step, "result": step_result})
    
    # Step 3: Synthesize final answer
    synthesis = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Synthesize the results into a final answer."},
            {"role": "user", "content": f"Task: {task}\n\nResults: {json.dumps(results)}"}
        ]
    )
    
    return synthesis.choices[0].message.content
```

## Agent Patterns

<CardGroup cols={2}>
  <Card title="ReAct Agent" icon="brain">
    Alternates between reasoning (Thought) and acting (Tool Use)
  </Card>
  <Card title="Plan-Execute Agent" icon="list-check">
    Creates full plan first, then executes steps
  </Card>
  <Card title="Reflexion Agent" icon="rotate">
    Reflects on failures and self-corrects
  </Card>
  <Card title="Multi-Agent" icon="users">
    Multiple specialized agents collaborate
  </Card>
</CardGroup>

## Best Practices

<AccordionGroup>
  <Accordion title="Limit Tool Iterations" icon="repeat">
    Set maximum iterations to prevent infinite loops:
    ```python
    for i in range(max_iterations):
        # Agent loop
        if done:
            break
    ```
  </Accordion>
  
  <Accordion title="Handle Tool Errors" icon="triangle-exclamation">
    Tools can fail. Always handle errors gracefully:
    ```python
    try:
        result = tool_function(**args)
    except Exception as e:
        result = f"Tool error: {e}. Try a different approach."
    ```
  </Accordion>
  
  <Accordion title="Validate Tool Arguments" icon="shield">
    Don't trust LLM-generated arguments blindly:
    ```python
    from pydantic import BaseModel, ValidationError
    
    class SearchArgs(BaseModel):
        query: str
        max_results: int = 10
    
    try:
        args = SearchArgs(**raw_args)
    except ValidationError as e:
        return f"Invalid arguments: {e}"
    ```
  </Accordion>
  
  <Accordion title="Add Observability" icon="eye">
    Log agent decisions for debugging:
    ```python
    import logging
    
    logger = logging.getLogger("agent")
    
    logger.info(f"Tool call: {function_name}({arguments})")
    logger.info(f"Tool result: {result[:200]}")
    ```
  </Accordion>
</AccordionGroup>

## When to Use Agents

| Use Agents When | Don't Use Agents When |
|-----------------|----------------------|
| Task requires multiple steps | Simple Q&A |
| Need real-time data | Static knowledge suffices |
| Actions have side effects | Pure text generation |
| Problem-solving required | Straightforward transformation |

## Next Steps

<Card title="LangGraph" icon="arrow-right" href="/ai-engineering/langgraph">
  Build complex agent workflows with state machines
</Card>
